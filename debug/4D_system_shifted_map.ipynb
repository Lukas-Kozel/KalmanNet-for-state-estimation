{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24e3857",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from scipy.io import loadmat\n",
    "import sys\n",
    "import os\n",
    "\n",
    "\n",
    "dataset_path = Path('data') / 'data.mat'\n",
    "if not dataset_path.exists():\n",
    "    alt = Path.cwd().parent / 'data' / 'data.mat'\n",
    "    if alt.exists():\n",
    "        dataset_path = alt\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"data.mat not found under {Path.cwd()} or its parent\")\n",
    "\n",
    "notebook_path = os.getcwd() \n",
    "print (f\"Current notebook path: {notebook_path}\")\n",
    "project_root = os.path.dirname(notebook_path)\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "print (f\"Added {project_root} to sys.path\")\n",
    "\n",
    "mat_data = loadmat(dataset_path)\n",
    "print(mat_data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47109e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import trainer\n",
    "from utils import utils\n",
    "from Systems import DynamicSystem\n",
    "import Filters\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "from scipy.interpolate import RegularGridInterpolator\n",
    "import random\n",
    "\n",
    "# Set reproducible seeds\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Currently used device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d8be52",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_data = loadmat(dataset_path)\n",
    "\n",
    "souradniceX_mapa = mat_data['souradniceX']\n",
    "souradniceY_mapa = mat_data['souradniceY']\n",
    "souradniceZ_mapa = mat_data['souradniceZ']\n",
    "souradniceGNSS = mat_data['souradniceGNSS'] \n",
    "x_axis_unique = souradniceX_mapa[0, :]\n",
    "y_axis_unique = souradniceY_mapa[:, 0]\n",
    "\n",
    "print(f\"Dimensions of 1D X axis: {x_axis_unique.shape}\")\n",
    "print(f\"Dimensions of 1D Y axis: {y_axis_unique.shape}\")\n",
    "print(f\"Dimensions of 2D elevation data Z: {souradniceZ_mapa.shape}\")\n",
    "\n",
    "\n",
    "terMap_interpolator = RegularGridInterpolator(\n",
    "    (y_axis_unique, x_axis_unique),\n",
    "    souradniceZ_mapa,\n",
    "    bounds_error=False, \n",
    "    fill_value=np.nan\n",
    ")\n",
    "\n",
    "def terMap(px, py):\n",
    "    # Query bilinear interpolation over the terrain map\n",
    "    points_to_query = np.column_stack((py, px))\n",
    "    return terMap_interpolator(points_to_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1e91fb",
   "metadata": {},
   "source": [
    "# 4D model\n",
    "\n",
    "### The map is shifted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f225b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as func\n",
    "from Systems import DynamicSystemTAN\n",
    "\n",
    "# Safe device selection with fallback\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Get global offset from first GNSS point (start at 0,0)\n",
    "global_offset_x = souradniceGNSS[0, 0]\n",
    "global_offset_y = souradniceGNSS[1, 0]\n",
    "\n",
    "# Original map axes\n",
    "x_axis_unique = souradniceX_mapa[0, :]\n",
    "y_axis_unique = souradniceY_mapa[:, 0]\n",
    "\n",
    "# Shifted map bounds (in local frame where start is 0,0)\n",
    "x_min_shifted = x_axis_unique.min() - global_offset_x\n",
    "x_max_shifted = x_axis_unique.max() - global_offset_x\n",
    "y_min_shifted = y_axis_unique.min() - global_offset_y\n",
    "y_max_shifted = y_axis_unique.max() - global_offset_y\n",
    "\n",
    "print(f\"Local map bounds X: [{x_min_shifted:.2f}, {x_max_shifted:.2f}]\")\n",
    "print(f\"Local map bounds Y: [{y_min_shifted:.2f}, {y_max_shifted:.2f}]\")\n",
    "\n",
    "# Prepare the map tensor; fallback to CPU if CUDA is busy/unavailable\n",
    "try:\n",
    "    terMap_tensor = torch.from_numpy(souradniceZ_mapa).float().unsqueeze(0).unsqueeze(0)\n",
    "    terMap_tensor = terMap_tensor.to(device)\n",
    "except RuntimeError as e:\n",
    "    print(\"Warning: CUDA unavailable or busy. Falling back to CPU for terMap_tensor.\")\n",
    "    print(f\"Reason: {e}\")\n",
    "    device = torch.device(\"cpu\")\n",
    "    terMap_tensor = terMap_tensor.cpu()\n",
    "\n",
    "state_dim = 4\n",
    "obs_dim = 3\n",
    "dT = 1.0\n",
    "q = 1.0\n",
    "\n",
    "F = torch.tensor([[1.0, 0.0, dT, 0.0],\n",
    "                  [0.0, 1.0, 0.0, dT],\n",
    "                  [0.0, 0.0, 1.0, 0.0],\n",
    "                  [0.0, 0.0, 0.0, 1.0]], device=device)\n",
    "\n",
    "Q = q * torch.tensor([[dT**3/3, 0.0,     dT**2/2, 0.0],\n",
    "                      [0.0,     dT**3/3, 0.0,     dT**2/2],\n",
    "                      [dT**2/2, 0.0,     dT,      0.0],\n",
    "                      [0.0,     dT**2/2, 0.0,     dT]], device=device)\n",
    "\n",
    "R = torch.tensor([[3.0**2, 0.0,    0.0],\n",
    "                  [0.0,    1.0**2, 0.0],\n",
    "                  [0.0,    0.0,    1.0**2]], device=device)\n",
    "\n",
    "x_0 = torch.zeros(state_dim, device=device).float()\n",
    "print(\"Initial state x_0:\", x_0)\n",
    "\n",
    "# Initial error covariance P_0\n",
    "P_0 = torch.tensor([[25.0, 0.0, 0.0, 0.0],\n",
    "                    [0.0, 25.0, 0.0, 0.0],\n",
    "                    [0.0, 0.0, 0.5, 0.0],\n",
    "                    [0.0, 0.0, 0.0, 0.5]], device=device)\n",
    "\n",
    "def h_nl_differentiable(x: torch.Tensor, map_tensor, x_min, x_max, y_min, y_max) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Maps state x -> measurement y.\n",
    "    x: [Batch, 4] (px, py, vx, vy)\n",
    "    Output: [Batch, 3] (z_baro, v_world_x, v_world_y)\n",
    "    \"\"\"\n",
    "    batch_size = x.shape[0]\n",
    "    \n",
    "    # 1. Extract position\n",
    "    px = x[:, 0]\n",
    "    py = x[:, 1]\n",
    "\n",
    "    # 2. Normalize coordinates for grid_sample to interval [-1, 1]\n",
    "    px_norm = 2.0 * (px - x_min) / (x_max - x_min) - 1.0\n",
    "    py_norm = 2.0 * (py - y_min) / (y_max - y_min) - 1.0\n",
    "\n",
    "    # Prepare grid [Batch, 1, 1, 2]\n",
    "    sampling_grid = torch.stack((px_norm, py_norm), dim=1).view(batch_size, 1, 1, 2)\n",
    "\n",
    "    vyska_terenu_batch = func.grid_sample(\n",
    "        map_tensor.expand(batch_size, -1, -1, -1), # duplicate map for batch\n",
    "        sampling_grid, \n",
    "        mode='bilinear', \n",
    "        padding_mode='border',\n",
    "        align_corners=True\n",
    "    )\n",
    "    vyska_terenu = vyska_terenu_batch.view(batch_size)\n",
    "\n",
    "    vx_w, vy_w = x[:, 2], x[:, 3]\n",
    "    \n",
    "    eps = 1e-12\n",
    "    norm_v_w = torch.sqrt(vx_w**2 + vy_w**2).clamp(min=eps)\n",
    "    \n",
    "    # Cos and Sin of heading angle\n",
    "    cos_psi = vx_w / norm_v_w\n",
    "    sin_psi = vy_w / norm_v_w\n",
    "\n",
    "    # Rotate velocity\n",
    "    vx_b = cos_psi * vx_w - sin_psi * vy_w  \n",
    "    vy_b = sin_psi * vx_w + cos_psi * vy_w \n",
    "    \n",
    "    result = torch.stack([vyska_terenu, vx_b, vy_b], dim=1)\n",
    "    return result\n",
    "\n",
    "h_wrapper = lambda x: h_nl_differentiable(\n",
    "    x, \n",
    "    map_tensor=terMap_tensor, \n",
    "    x_min=x_min_shifted, \n",
    "    x_max=x_max_shifted, \n",
    "    y_min=y_min_shifted, \n",
    "    y_max=y_max_shifted\n",
    ")\n",
    "\n",
    "system_model = DynamicSystemTAN(\n",
    "    state_dim=state_dim,\n",
    "    obs_dim=obs_dim,\n",
    "    Q=Q,\n",
    "    R=R,\n",
    "    Ex0=x_0,\n",
    "    P0=P_0,\n",
    "    F=F,\n",
    "    h=h_wrapper,\n",
    "    x_axis_unique=torch.tensor([x_min_shifted, x_max_shifted], device=device),\n",
    "    y_axis_unique=torch.tensor([y_min_shifted, y_max_shifted], device=device),\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eeceaa4",
   "metadata": {},
   "source": [
    "### Grafické ověření\n",
    "ověření, že funkce h je správně definována a mapa je správně posunuta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b9c58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "def verify_map_alignment_3d(gnss_data, map_x, map_y, map_z, model, x_offset, y_offset, downsample=10):\n",
    "    gnss_x_global = gnss_data[0, :]\n",
    "    gnss_y_global = gnss_data[1, :]\n",
    "    \n",
    "    # Transform to local frame (same as during training)\n",
    "    local_px = gnss_x_global - x_offset\n",
    "    local_py = gnss_y_global - y_offset\n",
    "    \n",
    "    N = len(local_px)\n",
    "    \n",
    "    dummy_vx = np.ones(N)\n",
    "    dummy_vy = np.zeros(N)\n",
    "    \n",
    "    # Build tensor [N, 4]\n",
    "    x_states_np = np.stack([local_px, local_py, dummy_vx, dummy_vy], axis=1)\n",
    "    x_states = torch.from_numpy(x_states_np).float().to(model.device)\n",
    "    \n",
    "    # If h is an nn.Module, switch to eval\n",
    "    model.h.eval() if hasattr(model.h, 'eval') else None\n",
    "    with torch.no_grad():\n",
    "        y_out = model.h(x_states)\n",
    "        \n",
    "    calculated_heights = y_out[:, 0].cpu().numpy()\n",
    "    \n",
    "    if map_x.ndim == 1 and map_y.ndim == 1 and map_z.ndim == 2:\n",
    "         # If map_x/y are axes only, create meshgrid for plotting\n",
    "         X_grid, Y_grid = np.meshgrid(map_x, map_y)  # Watch ordering: Z[row, col] -> Y[row], X[col]\n",
    "         if map_z.shape == (len(map_y), len(map_x)):\n",
    "             pass\n",
    "         elif map_z.shape == (len(map_x), len(map_y)):\n",
    "             X_grid, Y_grid = np.meshgrid(map_x, map_y, indexing='ij')\n",
    "    else:\n",
    "        X_grid, Y_grid = map_x, map_y\n",
    "        \n",
    "    # Shift map to local coordinates\n",
    "    X_grid_local = X_grid - x_offset\n",
    "    Y_grid_local = Y_grid - y_offset\n",
    "    Z_grid = map_z\n",
    "    \n",
    "    # Downsample for faster plotting (map may be huge)\n",
    "    ds = downsample\n",
    "    X_plot = X_grid_local[::ds, ::ds]\n",
    "    Y_plot = Y_grid_local[::ds, ::ds]\n",
    "    Z_plot = Z_grid[::ds, ::ds]\n",
    "    \n",
    "    # Plot\n",
    "    print(\"Rendering 3D plot...\")\n",
    "    fig = plt.figure(figsize=(12, 10))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    \n",
    "    surf = ax.plot_surface(X_plot, Y_plot, Z_plot, cmap='terrain', alpha=0.6, linewidth=0, antialiased=False)\n",
    "\n",
    "    ax.plot(local_px, local_py, calculated_heights, color='red', linewidth=2, label='GNSS trajectory via h(x)')\n",
    "    \n",
    "    ax.set_title('Verification of h(x) and coordinate shift')\n",
    "    ax.set_xlabel('Local X [m]')\n",
    "    ax.set_ylabel('Local Y [m]')\n",
    "    ax.set_zlabel('Elevation [m]')\n",
    "    ax.legend()\n",
    "    \n",
    "    ax.view_init(elev=45, azim=-45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Done.\")\n",
    "    print(f\"Elevation range along trajectory: {calculated_heights.min():.2f} m to {calculated_heights.max():.2f} m\")\n",
    "\n",
    "verify_map_alignment_3d(\n",
    "    souradniceGNSS, \n",
    "    x_axis_unique,\n",
    "    y_axis_unique, \n",
    "    souradniceZ_mapa, \n",
    "    system_model, \n",
    "    global_offset_x, \n",
    "    global_offset_y,\n",
    "    downsample=1 \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d6e172",
   "metadata": {},
   "source": [
    "## Data Generation\n",
    "### Data are generated from zero initial conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88fb331",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from utils import utils\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "TRAIN_SEQ_LEN = 100\n",
    "VALID_SEQ_LEN = 200\n",
    "\n",
    "NUM_TRAIN_TRAJECTORIES = 700  # Total number of training trajectories\n",
    "NUM_VALID_TRAJECTORIES = 100  # Total number of validation trajectories\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "# Map bounds propagated to system model\n",
    "system_model.min_x = x_min_shifted\n",
    "system_model.max_x = x_max_shifted\n",
    "system_model.min_y = y_min_shifted\n",
    "system_model.max_y = y_max_shifted\n",
    "system_model.device = device \n",
    "\n",
    "print(f\"\\n=== Generating {NUM_TRAIN_TRAJECTORIES} TRAINING trajectories (length {TRAIN_SEQ_LEN}) ===\")\n",
    "\n",
    "x_train, y_train = utils.generate_data_for_map(\n",
    "    system_model, \n",
    "    num_trajectories=NUM_TRAIN_TRAJECTORIES, \n",
    "    seq_len=TRAIN_SEQ_LEN,\n",
    "    force_initial_state_zero=True\n",
    ")\n",
    "\n",
    "print(f\"--> Done. Training data: X={x_train.shape}, Y={y_train.shape}\")\n",
    "\n",
    "\n",
    "print(f\"\\n=== Generating {NUM_VALID_TRAJECTORIES} VALIDATION trajectories (length {VALID_SEQ_LEN}) ===\")\n",
    "\n",
    "x_val, y_val = utils.generate_data_for_map(\n",
    "    system_model, \n",
    "    num_trajectories=NUM_VALID_TRAJECTORIES, \n",
    "    seq_len=VALID_SEQ_LEN,\n",
    "    force_initial_state_zero=True\n",
    ")\n",
    "\n",
    "print(f\"--> Done. Validation data: X={x_val.shape}, Y={y_val.shape}\")\n",
    "\n",
    "\n",
    "train_dataset = TensorDataset(x_train, y_train)\n",
    "val_dataset = TensorDataset(x_val, y_val)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(\"\\n✅ DataLoaders ready. Sets removed; using total trajectory counts.\")\n",
    "print(f\"Range of training X (min/max): {x_train.min():.2f} / {x_train.max():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1531b397",
   "metadata": {},
   "source": [
    "## Plot Training Trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ff8eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_trajectories(x_data, title=\"Trajectories\", num_to_plot=None):\n",
    "    # Convert to numpy for matplotlib\n",
    "    x_np = x_data.detach().cpu().numpy()\n",
    "    \n",
    "    total_traj = x_np.shape[0]\n",
    "    \n",
    "    # Select indices to plot\n",
    "    if num_to_plot is not None and num_to_plot < total_traj:\n",
    "        indices = np.random.choice(total_traj, num_to_plot, replace=False)\n",
    "        print(f\"Plotting {num_to_plot} random trajectories out of {total_traj} total.\")\n",
    "    else:\n",
    "        indices = range(total_traj)\n",
    "        print(f\"Plotting all {total_traj} trajectories.\")\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    for i in indices:\n",
    "        # x_np[i, :, 0] is X coordinate over time\n",
    "        # x_np[i, :, 1] is Y coordinate over time\n",
    "        pos_x = x_np[i, :, 0]\n",
    "        pos_y = x_np[i, :, 1]\n",
    "        \n",
    "        # Plot path\n",
    "        plt.plot(pos_x, pos_y, alpha=0.5, linewidth=1)\n",
    "        \n",
    "        # Highlight start (green dot) and end (red dot)\n",
    "        plt.plot(pos_x[0], pos_y[0], 'go', markersize=3, label='Start' if i == (indices[0] if hasattr(indices, '__getitem__') else 0) else \"\")\n",
    "        plt.plot(pos_x[-1], pos_y[-1], 'ro', markersize=3, label='End' if i == (indices[0] if hasattr(indices, '__getitem__') else 0) else \"\")\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Position X [m]\")\n",
    "    plt.ylabel(\"Position Y [m]\")\n",
    "    plt.grid(True)\n",
    "    plt.axis('equal')  # Avoid aspect ratio distortion\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 1. Plot all training data (may be cluttered if too many)\n",
    "plot_trajectories(x_train, title=\"All training trajectories (from zero)\")\n",
    "\n",
    "# 2. Or plot a random sample (e.g., 50 trajectories) for clarity\n",
    "# plot_trajectories(x_train, title=\"Sample of 50 training trajectories\", num_to_plot=50)\n",
    "\n",
    "# 3. You can also check validation data\n",
    "# plot_trajectories(x_val, title=\"Validation trajectories\", num_to_plot=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9268341f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def calculate_naive_baseline(x_train, x_val):\n",
    "    # Mean of states across all trajectories and timesteps\n",
    "    train_mean = torch.mean(x_train, dim=(0, 1))\n",
    "    \n",
    "    print(\"Mean of states (Naive prediction):\")\n",
    "    print(f\"  Position:  {train_mean[0:2].tolist()}\")\n",
    "    print(f\"  Velocity:  {train_mean[2:4].tolist()}\")\n",
    "\n",
    "    errors_squared = (x_val - train_mean) ** 2\n",
    "    \n",
    "    mse_pos = torch.mean(errors_squared[:, :, 0:2]).item()\n",
    "    mse_vel = torch.mean(errors_squared[:, :, 2:4]).item()\n",
    "    mse_total = torch.mean(errors_squared).item()\n",
    "    \n",
    "    print(\"---------------------------------------------------\")\n",
    "    print(f\"Baseline Loss (Total): {mse_total:.6f}  (for comparison with validation loss during training)\")\n",
    "    print(\"---------------------------------------------------\")\n",
    "    print(f\"  > Position MSE:  {mse_pos:.6f}\")\n",
    "    print(f\"  > Velocity MSE:  {mse_vel:.6f}\")\n",
    "    \n",
    "    return mse_total, mse_pos, mse_vel\n",
    "\n",
    "base_loss, base_pos, base_vel = calculate_naive_baseline(x_train, x_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1997e33",
   "metadata": {},
   "source": [
    "### KalmanNet Training\n",
    "\n",
    "Notes:\n",
    "- During training, for each new trajectory, KalmanNet receives the exact initial state via `reset()`.\n",
    "- The output layer `output_final_linear` is initialized with near-zero weights to reduce extreme loss spikes at the beginning of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d101fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from copy import deepcopy\n",
    "from state_NN_models import StateKalmanNet \n",
    "from state_NN_models import StateKalmanNet_arch2\n",
    "from utils import trainer \n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "if False:\n",
    "    # Use architecture 2: model with 3 distinct GRU layers\n",
    "    state_knet2 = StateKalmanNet_arch2(\n",
    "        system_model=system_model, \n",
    "        device=device,\n",
    "        hidden_size_multiplier=12,\n",
    "        output_layer_multiplier=4\n",
    "        ).to(device)\n",
    "else:\n",
    "    # Use architecture 1: model with a single GRU layer\n",
    "    state_knet2 = StateKalmanNet(\n",
    "        system_model=system_model, \n",
    "        device=device,\n",
    "        hidden_size_multiplier=10,\n",
    "        output_layer_multiplier=1,\n",
    "        num_gru_layers=1,\n",
    "        gru_hidden_dim_multiplier=8\n",
    "        ).to(device)\n",
    "\n",
    "print(state_knet2)\n",
    "\n",
    "trained_model = trainer.train_state_KalmanNet_sliding_window(\n",
    "    model=state_knet2,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    device=device,\n",
    "    epochs=500,\n",
    "    lr=1e-4,\n",
    "    clip_grad=10.0,\n",
    "    early_stopping_patience=200,\n",
    "    tbptt_k=2,\n",
    "    tbptt_w=30,\n",
    "    optimizer_=torch.optim.AdamW,\n",
    "    weight_decay_=1e-5,\n",
    "\n",
    ")\n",
    "print(trained_model)\n",
    "# New best model saved! Epoch [28/500], Train Loss: 47.183285, Val Loss: 115.5970380"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da747594",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def verify_dead_reckoning_hypothesis(model, val_loader, device, dt=1.0):\n",
    "    model.eval()\n",
    "    \n",
    "    pos_mse_knet = 0.0\n",
    "    pos_mse_dr = 0.0\n",
    "    total_samples = 0\n",
    "    \n",
    "    # For visualization, store the first trajectory from the batch\n",
    "    traj_gt = []\n",
    "    traj_knet = []\n",
    "    traj_dr = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (x_true, y_meas) in enumerate(val_loader):\n",
    "            x_true = x_true.to(device)\n",
    "            y_meas = y_meas.to(device)\n",
    "            batch_size, seq_len, _ = x_true.shape\n",
    "            \n",
    "            # --- 1. KalmanNet prediction ---\n",
    "            model.reset(batch_size=batch_size, initial_state=x_true[:, 0, :])\n",
    "            knet_preds = []\n",
    "            for t in range(1, seq_len):\n",
    "                out = model.step(y_meas[:, t, :])\n",
    "                # Handle tuple output for Architecture 2\n",
    "                state = out[0] if isinstance(out, tuple) else out\n",
    "                knet_preds.append(state)\n",
    "            knet_tensor = torch.stack(knet_preds, dim=1)  # [B, T-1, 4]\n",
    "            \n",
    "            # --- 2. Dead Reckoning (simulate a \"dumb\" integrator) ---\n",
    "            # Start at the correct position at t=0\n",
    "            dr_pos = x_true[:, 0, 0:2].clone()\n",
    "            dr_preds = []\n",
    "            \n",
    "            for t in range(1, seq_len):\n",
    "                # y_meas[:, t, 1] is vx, y_meas[:, t, 2] is vy (assuming world-frame measurement)\n",
    "                vx_meas = y_meas[:, t, 1]\n",
    "                vy_meas = y_meas[:, t, 2]\n",
    "                \n",
    "                # Euler integration: pos = pos + vel * dt\n",
    "                dr_pos[:, 0] += vx_meas * dt\n",
    "                dr_pos[:, 1] += vy_meas * dt\n",
    "                dr_preds.append(dr_pos.clone())\n",
    "            \n",
    "            dr_tensor = torch.stack(dr_preds, dim=1)  # [B, T-1, 2]\n",
    "            \n",
    "            # --- 3. Error computation ---\n",
    "            # Ground-truth position (from t=1)\n",
    "            gt_pos = x_true[:, 1:, 0:2]\n",
    "            \n",
    "            # MSE for KalmanNet (position)\n",
    "            knet_err = (knet_tensor[:, :, 0:2] - gt_pos) ** 2\n",
    "            pos_mse_knet += knet_err.sum().item()\n",
    "            \n",
    "            # MSE for Dead Reckoning (position)\n",
    "            dr_err = (dr_tensor - gt_pos) ** 2\n",
    "            pos_mse_dr += dr_err.sum().item()\n",
    "            \n",
    "            total_samples += (batch_size * (seq_len - 1))\n",
    "            \n",
    "            # Save first trajectory for plotting (only from first batch)\n",
    "            if i == 0:\n",
    "                traj_gt = x_true[0, :, 0:2].cpu().numpy()\n",
    "                traj_knet = torch.cat([x_true[0:1, 0, 0:2], knet_tensor[0, :, 0:2]], dim=0).cpu().numpy()\n",
    "                traj_dr = torch.cat([x_true[0:1, 0, 0:2], dr_tensor[0, :, :]], dim=0).cpu().numpy()\n",
    "\n",
    "    avg_mse_knet = pos_mse_knet / total_samples\n",
    "    avg_mse_dr = pos_mse_dr / total_samples\n",
    "    \n",
    "    print(\"\\n=== HYPOTHESIS VERIFICATION: IGNORING THE MAP ===\")\n",
    "    print(f\"Position MSE (Dead Reckoning - pure integration): {avg_mse_dr:.2f}\")\n",
    "    print(f\"Position MSE (KalmanNet - your model):           {avg_mse_knet:.2f}\")\n",
    "    \n",
    "    ratio = avg_mse_knet / avg_mse_dr\n",
    "    print(f\"Ratio (KNet / DR): {ratio:.4f}\")\n",
    "    \n",
    "    if 0.95 < ratio < 1.05:\n",
    "        print(\">> CONFIRMED: Model behaves almost identically to Dead Reckoning. It ignores the map.\")\n",
    "    elif ratio < 0.9:\n",
    "        print(\">> REJECTED: Model is more than 10% better than DR. It uses the map.\")\n",
    "    else:\n",
    "        print(\">> UNCLEAR: Model is somewhat different, but not by much.\")\n",
    "\n",
    "    return traj_gt, traj_knet, traj_dr\n",
    "\n",
    "# Run\n",
    "gt_plot, knet_plot, dr_plot = verify_dead_reckoning_hypothesis(state_knet2, val_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443fbafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(gt_plot[:, 0], gt_plot[:, 1], 'k-', label='Ground Truth', linewidth=2)\n",
    "plt.plot(dr_plot[:, 0], dr_plot[:, 1], 'r--', label='Dead Reckoning (No map)')\n",
    "plt.plot(knet_plot[:, 0], knet_plot[:, 1], 'b-.', label='KalmanNet Prediction')\n",
    "plt.legend()\n",
    "plt.title(\"Model behavior analysis: Does it follow the map or just integrate?\")\n",
    "plt.xlabel(\"X [m]\")\n",
    "plt.ylabel(\"Y [m]\")\n",
    "plt.grid(True)\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea69383",
   "metadata": {},
   "source": [
    "## Testing on Test Data\n",
    "- Comparison of KalmanNet against UKF and PF\n",
    "- PF would require roughly 10x more particles for higher accuracy; not explored here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717ecbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "TEST_SEQ_LEN = 1000\n",
    "NUM_TEST_TRAJ = 5\n",
    "\n",
    "print(f\"\\nGenerating {NUM_TEST_TRAJ} test trajectories of length {TEST_SEQ_LEN}...\")\n",
    "\n",
    "x_test, y_test = utils.generate_data_for_map(\n",
    "    system_model, \n",
    "    num_trajectories=NUM_TEST_TRAJ,\n",
    "    seq_len=TEST_SEQ_LEN,\n",
    "    force_initial_state_zero=True\n",
    ")\n",
    "\n",
    "test_dataset = TensorDataset(x_test, y_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "print(\"Data generation complete.\")\n",
    "\n",
    "print(\"y shape:\", y_test.shape)  # Should be [N, T, obs_dim]\n",
    "print(\"x shape:\", x_test.shape)  # Should be [N, T, state_dim]\n",
    "\n",
    "ukf_ideal = Filters.UnscentedKalmanFilter(system_model)\n",
    "pf_sir_ideal = Filters.ParticleFilter(system_model, num_particles=20000)\n",
    "\n",
    "all_x_true_cpu = []\n",
    "all_x_hat_ukf_ideal_cpu, all_P_hat_ukf_ideal_cpu = [], []\n",
    "all_x_hat_pf_sir_ideal_cpu, all_P_hat_pf_sir_ideal_cpu = [], []\n",
    "all_x_hat_classic_knet_cpu = []\n",
    "all_x_hat_bkn_cpu, all_P_hat_bkn_cpu = [], []\n",
    "all_x_hat_knet_cpu = []\n",
    "all_x_hat_classic_knet2_cpu = []\n",
    "all_x_hat_classic_knet3_cpu = []\n",
    "all_x_hat_kalman_former_cpu = []\n",
    "\n",
    "all_knet_diagnostics_cpu = []\n",
    "print(f\"\\nEvaluating models on {NUM_TEST_TRAJ} test trajectories...\")\n",
    "\n",
    "state_knet2.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (x_true_seq_batch, y_test_seq_batch) in enumerate(test_loader):\n",
    "        y_test_seq_gpu = y_test_seq_batch.squeeze(0).to(device)\n",
    "        x_true_seq_gpu = x_true_seq_batch.squeeze(0).to(device)\n",
    "        initial_state = x_true_seq_gpu[0, :].unsqueeze(0)\n",
    "        state_knet2.reset(batch_size=1, initial_state=initial_state)\n",
    "        classic_knet2_preds = []\n",
    "        for t in range(1, TEST_SEQ_LEN):\n",
    "            x_filtered_t = state_knet2.step(y_test_seq_gpu[t, :].unsqueeze(0))\n",
    "            classic_knet2_preds.append(x_filtered_t)\n",
    "        full_x_hat_classic_knet2 = torch.cat([initial_state, torch.cat(classic_knet2_preds, dim=0)], dim=0)\n",
    "\n",
    "        ukf_i_res = ukf_ideal.process_sequence(\n",
    "            y_seq=y_test_seq_gpu,\n",
    "            Ex0=system_model.Ex0, \n",
    "            P0=system_model.P0\n",
    "        )\n",
    "        full_x_hat_ukf_i = ukf_i_res['x_filtered']\n",
    "        full_P_hat_ukf_i = ukf_i_res['P_filtered']\n",
    "\n",
    "        pf_sir_i_res = pf_sir_ideal.process_sequence(y_test_seq_gpu, Ex0=system_model.Ex0,P0=system_model.P0)\n",
    "        full_x_hat_pf_sir_i = pf_sir_i_res['x_filtered']\n",
    "        full_P_hat_pf_sir_i = pf_sir_i_res['P_filtered']\n",
    "        full_particles_history_pf_sir_i = pf_sir_i_res['particles_history']\n",
    "        print(f\"PF-SIR (ideal model) finished for trajectory {i + 1}/{NUM_TEST_TRAJ}.\")\n",
    "\n",
    "        all_x_true_cpu.append(x_true_seq_gpu.cpu())\n",
    "        all_x_hat_classic_knet2_cpu.append(full_x_hat_classic_knet2.cpu())\n",
    "        all_x_hat_ukf_ideal_cpu.append(full_x_hat_ukf_i.cpu()); all_P_hat_ukf_ideal_cpu.append(full_P_hat_ukf_i.cpu())\n",
    "        all_x_hat_pf_sir_ideal_cpu.append(full_x_hat_pf_sir_i.cpu()); all_P_hat_pf_sir_ideal_cpu.append(full_P_hat_pf_sir_i.cpu())\n",
    "        print(f\"Completed trajectory {i + 1}/{NUM_TEST_TRAJ}...\")\n",
    "\n",
    "mse_bkn, anees_bkn = [], []; mse_ukf_ideal, anees_ukf_ideal = [], []\n",
    "\n",
    "mse_pf_sir_ideal, anees_pf_sir_ideal = [], []\n",
    "mse_classic_knet2 = []; mse_classic_knet3 = []\n",
    "mse_kalman_former = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(NUM_TEST_TRAJ):\n",
    "        x_true = all_x_true_cpu[i]\n",
    "        def get_metrics(x_hat_full, P_hat_full):\n",
    "            if x_hat_full.shape[0] != x_true.shape[0] or P_hat_full.shape[0] != x_true.shape[0]:\n",
    "                 raise ValueError(f\"Length mismatch! x_true: {x_true.shape[0]}, x_hat: {x_hat_full.shape[0]}, P_hat: {P_hat_full.shape[0]}\")\n",
    "\n",
    "            mse = F.mse_loss(x_hat_full[1:], x_true[1:]).item()\n",
    "\n",
    "            anees = utils.calculate_anees_vectorized(\n",
    "                x_true[1:].unsqueeze(0),\n",
    "                x_hat_full[1:].unsqueeze(0),\n",
    "                P_hat_full[1:].unsqueeze(0)\n",
    "            )\n",
    "            return mse, anees\n",
    "\n",
    "        mse = F.mse_loss(all_x_hat_classic_knet2_cpu[i][1:], x_true[1:]).item(); mse_classic_knet2.append(mse)\n",
    "        mse, anees = get_metrics(all_x_hat_ukf_ideal_cpu[i], all_P_hat_ukf_ideal_cpu[i]); mse_ukf_ideal.append(mse); anees_ukf_ideal.append(anees)\n",
    "        mse, anees = get_metrics(all_x_hat_pf_sir_ideal_cpu[i], all_P_hat_pf_sir_ideal_cpu[i]); mse_pf_sir_ideal.append(mse); anees_pf_sir_ideal.append(anees)\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(f\"trajectory: {i + 1}/{NUM_TEST_TRAJ}\")\n",
    "        print(\"=\"*80)\n",
    "        print(\"-\" * 80)\n",
    "        print(f\"{'KNet2 (MSE only)':<35} | {(mse_classic_knet2[i]):<20.4f} | {'N/A':<20}\")\n",
    "        print(f\"{'UKF (Ideal model)':<35} | {(mse_ukf_ideal[i]):<20.4f} | {(anees_ukf_ideal[i]):<20.4f}\")\n",
    "        print(f\"{'PF-SIR (Ideal model)':<35} | {(mse_pf_sir_ideal[i]):<20.4f} | {(anees_pf_sir_ideal[i]):<20.4f}\")\n",
    "        print(\"=\"*80)\n",
    "      \n",
    "def avg(metric_list): return np.mean([m for m in metric_list if not np.isnan(m)])\n",
    "state_dim_for_nees = all_x_true_cpu[0].shape[1]\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"FINAL RESULTS (average over {NUM_TEST_TRAJ} runs)\")\n",
    "print(\"=\"*80)\n",
    "print(f\"{'Model':<35} | {'Average MSE':<20} | {'Average ANEES':<20}\")\n",
    "print(\"-\" * 80)\n",
    "print(\"-\" * 80)\n",
    "print(f\"{'--- Model-Based Filters ---':<35} | {'':<20} | {'':<20}\")\n",
    "print(f\"{'KNet2 (MSE only)':<35} | {avg(mse_classic_knet2):<20.4f} | {'N/A':<20}\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"{'--- Benchmarks ---':<35} | {'':<20} | {'':<20}\")\n",
    "print(f\"{'UKF (Ideal model)':<35} | {avg(mse_ukf_ideal):<20.4f} | {avg(anees_ukf_ideal):<20.4f}\")\n",
    "print(f\"{'PF-SIR (Ideal model)':<35} | {avg(mse_pf_sir_ideal):<20.4f} | {avg(anees_pf_sir_ideal):<20.4f}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420d87a1",
   "metadata": {},
   "source": [
    "## Diagnostics on Test Trajectories\n",
    "\n",
    "The variable `index` represents a specific test trajectory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17338b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "map_bounds = {\n",
    "    'x_min': system_model.min_x,\n",
    "    'x_max': system_model.max_x,\n",
    "    'y_min': system_model.min_y,\n",
    "    'y_max': system_model.max_y\n",
    "}\n",
    "\n",
    "index = 0\n",
    "if index < 0: index = 0\n",
    "try:\n",
    "    knet_diagnostics = all_knet_diagnostics_cpu[index]\n",
    "    plot_diagnostics = True\n",
    "except (NameError, IndexError):\n",
    "    print(\"Warning: 'all_knet_diagnostics_cpu' not found or empty. Diagnostic plots (K, h, innovation) will not be rendered.\")\n",
    "    plot_diagnostics = False\n",
    "    plot_gains = False\n",
    "\n",
    "x_true_plot = all_x_true_cpu[index].numpy()\n",
    "x_true_tensor = all_x_true_cpu[index]\n",
    "x_pf_tensor = all_x_hat_pf_sir_ideal_cpu[index]\n",
    "x_knet2_tensor = all_x_hat_classic_knet2_cpu[index]\n",
    "x_knet_tensor = x_knet2_tensor\n",
    "squared_error = (x_knet_tensor - x_true_tensor)**2\n",
    "rmse_per_step = torch.sqrt(squared_error).numpy()\n",
    "\n",
    "num_steps = x_true_plot.shape[0]\n",
    "time_axis = np.arange(num_steps)\n",
    "gain_time_axis = np.arange(1, num_steps)\n",
    "\n",
    "if plot_diagnostics:\n",
    "    try:\n",
    "        kalman_gains_history = knet_diagnostics['K_history']\n",
    "        gains_col0_cpu = [K[0, :, 0].cpu().numpy() for K in kalman_gains_history]\n",
    "        gains_col0_np = np.array(gains_col0_cpu)\n",
    "        plot_gains = True\n",
    "        \n",
    "        if gains_col0_np.shape[0] != len(gain_time_axis):\n",
    "            print(f\"Warning: Gain history length ({gains_col0_np.shape[0]}) does not match time axis ({len(gain_time_axis)}). K gain plot will be skipped.\")\n",
    "            plot_gains = False\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error while processing Kalman gain: {e}. K plots will be skipped.\")\n",
    "        plot_gains = False\n",
    "\n",
    "    try:\n",
    "        h_history = knet_diagnostics['h_history']\n",
    "\n",
    "        h_norms = [torch.norm(h.squeeze(1)).item() for h in h_history]\n",
    "        plot_h_norm = True\n",
    "        \n",
    "        if len(h_norms) != len(time_axis):\n",
    "            print(f\"Warning: Hidden state h history length ({len(h_norms)}) does not match time axis ({len(time_axis)}). h plot will be skipped.\")\n",
    "            plot_h_norm = False\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error while processing hidden state h: {e}. h plot will be skipped.\")\n",
    "        plot_h_norm = False\n",
    "\n",
    "    try:\n",
    "        innovation_history = knet_diagnostics['innovation_history']\n",
    "        innov_norms = [torch.norm(innov.squeeze(0)).item() for innov in innovation_history]\n",
    "        plot_innov_norm = True\n",
    "        \n",
    "        if len(innov_norms) != len(gain_time_axis):\n",
    "            print(f\"Warning: Innovation history length ({len(innov_norms)}) does not match time axis ({len(gain_time_axis)}). Innovation plot will be skipped.\")\n",
    "            plot_innov_norm = False\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error while processing innovation: {e}. Innovation plot will be skipped.\")\n",
    "        plot_innov_norm = False\n",
    "        \n",
    "\n",
    "state_labels = [\n",
    "    'Position X [m]',\n",
    "    'Position Y [m]',\n",
    "    'Velocity vX [m/s]',\n",
    "    'Velocity vY [m/s]'\n",
    "]\n",
    "error_labels = [\n",
    "    'RMSE Position X [m]',\n",
    "    'RMSE Position Y [m]',\n",
    "    'RMSE Velocity vX [m/s]',\n",
    "    'RMSE Velocity vY [m/s]'\n",
    "]\n",
    "gain_labels = [\n",
    "    'K[0,0] (Elevation -> Position X)',\n",
    "    'K[1,0] (Elevation -> Position Y)',\n",
    "    'K[2,0] (Elevation -> Velocity vX)',\n",
    "    'K[3,0] (Elevation -> Velocity vY)'\n",
    "]\n",
    "diagnostic_labels = {\n",
    "    'h_norm': 'L2 Norm of hidden state $h_t$',\n",
    "    'innov_norm': 'L2 Norm of innovation $\\\\Delta y_t$'\n",
    "}\n",
    "\n",
    "fig1, axes1 = plt.subplots(4, 1, figsize=(12, 14), sharex=True)\n",
    "fig1.suptitle(f'Detailed comparison of state estimates over time (Trajectory {index+1})', fontsize=16)\n",
    "\n",
    "fig2, axes2 = plt.subplots(4, 1, figsize=(12, 14), sharex=True)\n",
    "fig2.suptitle(f'RMSE of estimates for individual state components over time (KNet, Traj. {index+1})', fontsize=16)\n",
    "\n",
    "if plot_gains:\n",
    "    fig3, axes3 = plt.subplots(4, 1, figsize=(12, 14), sharex=True)\n",
    "    fig3.suptitle(f'Evolution of the 1st column of Kalman gain KNet over time (Traj. {index+1})', fontsize=16)\n",
    "\n",
    "if plot_diagnostics and plot_h_norm and plot_innov_norm:\n",
    "    fig4, axes4 = plt.subplots(2, 1, figsize=(12, 10), sharex=True)\n",
    "    fig4.suptitle(f'Diagnostics of KNet internal states over time (Traj. {index+1})', fontsize=16)\n",
    "else:\n",
    "    plot_h_norm = False\n",
    "    plot_innov_norm = False\n",
    "\n",
    "for i in range(4):\n",
    "    ax1 = axes1[i]\n",
    "    ax1.plot(time_axis, x_true_plot[:, i], 'r-', linewidth=2.0, label='Reference')\n",
    "    ax1.plot(time_axis, x_knet_tensor[:, i].numpy(), 'g--', linewidth=1.5, label='KNet estimate')\n",
    "    ax1.plot(time_axis, x_pf_tensor[:, i].numpy(), 'm:', linewidth=1.5, label='PF-SIR estimate')\n",
    "    ax1.plot(time_axis, x_knet2_tensor[:, i].numpy(), 'b-.', linewidth=1.5, label='KNet2 estimate')\n",
    "    ax1.set_ylabel(state_labels[i])\n",
    "    ax1.grid(True)\n",
    "    ax1.legend()\n",
    "\n",
    "    if i == 0: \n",
    "        ax1.axhline(map_bounds['x_min'], color='grey', linestyle=':', linewidth=1.5, label='Map boundary X')\n",
    "        ax1.axhline(map_bounds['x_max'], color='grey', linestyle=':', linewidth=1.5)\n",
    "        print(f\"INFO: Adding X boundaries ({map_bounds['x_min']:.2f}, {map_bounds['x_max']:.2f}) to Position X plot.\")\n",
    "    elif i == 1: \n",
    "        ax1.axhline(map_bounds['y_min'], color='grey', linestyle=':', linewidth=1.5, label='Map boundary Y')\n",
    "        ax1.axhline(map_bounds['y_max'], color='grey', linestyle=':', linewidth=1.5)\n",
    "        print(f\"INFO: Adding Y boundaries ({map_bounds['y_min']:.2f}, {map_bounds['y_max']:.2f}) to Position Y plot.\")\n",
    "    \n",
    "    ax2 = axes2[i]\n",
    "    ax2.plot(time_axis, rmse_per_step[:, i], 'b-', linewidth=1.5, label=f'RMSE KNet (Avg: {np.mean(rmse_per_step[1:, i]):.2f})')\n",
    "    ax2.set_ylabel(error_labels[i])\n",
    "    ax2.grid(True)\n",
    "    ax2.legend()\n",
    "\n",
    "    if plot_gains:\n",
    "         ax3 = axes3[i]\n",
    "         ax3.plot(gain_time_axis, gains_col0_np[:, i], 'k-', linewidth=1.5, label=f'{gain_labels[i]} (Avg: {np.mean(gains_col0_np[:, i]):.4f})')\n",
    "         ax3.set_ylabel(gain_labels[i])\n",
    "         ax3.grid(True)\n",
    "         ax3.legend()\n",
    "\n",
    "if plot_h_norm:\n",
    "    ax4_h = axes4[0]\n",
    "    ax4_h.plot(time_axis, h_norms, 'darkorange', linewidth=1.5, label='Norm $h_t$')\n",
    "    ax4_h.set_ylabel(diagnostic_labels['h_norm'])\n",
    "    ax4_h.grid(True)\n",
    "    ax4_h.legend()\n",
    "    ax4_h.set_yscale('log')\n",
    "\n",
    "if plot_innov_norm:\n",
    "    ax4_innov = axes4[1]\n",
    "    ax4_innov.plot(gain_time_axis, innov_norms, 'purple', linewidth=1.5, label='Norm $\\\\Delta y_t$')\n",
    "    ax4_innov.set_ylabel(diagnostic_labels['innov_norm'])\n",
    "    ax4_innov.set_xlabel('Time step [s]')\n",
    "    ax4_innov.grid(True)\n",
    "    ax4_innov.legend()\n",
    "    ax4_innov.set_yscale('log')\n",
    "\n",
    "axes1[-1].set_xlabel('Time step [s]')\n",
    "axes2[-1].set_xlabel('Time step [s]')\n",
    "if plot_gains:\n",
    "    axes3[-1].set_xlabel('Time step [s]')\n",
    "\n",
    "fig1.tight_layout(rect=[0, 0.03, 1, 0.96])\n",
    "fig2.tight_layout(rect=[0, 0.03, 1, 0.96])\n",
    "if plot_gains:\n",
    "    fig3.tight_layout(rect=[0, 0.03, 1, 0.96])\n",
    "if plot_h_norm or plot_innov_norm:\n",
    "    fig4.tight_layout(rect=[0, 0.03, 1, 0.96])\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
