{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24e3857",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from scipy.io import loadmat\n",
    "import sys\n",
    "import os\n",
    "\n",
    "\n",
    "dataset_path = Path('data') / 'data.mat'\n",
    "if not dataset_path.exists():\n",
    "    alt = Path.cwd().parent / 'data' / 'data.mat'\n",
    "    if alt.exists():\n",
    "        dataset_path = alt\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"data.mat not found under {Path.cwd()} or its parent\")\n",
    "\n",
    "notebook_path = os.getcwd() \n",
    "print (f\"Current notebook path: {notebook_path}\")\n",
    "project_root = os.path.dirname(notebook_path)\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "print (f\"Added {project_root} to sys.path\")\n",
    "\n",
    "mat_data = loadmat(dataset_path)\n",
    "print(mat_data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47109e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import trainer\n",
    "from utils import utils\n",
    "from Systems import DynamicSystem\n",
    "import Filters\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "from scipy.interpolate import RegularGridInterpolator\n",
    "import random\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d8be52",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_data = loadmat(dataset_path)\n",
    "\n",
    "souradniceX_mapa = mat_data['souradniceX']\n",
    "souradniceY_mapa = mat_data['souradniceY']\n",
    "souradniceZ_mapa = mat_data['souradniceZ']\n",
    "souradniceGNSS = mat_data['souradniceGNSS'] \n",
    "x_axis_unique = souradniceX_mapa[0, :]\n",
    "y_axis_unique = souradniceY_mapa[:, 0]\n",
    "\n",
    "print(f\"Dimensions of 1D X axis: {x_axis_unique.shape}\")\n",
    "print(f\"Dimensions of 1D Y axis: {y_axis_unique.shape}\")\n",
    "print(f\"Dimensions of 2D elevation data Z: {souradniceZ_mapa.shape}\")\n",
    "\n",
    "terMap_interpolator = RegularGridInterpolator(\n",
    "    (y_axis_unique, x_axis_unique),\n",
    "    souradniceZ_mapa,\n",
    "    bounds_error=False, \n",
    "    fill_value=np.nan\n",
    ")\n",
    "\n",
    "def terMap(px, py):\n",
    "    # Query bilinear interpolation over the terrain map\n",
    "    points_to_query = np.column_stack((py, px))\n",
    "    return terMap_interpolator(points_to_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1e91fb",
   "metadata": {},
   "source": [
    "## Model Description\n",
    "\n",
    "This section defines the dynamic system and the measurement model used in experiments:\n",
    "- State: position and velocity components in 2D.\n",
    "- Process model: constant-velocity with Gaussian process noise.\n",
    "- Measurement model: terrain-based elevation reading via interpolated map at the current position.\n",
    "\n",
    "Note: Coordinates are used in the original map reference frame (no shift)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f225b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from Systems import DynamicSystemTAN\n",
    "\n",
    "state_dim = 4\n",
    "obs_dim = 3\n",
    "dT = 1\n",
    "q = 1\n",
    "\n",
    "F = torch.tensor([[1.0, 0.0, dT, 0.0],\n",
    "                   [0.0, 1.0, 0.0, dT],\n",
    "                   [0.0, 0.0, 1.0, 0.0],\n",
    "                   [0.0, 0.0, 0.0, 1.0]])\n",
    "\n",
    "Q = q* torch.tensor([[dT**3/3, 0.0, dT**2/2, 0.0],\n",
    "                   [0.0, dT**3/3, 0.0, dT**2/2],\n",
    "                   [dT**2/2, 0.0, dT, 0.0],\n",
    "                   [0.0, dT**2/2, 0.0, dT]])\n",
    "R = torch.tensor([[3.0**2, 0.0, 0.0],\n",
    "                   [0.0, 1.0**2, 0.0],\n",
    "                   [0.0, 0.0, 1.0**2]])\n",
    "\n",
    "initial_velocity_np = souradniceGNSS[:2, 1] - souradniceGNSS[:2, 0]\n",
    "initial_velocity = torch.from_numpy(initial_velocity_np)\n",
    "\n",
    "initial_position = torch.from_numpy(souradniceGNSS[:2, 0])\n",
    "x_0 = torch.cat([\n",
    "    initial_position,\n",
    "    initial_velocity\n",
    "]).float()\n",
    "print(x_0)\n",
    "\n",
    "P_0 = torch.tensor([[25.0, 0.0, 0.0, 0.0],\n",
    "                    [0.0, 25.0, 0.0, 0.0],\n",
    "                    [0.0, 0.0, 0.5, 0.0],\n",
    "                    [0.0, 0.0, 0.0, 0.5]])\n",
    "import torch.nn.functional as func\n",
    "\n",
    "def h_nl_differentiable(x: torch.Tensor, map_tensor, x_min, x_max, y_min, y_max) -> torch.Tensor:\n",
    "    batch_size = x.shape[0]\n",
    "\n",
    "    px = x[:, 0]\n",
    "    py = x[:, 1]\n",
    "\n",
    "    px_norm = 2.0 * (px - x_min) / (x_max - x_min) - 1.0\n",
    "    py_norm = 2.0 * (py - y_min) / (y_max - y_min) - 1.0\n",
    "\n",
    "    sampling_grid = torch.stack((px_norm, py_norm), dim=1).view(batch_size, 1, 1, 2)\n",
    "\n",
    "    vyska_terenu_batch = func.grid_sample(\n",
    "        map_tensor.expand(batch_size, -1, -1, -1),\n",
    "        sampling_grid, \n",
    "        mode='bilinear', \n",
    "        padding_mode='border',\n",
    "        align_corners=True\n",
    "    )\n",
    "\n",
    "    vyska_terenu = vyska_terenu_batch.view(batch_size)\n",
    "\n",
    "    eps = 1e-12\n",
    "    vx_w, vy_w = x[:, 2], x[:, 3]\n",
    "    norm_v_w = torch.sqrt(vx_w**2 + vy_w**2).clamp(min=eps)\n",
    "    cos_psi = vx_w / norm_v_w\n",
    "    sin_psi = vy_w / norm_v_w\n",
    "\n",
    "    vx_b = cos_psi * vx_w - sin_psi * vy_w \n",
    "    vy_b = sin_psi * vx_w + cos_psi * vy_w\n",
    "\n",
    "    result = torch.stack([vyska_terenu, vx_b, vy_b], dim=1)\n",
    "\n",
    "    return result\n",
    "\n",
    "x_axis_unique = souradniceX_mapa[0, :]\n",
    "y_axis_unique = souradniceY_mapa[:, 0]\n",
    "terMap_tensor = torch.from_numpy(souradniceZ_mapa).float().unsqueeze(0).unsqueeze(0).to(device)\n",
    "x_min, x_max = x_axis_unique.min(), x_axis_unique.max()\n",
    "y_min, y_max = y_axis_unique.min(), y_axis_unique.max()\n",
    "\n",
    "h_wrapper = lambda x: h_nl_differentiable(\n",
    "    x, \n",
    "    map_tensor=terMap_tensor, \n",
    "    x_min=x_min, \n",
    "    x_max=x_max, \n",
    "    y_min=y_min, \n",
    "    y_max=y_max\n",
    ")\n",
    "\n",
    "system_model = DynamicSystemTAN(\n",
    "    state_dim=state_dim,\n",
    "    obs_dim=obs_dim,\n",
    "    Q=Q.float(),\n",
    "    R=R.float(),\n",
    "    Ex0=x_0.float(),\n",
    "    P0=P_0.float(),\n",
    "    F=F.float(),\n",
    "    h=h_wrapper,\n",
    "    x_axis_unique=x_axis_unique, \n",
    "    y_axis_unique=y_axis_unique,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e34191",
   "metadata": {},
   "source": [
    "## Data Generation\n",
    "\n",
    "We generate synthetic trajectories and corresponding measurements:\n",
    "- Number of trajectories and sequence length are configurable.\n",
    "- Initial state either set to zero or sampled from `Ex0`.\n",
    "- Measurements are obtained by sampling the elevation map at the trajectory positions.\n",
    "\n",
    "All prints and comments in the following code are translated to English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88fb331",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from utils import utils\n",
    "\n",
    "TRAIN_SEQ_LEN = 50\n",
    "VALID_SEQ_LEN = 600\n",
    "\n",
    "NUM_TRAIN_TRAJECTORIES = 500 \n",
    "NUM_VALID_TRAJECTORIES = 50 \n",
    "BATCH_SIZE = 256\n",
    "\n",
    "system_model.min_x = x_axis_unique.min()\n",
    "system_model.max_x = x_axis_unique.max()\n",
    "system_model.min_y = y_axis_unique.min()\n",
    "system_model.max_y = y_axis_unique.max()\n",
    "system_model.device = device \n",
    "\n",
    "system_model.Ex0 = torch.tensor([(system_model.min_x+system_model.max_x)/2, (system_model.min_y+system_model.max_y)/2, 0.0, 0.0]).float().to(device)\n",
    "\n",
    "\n",
    "x_train, y_train = utils.generate_data_for_map(\n",
    "    system_model, \n",
    "    num_trajectories=NUM_TRAIN_TRAJECTORIES, \n",
    "    seq_len=TRAIN_SEQ_LEN,\n",
    "    force_initial_state_zero=False\n",
    ")\n",
    "\n",
    "x_val, y_val = utils.generate_data_for_map(\n",
    "    system_model, \n",
    "    num_trajectories=NUM_VALID_TRAJECTORIES, \n",
    "    seq_len=VALID_SEQ_LEN,\n",
    "    force_initial_state_zero=False\n",
    ")\n",
    "\n",
    "train_dataset = TensorDataset(x_train, y_train)\n",
    "val_dataset = TensorDataset(x_val, y_val)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee15f67",
   "metadata": {},
   "source": [
    "## Trajectory and Measurement Visualization\n",
    "\n",
    "We plot sample trajectories and overlay measurement/elevation information:\n",
    "- 2D position plots with map boundaries.\n",
    "- Optional 3D surface or contour views of elevation.\n",
    "- Legends and axis labels provided in English for clarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ff8eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_trajectories(x_data, title=\"Trajectories\", num_to_plot=None):\n",
    "    x_np = x_data.detach().cpu().numpy()\n",
    "    \n",
    "    total_traj = x_np.shape[0]\n",
    "    \n",
    "    if num_to_plot is not None and num_to_plot < total_traj:\n",
    "        indices = np.random.choice(total_traj, num_to_plot, replace=False)\n",
    "    else:\n",
    "        indices = range(total_traj)\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    for i in indices:\n",
    "        pos_x = x_np[i, :, 0]\n",
    "        pos_y = x_np[i, :, 1]\n",
    "        \n",
    "        plt.plot(pos_x, pos_y, alpha=0.5, linewidth=1)\n",
    "        \n",
    "        plt.plot(pos_x[0], pos_y[0], 'go', markersize=3, label='Start' if i == indices[0] else \"\")\n",
    "        plt.plot(pos_x[-1], pos_y[-1], 'ro', markersize=3, label='End' if i == indices[0] else \"\")\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Position X [m]\")\n",
    "    plt.ylabel(\"Position Y [m]\")\n",
    "    plt.grid(True)\n",
    "    plt.axis('equal')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "plot_trajectories(x_train, title=\"All training trajectories\", num_to_plot=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accc2cc4",
   "metadata": {},
   "source": [
    "## Training Setup\n",
    "\n",
    "We train the KalmanNet-based model (`KNet2`) on generated sequences:\n",
    "- Optimizer and learning rate configured in the next cell.\n",
    "- Training runs for a fixed number of epochs with validation splits as needed.\n",
    "- Loss function: Mean Squared Error (MSE) between filtered state estimates and ground-truth states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d101fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from copy import deepcopy\n",
    "from state_NN_models import StateKalmanNet \n",
    "from state_NN_models import StateKalmanNet_arch2\n",
    "from utils import trainer \n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "if False:\n",
    "    # Use architecture 2: model with 3 distinct GRU layers\n",
    "    state_knet2 = StateKalmanNet_arch2(\n",
    "        system_model=system_model, \n",
    "        device=device,\n",
    "        hidden_size_multiplier=12,\n",
    "        output_layer_multiplier=4\n",
    "        ).to(device)\n",
    "else:\n",
    "    # Use architecture 1: model with a single GRU layer\n",
    "    state_knet2 = StateKalmanNet(\n",
    "        system_model=system_model, \n",
    "        device=device,\n",
    "        hidden_size_multiplier=12,\n",
    "        output_layer_multiplier=4,\n",
    "        num_gru_layers=2,\n",
    "        gru_hidden_dim_multiplier=10\n",
    "        ).to(device)\n",
    "\n",
    "print(state_knet2)\n",
    "\n",
    "trained_model = trainer.train_state_KalmanNet_sliding_window(\n",
    "    model=state_knet2,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    device=device,\n",
    "    epochs=500,\n",
    "    lr=1e-3,\n",
    "    clip_grad=10.0,\n",
    "    early_stopping_patience=200,\n",
    "    tbptt_k=2,\n",
    "    tbptt_w=50,\n",
    "    optimizer_=torch.optim.AdamW,\n",
    "    weight_decay_=1e-5,\n",
    "\n",
    ")\n",
    "print(trained_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b363c4",
   "metadata": {},
   "source": [
    "## Testing and Evaluation\n",
    "\n",
    "We evaluate trained and baseline models on held-out test trajectories:\n",
    "- Metrics: MSE for all, ANEES for model-based filters (when covariance available).\n",
    "- We report per-trajectory results and final averages across runs.\n",
    "- Diagnostic plots are included in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717ecbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "\n",
    "TEST_SEQ_LEN = 600 \n",
    "NUM_TEST_TRAJ = 5\n",
    "\n",
    "print(f\"\\nGenerating {NUM_TEST_TRAJ} test trajectories of length {TEST_SEQ_LEN}...\")\n",
    "\n",
    "x_test, y_test = utils.generate_data_for_map(\n",
    "    system_model, \n",
    "    num_trajectories=NUM_TEST_TRAJ,\n",
    "    seq_len=TEST_SEQ_LEN,\n",
    "    force_initial_state_zero=False\n",
    ")\n",
    "\n",
    "test_dataset = TensorDataset(x_test, y_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "print(\"Data generation complete.\")\n",
    "\n",
    "print(\"y shape:\", y_test.shape)  # Should be [N, T, obs_dim]\n",
    "print(\"x shape:\", x_test.shape)  # Should be [N, T, state_dim]\n",
    "\n",
    "ukf_ideal = Filters.UnscentedKalmanFilter(system_model)\n",
    "pf_sir_ideal = Filters.ParticleFilter(system_model, num_particles=2000)\n",
    "\n",
    "all_x_true_cpu = []\n",
    "all_x_hat_ukf_ideal_cpu, all_P_hat_ukf_ideal_cpu = [], []\n",
    "all_x_hat_pf_sir_ideal_cpu, all_P_hat_pf_sir_ideal_cpu = [], []\n",
    "all_x_hat_classic_knet2_cpu = []\n",
    "\n",
    "all_knet_diagnostics_cpu = []\n",
    "print(f\"\\nEvaluating models on {NUM_TEST_TRAJ} test trajectories...\")\n",
    "\n",
    "state_knet2.eval()\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (x_true_seq_batch, y_test_seq_batch) in enumerate(test_loader):\n",
    "        y_test_seq_gpu = y_test_seq_batch.squeeze(0).to(device)\n",
    "        x_true_seq_gpu = x_true_seq_batch.squeeze(0).to(device)\n",
    "        initial_state = x_true_seq_gpu[0, :].unsqueeze(0)\n",
    "        state_knet2.reset(batch_size=1, initial_state=initial_state)\n",
    "        classic_knet2_preds = []\n",
    "        for t in range(1, TEST_SEQ_LEN):\n",
    "            x_filtered_t = state_knet2.step(y_test_seq_gpu[t, :].unsqueeze(0))\n",
    "            classic_knet2_preds.append(x_filtered_t)\n",
    "        full_x_hat_classic_knet2 = torch.cat([initial_state, torch.cat(classic_knet2_preds, dim=0)], dim=0)\n",
    "        ukf_i_res = ukf_ideal.process_sequence(\n",
    "            y_seq=y_test_seq_gpu,\n",
    "            Ex0=system_model.Ex0, \n",
    "            P0=system_model.P0\n",
    "        )\n",
    "        full_x_hat_ukf_i = ukf_i_res['x_filtered']\n",
    "        full_P_hat_ukf_i = ukf_i_res['P_filtered']\n",
    "\n",
    "        pf_sir_i_res = pf_sir_ideal.process_sequence(y_test_seq_gpu, Ex0=system_model.Ex0,P0=system_model.P0)\n",
    "        full_x_hat_pf_sir_i = pf_sir_i_res['x_filtered']\n",
    "        full_P_hat_pf_sir_i = pf_sir_i_res['P_filtered']\n",
    "        full_particles_history_pf_sir_i = pf_sir_i_res['particles_history']\n",
    "        print(f\"PF-SIR (ideal model) finished for trajectory {i + 1}/{NUM_TEST_TRAJ}.\")\n",
    "\n",
    "        all_x_true_cpu.append(x_true_seq_gpu.cpu())\n",
    "        all_x_hat_classic_knet2_cpu.append(full_x_hat_classic_knet2.cpu())\n",
    "        all_x_hat_ukf_ideal_cpu.append(full_x_hat_ukf_i.cpu()); all_P_hat_ukf_ideal_cpu.append(full_P_hat_ukf_i.cpu())\n",
    "        all_x_hat_pf_sir_ideal_cpu.append(full_x_hat_pf_sir_i.cpu()); all_P_hat_pf_sir_ideal_cpu.append(full_P_hat_pf_sir_i.cpu())\n",
    "        print(f\"Completed trajectory {i + 1}/{NUM_TEST_TRAJ}...\")\n",
    "\n",
    "mse_ukf_ideal, anees_ukf_ideal = [], []\n",
    "\n",
    "mse_pf_sir_ideal, anees_pf_sir_ideal = [], []\n",
    "mse_classic_knet2 = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(NUM_TEST_TRAJ):\n",
    "        x_true = all_x_true_cpu[i]\n",
    "        def get_metrics(x_hat_full, P_hat_full):\n",
    "            if x_hat_full.shape[0] != x_true.shape[0] or P_hat_full.shape[0] != x_true.shape[0]:\n",
    "                 raise ValueError(f\"Length mismatch! x_true: {x_true.shape[0]}, x_hat: {x_hat_full.shape[0]}, P_hat: {P_hat_full.shape[0]}\")\n",
    "\n",
    "            mse = F.mse_loss(x_hat_full[1:], x_true[1:]).item()\n",
    "\n",
    "            anees = utils.calculate_anees_vectorized(\n",
    "                x_true[1:].unsqueeze(0),\n",
    "                x_hat_full[1:].unsqueeze(0),\n",
    "                P_hat_full[1:].unsqueeze(0)\n",
    "            )\n",
    "            return mse, anees\n",
    "\n",
    "        mse = F.mse_loss(all_x_hat_classic_knet2_cpu[i][1:], x_true[1:]).item(); mse_classic_knet2.append(mse)\n",
    "        mse, anees = get_metrics(all_x_hat_ukf_ideal_cpu[i], all_P_hat_ukf_ideal_cpu[i]); mse_ukf_ideal.append(mse); anees_ukf_ideal.append(anees)\n",
    "        mse, anees = get_metrics(all_x_hat_pf_sir_ideal_cpu[i], all_P_hat_pf_sir_ideal_cpu[i]); mse_pf_sir_ideal.append(mse); anees_pf_sir_ideal.append(anees)\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(f\"trajectory: {i + 1}/{NUM_TEST_TRAJ}\")\n",
    "        print(\"=\"*80)\n",
    "        print(\"-\" * 80)\n",
    "        print(f\"{'KNet2 (MSE only)':<35} | {(mse_classic_knet2[i]):<20.4f} | {'N/A':<20}\")\n",
    "        print(f\"{'UKF (Ideal model)':<35} | {(mse_ukf_ideal[i]):<20.4f} | {(anees_ukf_ideal[i]):<20.4f}\")\n",
    "        print(f\"{'PF-SIR (Ideal model)':<35} | {(mse_pf_sir_ideal[i]):<20.4f} | {(anees_pf_sir_ideal[i]):<20.4f}\")\n",
    "        print(\"=\"*80)\n",
    "      \n",
    "def avg(metric_list): return np.mean([m for m in metric_list if not np.isnan(m)])\n",
    "state_dim_for_nees = all_x_true_cpu[0].shape[1]\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"FINAL RESULTS (average over {NUM_TEST_TRAJ} runs)\")\n",
    "print(\"=\"*80)\n",
    "print(f\"{'Model':<35} | {'Average MSE':<20} | {'Average ANEES':<20}\")\n",
    "print(\"-\" * 80)\n",
    "print(\"-\" * 80)\n",
    "print(f\"{'--- Model-Based Filters ---':<35} | {'':<20} | {'':<20}\")\n",
    "print(f\"{'KNet2 (MSE only)':<35} | {avg(mse_classic_knet2):<20.4f} | {'N/A':<20}\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"{'--- Benchmarks ---':<35} | {'':<20} | {'':<20}\")\n",
    "print(f\"{'UKF (Ideal model)':<35} | {avg(mse_ukf_ideal):<20.4f} | {avg(anees_ukf_ideal):<20.4f}\")\n",
    "print(f\"{'PF-SIR (Ideal model)':<35} | {avg(mse_pf_sir_ideal):<20.4f} | {avg(anees_pf_sir_ideal):<20.4f}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53854c3",
   "metadata": {},
   "source": [
    "## Diagnostics and Plots\n",
    "\n",
    "This section visualizes filter estimates, uncertainties, and particle distributions:\n",
    "- Position/velocity comparisons between ground truth and estimates.\n",
    "- Covariance-derived uncertainty bands where applicable.\n",
    "- Particle filter scatter/heatmaps for intuition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17338b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "map_bounds = {\n",
    "    'x_min': 1476611.42,\n",
    "    'x_max': 1489541.47,\n",
    "    'y_min': 6384032.63,\n",
    "    'y_max': 6400441.34\n",
    "}\n",
    "\n",
    "index = 1\n",
    "if index < 0: index = 0\n",
    "try:\n",
    "    knet_diagnostics = all_knet_diagnostics_cpu[index]\n",
    "    plot_diagnostics = True\n",
    "except (NameError, IndexError):\n",
    "    plot_diagnostics = False\n",
    "    plot_gains = False\n",
    "\n",
    "x_true_plot = all_x_true_cpu[index].numpy()\n",
    "x_true_tensor = all_x_true_cpu[index]\n",
    "x_pf_tensor = all_x_hat_pf_sir_ideal_cpu[index]\n",
    "x_knet2_tensor = all_x_hat_classic_knet2_cpu[index]\n",
    "x_knet_tensor = x_knet2_tensor\n",
    "squared_error = (x_knet_tensor - x_true_tensor)**2\n",
    "rmse_per_step = torch.sqrt(squared_error).numpy()\n",
    "\n",
    "num_steps = x_true_plot.shape[0]\n",
    "time_axis = np.arange(num_steps)\n",
    "gain_time_axis = np.arange(1, num_steps)\n",
    "\n",
    "if plot_diagnostics:\n",
    "    try:\n",
    "        kalman_gains_history = knet_diagnostics['K_history']\n",
    "        gains_col0_cpu = [K[0, :, 0].cpu().numpy() for K in kalman_gains_history] \n",
    "        gains_col0_np = np.array(gains_col0_cpu)\n",
    "        plot_gains = True\n",
    "        \n",
    "        if gains_col0_np.shape[0] != len(gain_time_axis):\n",
    "            plot_gains = False\n",
    "            \n",
    "    except Exception as e:\n",
    "        plot_gains = False\n",
    "\n",
    "    try:\n",
    "        h_history = knet_diagnostics['h_history']\n",
    "\n",
    "        h_norms = [torch.norm(h.squeeze(1)).item() for h in h_history] \n",
    "        plot_h_norm = True\n",
    "        \n",
    "        if len(h_norms) != len(time_axis):\n",
    "            plot_h_norm = False\n",
    "            \n",
    "    except Exception as e:\n",
    "        plot_h_norm = False\n",
    "\n",
    "    try:\n",
    "        innovation_history = knet_diagnostics['innovation_history']\n",
    "        innov_norms = [torch.norm(innov.squeeze(0)).item() for innov in innovation_history] \n",
    "        plot_innov_norm = True\n",
    "        \n",
    "        if len(innov_norms) != len(gain_time_axis):\n",
    "            plot_innov_norm = False\n",
    "            \n",
    "    except Exception as e:\n",
    "        plot_innov_norm = False\n",
    "        \n",
    "\n",
    "state_labels = [\n",
    "    'Position X [m]',\n",
    "    'Position Y [m]',\n",
    "    'Velocity vX [m/s]',\n",
    "    'Velocity vY [m/s]'\n",
    "]\n",
    "error_labels = [\n",
    "    'RMSE Position X [m]',\n",
    "    'RMSE Position Y [m]',\n",
    "    'RMSE Velocity vX [m/s]',\n",
    "    'RMSE Velocity vY [m/s]'\n",
    "]\n",
    "gain_labels = [\n",
    "    'K[0,0] (height -> Position X)',\n",
    "    'K[1,0] (height -> Position Y)',\n",
    "    'K[2,0] (height -> Velocity vX)',\n",
    "    'K[3,0] (height -> Velocity vY)'\n",
    "]\n",
    "diagnostic_labels = {\n",
    "    'h_norm': 'L2 Norm $h_t$',\n",
    "    'innov_norm': 'L2 Norm $\\Delta y_t$'\n",
    "}\n",
    "\n",
    "\n",
    "fig1, axes1 = plt.subplots(4, 1, figsize=(12, 14), sharex=True)\n",
    "\n",
    "\n",
    "fig2, axes2 = plt.subplots(4, 1, figsize=(12, 14), sharex=True)\n",
    "\n",
    "\n",
    "if plot_gains:\n",
    "    fig3, axes3 = plt.subplots(4, 1, figsize=(12, 14), sharex=True)\n",
    "\n",
    "if plot_diagnostics and plot_h_norm and plot_innov_norm:\n",
    "    fig4, axes4 = plt.subplots(2, 1, figsize=(12, 10), sharex=True)\n",
    "else:\n",
    "    plot_h_norm = False\n",
    "    plot_innov_norm = False\n",
    "\n",
    "\n",
    "\n",
    "for i in range(4):\n",
    "    ax1 = axes1[i]\n",
    "    ax1.plot(time_axis, x_true_plot[:, i], 'r-', linewidth=2.0, label='Reference value')\n",
    "    ax1.plot(time_axis, x_knet_tensor[:, i].numpy(), 'g--', linewidth=1.5, label='KNet estimate')\n",
    "    ax1.plot(time_axis, x_pf_tensor[:, i].numpy(), 'm:', linewidth=1.5, label='PF-SIR estimate')\n",
    "    ax1.plot(time_axis, x_knet2_tensor[:, i].numpy(), 'b-.', linewidth=1.5, label='KNet2 estimate')\n",
    "    ax1.set_ylabel(state_labels[i])\n",
    "    ax1.grid(True)\n",
    "    ax1.legend()\n",
    "\n",
    "    if i == 0: \n",
    "        ax1.axhline(map_bounds['x_min'], color='grey', linestyle=':', linewidth=1.5, label='Map boundary X')\n",
    "        ax1.axhline(map_bounds['x_max'], color='grey', linestyle=':', linewidth=1.5)\n",
    "    elif i == 1: \n",
    "        ax1.axhline(map_bounds['y_min'], color='grey', linestyle=':', linewidth=1.5, label='Map boundary Y')\n",
    "        ax1.axhline(map_bounds['y_max'], color='grey', linestyle=':', linewidth=1.5)\n",
    "    \n",
    "    ax2 = axes2[i]\n",
    "    ax2.plot(time_axis, rmse_per_step[:, i], 'b-', linewidth=1.5, label=f'RMSE KNet (Avg: {np.mean(rmse_per_step[1:, i]):.2f})')\n",
    "    ax2.set_ylabel(error_labels[i])\n",
    "    ax2.grid(True)\n",
    "    ax2.legend()\n",
    "\n",
    "    if plot_gains:\n",
    "         ax3 = axes3[i]\n",
    "         ax3.plot(gain_time_axis, gains_col0_np[:, i], 'k-', linewidth=1.5, label=f'{gain_labels[i]} (Avg: {np.mean(gains_col0_np[:, i]):.4f})')\n",
    "         ax3.set_ylabel(gain_labels[i])\n",
    "         ax3.grid(True)\n",
    "         ax3.legend()\n",
    "\n",
    "if plot_h_norm:\n",
    "    ax4_h = axes4[0]\n",
    "    ax4_h.plot(time_axis, h_norms, 'darkorange', linewidth=1.5, label=f'Norma $h_t$')\n",
    "    ax4_h.set_ylabel(diagnostic_labels['h_norm'])\n",
    "    ax4_h.grid(True)\n",
    "    ax4_h.legend()\n",
    "    ax4_h.set_yscale('log') \n",
    "\n",
    "if plot_innov_norm:\n",
    "    ax4_innov = axes4[1]\n",
    "    ax4_innov.plot(gain_time_axis, innov_norms, 'purple', linewidth=1.5, label=f'Norm $\\Delta y_t$')\n",
    "    ax4_innov.set_ylabel(diagnostic_labels['innov_norm'])\n",
    "    ax4_innov.set_xlabel('Time step [s]')\n",
    "    ax4_innov.grid(True)\n",
    "    ax4_innov.legend()\n",
    "    ax4_innov.set_yscale('log')\n",
    "\n",
    "axes1[-1].set_xlabel('Time step [s]')\n",
    "axes2[-1].set_xlabel('Time step [s]')\n",
    "if plot_gains:\n",
    "    axes3[-1].set_xlabel('Time step [s]')\n",
    "\n",
    "fig1.tight_layout(rect=[0, 0.03, 1, 0.96])\n",
    "fig2.tight_layout(rect=[0, 0.03, 1, 0.96])\n",
    "if plot_gains:\n",
    "    fig3.tight_layout(rect=[0, 0.03, 1, 0.96])\n",
    "if plot_h_norm or plot_innov_norm:\n",
    "    fig4.tight_layout(rect=[0, 0.03, 1, 0.96])\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
