{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15959426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset path: /home/luky/skola/KalmanNet-main/data/data.mat\n",
      "Project root added: /home/luky/skola/KalmanNet-main\n",
      "dict_keys(['__header__', '__version__', '__globals__', 'hB', 'souradniceGNSS', 'souradniceX', 'souradniceY', 'souradniceZ'])\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from scipy.io import loadmat\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Robust path finding for data.mat\n",
    "current_path = Path.cwd()\n",
    "possible_data_paths = [\n",
    "    current_path / 'data' / 'data.mat',\n",
    "    current_path.parent / 'data' / 'data.mat',\n",
    "    current_path.parent.parent / 'data' / 'data.mat',\n",
    "    # Fallback absolute path\n",
    "    Path('/home/luky/skola/KalmanNet-for-state-estimation/data/data.mat')\n",
    "]\n",
    "\n",
    "dataset_path = None\n",
    "for p in possible_data_paths:\n",
    "    if p.exists():\n",
    "        dataset_path = p\n",
    "        break\n",
    "\n",
    "if dataset_path is None or not dataset_path.exists():\n",
    "    print(\"Warning: data.mat not found automatically.\")\n",
    "    dataset_path = Path('data/data.mat')\n",
    "\n",
    "print(f\"Dataset path: {dataset_path}\")\n",
    "\n",
    "# Add project root to sys.path (2 levels up from debug/test)\n",
    "notebook_dir = os.getcwd()\n",
    "project_root = os.path.abspath(os.path.join(notebook_dir, '..', '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "print(f\"Project root added: {project_root}\")\n",
    "\n",
    "mat_data = loadmat(dataset_path)\n",
    "print(mat_data.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94742705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import trainer\n",
    "from utils import utils\n",
    "from Systems import DynamicSystem\n",
    "import Filters\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "from scipy.interpolate import RegularGridInterpolator\n",
    "import random\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51f00243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of 1D X axis: (2500,)\n",
      "Dimensions of 1D Y axis: (2500,)\n",
      "Dimensions of 2D elevation data Z: (2500, 2500)\n"
     ]
    }
   ],
   "source": [
    "mat_data = loadmat(dataset_path)\n",
    "\n",
    "souradniceX_mapa = mat_data['souradniceX']\n",
    "souradniceY_mapa = mat_data['souradniceY']\n",
    "souradniceZ_mapa = mat_data['souradniceZ']\n",
    "souradniceGNSS = mat_data['souradniceGNSS'] \n",
    "x_axis_unique = souradniceX_mapa[0, :]\n",
    "y_axis_unique = souradniceY_mapa[:, 0]\n",
    "\n",
    "print(f\"Dimensions of 1D X axis: {x_axis_unique.shape}\")\n",
    "print(f\"Dimensions of 1D Y axis: {y_axis_unique.shape}\")\n",
    "print(f\"Dimensions of 2D elevation data Z: {souradniceZ_mapa.shape}\")\n",
    "\n",
    "terMap_interpolator = RegularGridInterpolator(\n",
    "    (y_axis_unique, x_axis_unique),\n",
    "    souradniceZ_mapa,\n",
    "    bounds_error=False, \n",
    "    fill_value=np.nan\n",
    ")\n",
    "\n",
    "def terMap(px, py):\n",
    "    # Query bilinear interpolation over the terrain map\n",
    "    points_to_query = np.column_stack((py, px))\n",
    "    return terMap_interpolator(points_to_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2c2c2b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1487547.1250, 6395520.5000,       0.0000,       0.0000])\n",
      "INFO: DynamicSystemTAN inicializov√°n s hranicemi mapy:\n",
      "  X: [1476611.42, 1489541.47]\n",
      "  Y: [6384032.63, 6400441.34]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from Systems import DynamicSystemTAN\n",
    "\n",
    "state_dim = 4\n",
    "obs_dim = 3\n",
    "dT = 1\n",
    "q = 1\n",
    "\n",
    "F = torch.tensor([[1.0, 0.0, dT, 0.0],\n",
    "                   [0.0, 1.0, 0.0, dT],\n",
    "                   [0.0, 0.0, 1.0, 0.0],\n",
    "                   [0.0, 0.0, 0.0, 1.0]])\n",
    "\n",
    "Q = q* torch.tensor([[dT**3/3, 0.0, dT**2/2, 0.0],\n",
    "                   [0.0, dT**3/3, 0.0, dT**2/2],\n",
    "                   [dT**2/2, 0.0, dT, 0.0],\n",
    "                   [0.0, dT**2/2, 0.0, dT]])\n",
    "R = torch.tensor([[3.0**2, 0.0, 0.0],\n",
    "                   [0.0, 1.0**2, 0.0],\n",
    "                   [0.0, 0.0, 1.0**2]])\n",
    "\n",
    "initial_velocity_np = souradniceGNSS[:2, 1] - souradniceGNSS[:2, 0]\n",
    "# initial_velocity_np = torch.from_numpy()\n",
    "initial_velocity = torch.from_numpy(np.array([0,0]))\n",
    "\n",
    "initial_position = torch.from_numpy(souradniceGNSS[:2, 0])\n",
    "x_0 = torch.cat([\n",
    "    initial_position,\n",
    "    initial_velocity\n",
    "]).float()\n",
    "print(x_0)\n",
    "\n",
    "P_0 = torch.tensor([[25.0, 0.0, 0.0, 0.0],\n",
    "                    [0.0, 25.0, 0.0, 0.0],\n",
    "                    [0.0, 0.0, 0.5, 0.0],\n",
    "                    [0.0, 0.0, 0.0, 0.5]])\n",
    "import torch.nn.functional as func\n",
    "\n",
    "def h_nl_differentiable(x: torch.Tensor, map_tensor, x_min, x_max, y_min, y_max) -> torch.Tensor:\n",
    "    batch_size = x.shape[0]\n",
    "\n",
    "    px = x[:, 0]\n",
    "    py = x[:, 1]\n",
    "\n",
    "    px_norm = 2.0 * (px - x_min) / (x_max - x_min) - 1.0\n",
    "    py_norm = 2.0 * (py - y_min) / (y_max - y_min) - 1.0\n",
    "\n",
    "    sampling_grid = torch.stack((px_norm, py_norm), dim=1).view(batch_size, 1, 1, 2)\n",
    "\n",
    "    vyska_terenu_batch = func.grid_sample(\n",
    "        map_tensor.expand(batch_size, -1, -1, -1),\n",
    "        sampling_grid, \n",
    "        mode='bilinear', \n",
    "        padding_mode='border',\n",
    "        align_corners=True\n",
    "    )\n",
    "\n",
    "    vyska_terenu = vyska_terenu_batch.view(batch_size)\n",
    "\n",
    "    eps = 1e-12\n",
    "    vx_w, vy_w = x[:, 2], x[:, 3]\n",
    "    norm_v_w = torch.sqrt(vx_w**2 + vy_w**2).clamp(min=eps)\n",
    "    cos_psi = vx_w / norm_v_w\n",
    "    sin_psi = vy_w / norm_v_w\n",
    "\n",
    "    vx_b = cos_psi * vx_w - sin_psi * vy_w \n",
    "    vy_b = sin_psi * vx_w + cos_psi * vy_w\n",
    "\n",
    "    result = torch.stack([vyska_terenu, vx_b, vy_b], dim=1)\n",
    "\n",
    "    return result\n",
    "\n",
    "x_axis_unique = souradniceX_mapa[0, :]\n",
    "y_axis_unique = souradniceY_mapa[:, 0]\n",
    "terMap_tensor = torch.from_numpy(souradniceZ_mapa).float().unsqueeze(0).unsqueeze(0).to(device)\n",
    "x_min, x_max = x_axis_unique.min(), x_axis_unique.max()\n",
    "y_min, y_max = y_axis_unique.min(), y_axis_unique.max()\n",
    "\n",
    "h_wrapper = lambda x: h_nl_differentiable(\n",
    "    x, \n",
    "    map_tensor=terMap_tensor, \n",
    "    x_min=x_min, \n",
    "    x_max=x_max, \n",
    "    y_min=y_min, \n",
    "    y_max=y_max\n",
    ")\n",
    "\n",
    "system_model = DynamicSystemTAN(\n",
    "    state_dim=state_dim,\n",
    "    obs_dim=obs_dim,\n",
    "    Q=Q.float(),\n",
    "    R=R.float(),\n",
    "    Ex0=x_0.float(),\n",
    "    P0=P_0.float(),\n",
    "    F=F.float(),\n",
    "    h=h_wrapper,\n",
    "    x_axis_unique=x_axis_unique, \n",
    "    y_axis_unique=y_axis_unique,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0770f72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from utils import utils\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from copy import deepcopy\n",
    "from state_NN_models import TAN\n",
    "from utils import trainer \n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af0b11ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== NAƒå√çT√ÅN√ç RAW DAT Z DISKU (BEZ EXT. NORMALIZACE) ===\n",
      "üì• Naƒç√≠t√°m F√°zi 1: Seq=10 | Batch=256 ...\n",
      "   üîé Uk√°zka RAW dat (y): [362.96917724609375, -12.126676559448242, 0.16327548027038574]\n",
      "üì• Naƒç√≠t√°m F√°zi 2: Seq=100 | Batch=128 ...\n",
      "üì• Naƒç√≠t√°m F√°zi 3: Seq=300 | Batch=64 ...\n",
      "\n",
      "‚úÖ Data p≈ôipravena. Normalizaci ≈ôe≈°√≠ model.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import os\n",
    "from utils import trainer # P≈ôedpokl√°d√°m, ≈æe toto m√°≈°\n",
    "\n",
    "# === 1. ZJEDNODU≈†EN√ù DATA MANAGER (BEZ NORMALIZACE) ===\n",
    "class NavigationDataManager:\n",
    "    def __init__(self, data_dir):\n",
    "        \"\"\"\n",
    "        Jen dr≈æ√°k na cestu k dat≈Øm. ≈Ω√°dn√° statistika, ≈æ√°dn√° normalizace.\n",
    "        \"\"\"\n",
    "        self.data_dir = data_dir\n",
    "        \n",
    "    def get_dataloader(self, seq_len, split='train', shuffle=True, batch_size=32):\n",
    "        # Sestaven√≠ cesty: ./generated_data/len_100/train.pt\n",
    "        path = os.path.join(self.data_dir, f'len_{seq_len}', f'{split}.pt')\n",
    "        \n",
    "        if not os.path.exists(path):\n",
    "            raise FileNotFoundError(f\"‚ùå Dataset nenalezen: {path}\")\n",
    "            \n",
    "        # Naƒçten√≠ tenzor≈Ø\n",
    "        data = torch.load(path)\n",
    "        x = data['x'] # Stav [Batch, Seq, DimX]\n",
    "        y = data['y'] # Mƒõ≈ôen√≠ [Batch, Seq, DimY] - RAW DATA\n",
    "        \n",
    "        # Vytvo≈ôen√≠ datasetu\n",
    "        dataset = TensorDataset(x, y)\n",
    "        \n",
    "        return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "# === 2. KONFIGURACE CURRICULA ===\n",
    "DATA_DIR = './generated_data_clean_motion'\n",
    "\n",
    "# Inicializace mana≈æera (teƒè je to jen wrapper pro naƒç√≠t√°n√≠ soubor≈Ø)\n",
    "data_manager = NavigationDataManager(DATA_DIR)\n",
    "\n",
    "# Definice f√°z√≠ (zde ≈ô√≠d√≠≈°, jak se tr√©nink vyv√≠j√≠)\n",
    "curriculum_schedule = [\n",
    "    # F√ÅZE 1: Warm-up (Kr√°tk√© sekvence)\n",
    "    {\n",
    "        'phase_id': 1,\n",
    "        'seq_len': 10,          \n",
    "        'epochs': 500,           \n",
    "        'lr': 1e-3, \n",
    "        'batch_size': 256\n",
    "    },\n",
    "    \n",
    "    # F√ÅZE 2: Stabilizace (St≈ôedn√≠ d√©lka)\n",
    "    {\n",
    "        'phase_id': 2,\n",
    "        'seq_len': 100, \n",
    "        'epochs': 200, \n",
    "        'lr': 1e-4,             \n",
    "        'batch_size': 128\n",
    "    },\n",
    "    \n",
    "    # F√ÅZE 3: Long-term Reality (Pln√° d√©lka)\n",
    "    {\n",
    "        'phase_id': 3,\n",
    "        'seq_len': 300,         \n",
    "        'epochs': 200, \n",
    "        'lr': 5e-5,             \n",
    "        'batch_size': 64       # Men≈°√≠ batch kv≈Øli pamƒõti GPU u dlouh√Ωch sekvenc√≠\n",
    "    }\n",
    "]\n",
    "\n",
    "# === 3. NAƒå√çT√ÅN√ç DO PAMƒöTI (CACHING) ===\n",
    "print(\"\\n=== NAƒå√çT√ÅN√ç RAW DAT Z DISKU (BEZ EXT. NORMALIZACE) ===\")\n",
    "datasets_cache = {} \n",
    "\n",
    "for phase in curriculum_schedule:\n",
    "    seq_len = phase['seq_len']\n",
    "    bs = phase['batch_size']\n",
    "    \n",
    "    print(f\"üì• Naƒç√≠t√°m F√°zi {phase['phase_id']}: Seq={seq_len} | Batch={bs} ...\")\n",
    "    \n",
    "    try:\n",
    "        # Pou≈æit√≠ DataManageru\n",
    "        train_loader = data_manager.get_dataloader(seq_len=seq_len, split='train', shuffle=True, batch_size=bs)\n",
    "        val_loader = data_manager.get_dataloader(seq_len=seq_len, split='val', shuffle=False, batch_size=bs)\n",
    "        \n",
    "        # Ulo≈æen√≠ do cache\n",
    "        datasets_cache[phase['phase_id']] = (train_loader, val_loader)\n",
    "        \n",
    "        # Rychl√° kontrola pro jistotu\n",
    "        x_ex, y_ex = next(iter(train_loader))\n",
    "        if phase['phase_id'] == 1:\n",
    "            print(f\"   üîé Uk√°zka RAW dat (y): {y_ex[0, 0, :].tolist()}\") \n",
    "            # Mƒõl bys vidƒõt velk√° ƒç√≠sla (nap≈ô. 250.0) a mal√° (0.2), ne ~0.0\n",
    "        \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"   ‚ö†Ô∏è CHYBA: {e}\")\n",
    "        # raise e # Odkomentuj, pokud chce≈°, aby to spadlo p≈ôi chybƒõ\n",
    "\n",
    "print(\"\\n‚úÖ Data p≈ôipravena. Normalizaci ≈ôe≈°√≠ model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5daecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== INICIALIZACE NOV√âHO MODELU ===\n",
      "DEBUG: Layer 'output_final_linear.0' initialized near zero (Start K=0).\n",
      "Model inicializov√°n. Poƒçet parametr≈Ø: 472536\n",
      "=== SPU≈†TƒöN√ç TR√âNINKU ===\n",
      "\n",
      "--- PHASE 1: SeqLen 10 ---\n",
      "-> Using Standard Training (with Init Noise)\n",
      "Start training on cuda...\n",
      "Epoch [1/500] | Train Loss: 269.6514 | Val Loss: 186.1079 -> New Best!\n",
      "Epoch [2/500] | Train Loss: 168.3842 | Val Loss: 137.7553 -> New Best!\n",
      "Epoch [3/500] | Train Loss: 111.4717 | Val Loss: 66.5612 -> New Best!\n",
      "Epoch [4/500] | Train Loss: 43.4048 | Val Loss: 30.7094 -> New Best!\n",
      "Epoch [5/500] | Train Loss: 23.1602 | Val Loss: 22.0826 | PosMSE: 38.8, VelMSE: 7.5 -> New Best!\n",
      "Epoch [6/500] | Train Loss: 16.5721 | Val Loss: 20.0504 -> New Best!\n",
      "Epoch [8/500] | Train Loss: 14.0232 | Val Loss: 14.4167 -> New Best!\n",
      "Epoch [9/500] | Train Loss: 13.2246 | Val Loss: 13.9480 -> New Best!\n",
      "Epoch [10/500] | Train Loss: 12.6372 | Val Loss: 14.1405 | PosMSE: 20.1, VelMSE: 5.1\n",
      "Epoch [11/500] | Train Loss: 12.2331 | Val Loss: 13.8669 -> New Best!\n",
      "Epoch [15/500] | Train Loss: 10.6784 | Val Loss: 13.3072 | PosMSE: 16.7, VelMSE: 4.7 -> New Best!\n",
      "Epoch [19/500] | Train Loss: 9.2230 | Val Loss: 12.7913 -> New Best!\n",
      "Epoch [20/500] | Train Loss: 8.7948 | Val Loss: 12.7423 | PosMSE: 13.2, VelMSE: 4.4 -> New Best!\n",
      "Epoch [24/500] | Train Loss: 7.8025 | Val Loss: 12.6788 -> New Best!\n",
      "Epoch [25/500] | Train Loss: 7.4856 | Val Loss: 12.7940 | PosMSE: 10.7, VelMSE: 4.2\n",
      "Epoch [30/500] | Train Loss: 6.4133 | Val Loss: 13.8228 | PosMSE: 8.7, VelMSE: 4.1\n",
      "Epoch [35/500] | Train Loss: 5.3339 | Val Loss: 14.1673 | PosMSE: 6.6, VelMSE: 4.0\n",
      "Epoch [40/500] | Train Loss: 4.8842 | Val Loss: 14.3110 | PosMSE: 5.8, VelMSE: 3.9\n",
      "Epoch [45/500] | Train Loss: 4.4011 | Val Loss: 14.3520 | PosMSE: 5.0, VelMSE: 3.8\n",
      "Epoch [50/500] | Train Loss: 4.1335 | Val Loss: 14.8700 | PosMSE: 4.5, VelMSE: 3.8\n",
      "\n",
      "Early stopping triggered after 54 epochs.\n",
      "Training completed.\n",
      "Loading best model with validation loss: 12.678763\n",
      "Phase 1 completed. Model saved.\n",
      "\n",
      "--- PHASE 2: SeqLen 100 ---\n",
      "Start training on cuda...\n",
      "Epoch [1/200] | Train Loss: 141.8803 | Val Loss: 134.8963 -> New Best!\n",
      "Epoch [2/200] | Train Loss: 126.1043 | Val Loss: 129.4285 -> New Best!\n",
      "Epoch [3/200] | Train Loss: 121.1931 | Val Loss: 127.0807 -> New Best!\n",
      "Epoch [5/200] | Train Loss: 113.8620 | Val Loss: 127.3621 | PosMSE: 223.7, VelMSE: 4.0\n",
      "Epoch [6/200] | Train Loss: 112.5562 | Val Loss: 125.1217 -> New Best!\n",
      "Epoch [8/200] | Train Loss: 108.5374 | Val Loss: 123.8427 -> New Best!\n",
      "Epoch [9/200] | Train Loss: 105.3309 | Val Loss: 122.0596 -> New Best!\n",
      "Epoch [10/200] | Train Loss: 106.3459 | Val Loss: 123.7406 | PosMSE: 208.7, VelMSE: 4.0\n",
      "Epoch [14/200] | Train Loss: 98.9645 | Val Loss: 122.0453 -> New Best!\n",
      "Epoch [15/200] | Train Loss: 98.3881 | Val Loss: 123.4535 | PosMSE: 192.8, VelMSE: 3.9\n",
      "Epoch [19/200] | Train Loss: 94.4943 | Val Loss: 121.4062 -> New Best!\n",
      "Epoch [20/200] | Train Loss: 92.7385 | Val Loss: 123.2214 | PosMSE: 181.5, VelMSE: 4.0\n"
     ]
    }
   ],
   "source": [
    "# --- A) KONFIGURACE S√çTƒö ---\n",
    "print(\"=== INICIALIZACE NOV√âHO MODELU ===\")\n",
    "state_knet2 = TAN.StateKalmanNetTAN(\n",
    "        system_model=system_model, \n",
    "        device=device,\n",
    "        hidden_size_multiplier=10,       \n",
    "        output_layer_multiplier=4,\n",
    "        num_gru_layers=2,\n",
    "        gru_hidden_dim_multiplier=6      \n",
    ").to(device)\n",
    "\n",
    "print(f\"Model inicializov√°n. Poƒçet parametr≈Ø: {sum(p.numel() for p in state_knet2.parameters() if p.requires_grad)}\")\n",
    "\n",
    "# --- B) SPU≈†TƒöN√ç TR√âNINKU ---\n",
    "print(\"=== SPU≈†TƒöN√ç TR√âNINKU ===\")\n",
    "\n",
    "for phase in curriculum_schedule:\n",
    "    phase_id = phase['phase_id']\n",
    "    seq_len = phase['seq_len']\n",
    "    \n",
    "    print(f\"\\n--- PHASE {phase_id}: SeqLen {seq_len} ---\")\n",
    "    \n",
    "    # 1. Naƒçten√≠ dat\n",
    "    if phase_id not in datasets_cache:\n",
    "        raise ValueError(\"Data nejsou vygenerov√°na! Spus≈• prvn√≠ bu≈àku.\")\n",
    "        \n",
    "    train_loader, val_loader = datasets_cache[phase_id]\n",
    "    \n",
    "    # 2. Z√°kladn√≠ argumenty spoleƒçn√© pro obƒõ metody\n",
    "    common_args = {\n",
    "        'model': state_knet2,\n",
    "        'train_loader': train_loader,\n",
    "        'val_loader': val_loader,\n",
    "        'device': device,\n",
    "        'epochs': phase['epochs'],\n",
    "        'lr': phase['lr'],\n",
    "    }\n",
    "\n",
    "    # 3. Rozvƒõtven√≠ logiky podle d√©lky sekvence\n",
    "    if seq_len <= 20:\n",
    "        # === F√ÅZE 1 & 2: Kr√°tk√© sekvence (Standardn√≠ tr√©nink) ===\n",
    "        # Zde chceme init_noise pro robustnost startu\n",
    "        print(\"-> Using Standard Training (with Init Noise)\")\n",
    "        trainer.train_state_KalmanNetTAN(\n",
    "            **common_args,\n",
    "            optimizer_type=torch.optim.AdamW,\n",
    "            weight_decay=1e-3,\n",
    "            clip_grad=1.0,\n",
    "            early_stopping_patience=30\n",
    "        )\n",
    "    elif seq_len == 100:\n",
    "        trainer.train_state_KalmanNetTAN(\n",
    "            **common_args,\n",
    "            optimizer_type=torch.optim.AdamW,\n",
    "            weight_decay=1e-3, # Jemnƒõj≈°√≠ weight decay\n",
    "            clip_grad=1.0,     # D≈Øle≈æit√© pro stabilitu u del≈°√≠ch sekvenc√≠\n",
    "            early_stopping_patience=30 # Dej mu ƒças\n",
    "        )\n",
    "    else:\n",
    "        # === F√ÅZE 3 & 4: Dlouh√© sekvence (TBPTT / Sliding Window) ===\n",
    "        # Zde jsi init_noise odstranil, tak≈æe ho nep≈ôed√°v√°me\n",
    "        print(\"-> Using TBPTT Sliding Window (No Init Noise)\")\n",
    "        trainer.train_state_KalmanNet_sliding_windowTAN(\n",
    "            **common_args,\n",
    "            # init_noise argumenty zde vynech√°v√°me!\n",
    "            weight_decay_=1e-4,\n",
    "            early_stopping_patience=20,\n",
    "            tbptt_k=2,\n",
    "            tbptt_w=6,   \n",
    "            optimizer_=torch.optim.AdamW,\n",
    "            clip_grad=1.0\n",
    "        )\n",
    "    save_path = f'knet_robust_len{seq_len}.pth'\n",
    "    torch.save(state_knet2.state_dict(), save_path)\n",
    "    print(f\"Phase {phase_id} completed. Model saved.\")\n",
    "\n",
    "print(\"üéâ Tr√©nink dokonƒçen.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0a86e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    # save model.\n",
    "    save_path = f'most_consistent_knet.pth'\n",
    "    torch.save(state_knet2.state_dict(), save_path)\n",
    "    print(f\"Model saved to '{save_path}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0098af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # 1. Naƒçteme podez≈ôel√Ω dataset\n",
    "# suspicious_path = './generated_data_clean_motion/len_300/val.pt'\n",
    "# data = torch.load(suspicious_path)\n",
    "# x_gt_all = data['x'].to(device)\n",
    "# y_meas_all = data['y'].to(device)\n",
    "\n",
    "# print(f\"üîé Analyzuji dataset: {suspicious_path}\")\n",
    "# print(f\"   Poƒçet trajektori√≠: {len(x_gt_all)}\")\n",
    "\n",
    "# # 2. Spust√≠me v√°≈° aktu√°ln√≠ model (StateKalmanNet) na v≈°ech datech\n",
    "# state_knet2.eval()\n",
    "# losses = []\n",
    "\n",
    "# bad_indices = []\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for i in range(len(x_gt_all)):\n",
    "#         # P≈ô√≠prava jedn√© trajektorie\n",
    "#         x_gt = x_gt_all[i].unsqueeze(0) # [1, Seq, 4]\n",
    "#         y_meas = y_meas_all[i].unsqueeze(0) # [1, Seq, 3]\n",
    "        \n",
    "#         # Reset modelu\n",
    "#         state_knet2.reset(batch_size=1, initial_state=x_gt[:, 0, :])\n",
    "        \n",
    "#         # Inference\n",
    "#         preds = []\n",
    "#         for t in range(1, x_gt.shape[1]):\n",
    "#             pred = state_knet2.step(y_meas[:, t, :])\n",
    "#             preds.append(pred)\n",
    "            \n",
    "#         preds = torch.stack(preds, dim=1) # [1, Seq-1, 4]\n",
    "        \n",
    "#         # V√Ωpoƒçet MSE pro tuto jednu trajektorii\n",
    "#         loss = torch.nn.functional.mse_loss(preds, x_gt[:, 1:, :]).item()\n",
    "#         losses.append(loss)\n",
    "        \n",
    "#         # Hled√°me extr√©my (nap≈ô. Loss > 500)\n",
    "#         if loss > 1000:\n",
    "#             bad_indices.append((i, loss))\n",
    "\n",
    "# # 3. V√Ωpis v√Ωsledk≈Ø\n",
    "# losses = np.array(losses)\n",
    "# print(f\"\\nüìä Statistika Loss:\")\n",
    "# print(f\"   Pr≈Ømƒõr: {np.mean(losses):.2f}\")\n",
    "# print(f\"   Medi√°n: {np.median(losses):.2f}\") # Medi√°n nebude ovlivnƒõn outlierem!\n",
    "# print(f\"   Max:    {np.max(losses):.2f}\")\n",
    "# print(f\"   Min:    {np.min(losses):.2f}\")\n",
    "\n",
    "# print(f\"\\n‚ö†Ô∏è Nalezen√≠ vin√≠ci (Loss > 1000):\")\n",
    "# for idx, val in bad_indices:\n",
    "#     print(f\"   Index {idx}: Loss = {val:.2f}\")\n",
    "\n",
    "# # 4. Vizualizace nejhor≈°√≠ho p≈ô√≠padu\n",
    "# if bad_indices:\n",
    "#     worst_idx =  max(bad_indices, key=lambda item: item[1])[0]\n",
    "#     print(f\"\\nüìà Vykresluji nejhor≈°√≠ trajektorii (Index {worst_idx})...\")\n",
    "    \n",
    "#     # Znovu spust√≠me pro vykreslen√≠\n",
    "#     x_gt = x_gt_all[worst_idx].cpu().numpy()\n",
    "#     y_meas = y_meas_all[worst_idx].cpu().numpy()\n",
    "    \n",
    "#     # ... (zde by byl k√≥d pro plot, pokud ho chce≈°) ...\n",
    "#     # Ale u≈æ ta ƒç√≠sla naho≈ôe ti ≈ôeknou v≈°e."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67435c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import os\n",
    "\n",
    "# # Cesta k po≈°kozen√©mu souboru\n",
    "# bad_file = './generated_data_clean_motion/len_300/train.pt'\n",
    "# backup_file = bad_file + '.bak'\n",
    "\n",
    "# # 1. Naƒçten√≠\n",
    "# data = torch.load(bad_file)\n",
    "# x_all = data['x']\n",
    "# y_all = data['y']\n",
    "\n",
    "# print(f\"P≈Øvodn√≠ poƒçet: {len(x_all)}\")\n",
    "\n",
    "# # 2. Definice index≈Ø k odstranƒõn√≠ (z va≈°√≠ diagnostiky)\n",
    "# bad_indices = [1887] \n",
    "\n",
    "# # 3. Vytvo≈ôen√≠ masky pro zachov√°n√≠ dobr√Ωch dat\n",
    "# mask = torch.ones(len(x_all), dtype=torch.bool)\n",
    "# mask[bad_indices] = False\n",
    "\n",
    "# # 4. Filtrace\n",
    "# x_clean = x_all[mask]\n",
    "# y_clean = y_all[mask]\n",
    "\n",
    "# print(f\"Nov√Ω poƒçet: {len(x_clean)}\")\n",
    "\n",
    "# # 5. Ulo≈æen√≠ (s z√°lohou)\n",
    "# if not os.path.exists(backup_file):\n",
    "#     os.rename(bad_file, backup_file)\n",
    "#     print(f\"Z√°loha ulo≈æena do: {backup_file}\")\n",
    "\n",
    "# torch.save({'x': x_clean, 'y': y_clean}, bad_file)\n",
    "# print(f\"‚úÖ Vyƒçi≈°tƒõn√Ω dataset ulo≈æen do: {bad_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1ec4ec",
   "metadata": {},
   "source": [
    "# Test na realne trajektorii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d79a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd # Pro hezkou tabulku\n",
    "import Filters\n",
    "from tqdm import tqdm\n",
    "real_traj_np = souradniceGNSS[:2, :].T \n",
    "\n",
    "real_traj_tensor = torch.from_numpy(real_traj_np).float().to(device)\n",
    "train_source_tensor = real_traj_tensor[:, :]\n",
    "# --- POMOCN√Å FUNKCE PRO GENEROW√ÅN√ç DAT ---\n",
    "def get_reference_test_set(system, real_traj_tensor, reverse=False):\n",
    "    # O≈ô√≠znut√≠ trajektorie (pokud je pot≈ôeba)\n",
    "    # real_traj_tensor = real_traj_tensor[:1050,:] \n",
    "    \n",
    "    device = system.Ex0.device\n",
    "    \n",
    "    # P≈ôedpoklad: mat_data je glob√°ln√≠ promƒõnn√° s naƒçten√Ωm .mat souborem\n",
    "    hB_np = mat_data['hB']\n",
    "    real_hB_tensor = torch.from_numpy(hB_np).float().to(device).view(-1)\n",
    "\n",
    "    pos_full = real_traj_tensor.clone().to(device)\n",
    "    \n",
    "    deltas = pos_full[1:] - pos_full[:-1] \n",
    "    last_vel = deltas[-1:]\n",
    "    velocities = torch.cat([deltas, last_vel], dim=0) # [T, 2]\n",
    "    \n",
    "    x_traj_flat = torch.cat([pos_full, velocities], dim=1) # [T, 4]\n",
    "    \n",
    "    # Generov√°n√≠ mƒõ≈ôen√≠ (s n√°hodn√Ωm ≈°umem uvnit≈ô system.measure)\n",
    "    y_traj_flat = system.measure(x_traj_flat) # [T, 3]\n",
    "    \n",
    "    # Nahrazen√≠ barometru re√°ln√Ωmi daty (pokud je to ≈æ√°douc√≠)\n",
    "    seq_len = x_traj_flat.shape[0]\n",
    "    # Pokud chce≈° simulovat ƒçistƒõ syntetick√Ω ≈°um barometru, tento ≈ô√°dek zakomentuj:\n",
    "    y_traj_flat[:, 0] = real_hB_tensor[:seq_len] \n",
    "    \n",
    "    x_ref = x_traj_flat.unsqueeze(0) # [1, T, 4]\n",
    "    y_ref = y_traj_flat.unsqueeze(0) # [1, T, 3]\n",
    "    \n",
    "    return x_ref, y_ref\n",
    "\n",
    "\n",
    "# --- KONFIGURACE MC ---\n",
    "MC_ITERATIONS = 20  # Nastav rozumn√© ƒç√≠slo (pro 100 graf≈Ø by to zahltilo notebook)\n",
    "PLOT_PER_ITERATION = True # Zda vykreslovat grafy pro ka≈æd√Ω bƒõh\n",
    "\n",
    "print(f\"=== SPU≈†TƒöN√ç MONTE CARLO SIMULACE ({MC_ITERATIONS} bƒõh≈Ø) ===\")\n",
    "print(\"Modely: KalmanNet vs. UKF vs. PF\")\n",
    "\n",
    "# 1. P≈ô√≠prava Ground Truth (GT)\n",
    "real_traj_tensor = torch.from_numpy(real_traj_np).float().to(device)\n",
    "# Z√≠sk√°me GT stavy (X) jen jednou, proto≈æe trajektorie je fixn√≠\n",
    "# Mƒõ≈ôen√≠ (Y) se bude mƒõnit v ka≈æd√© iteraci kv≈Øli ≈°umu\n",
    "x_ref_tensor_static, _ = get_reference_test_set(system_model, real_traj_tensor)\n",
    "x_gt = x_ref_tensor_static.squeeze().cpu().numpy()\n",
    "seq_len = x_gt.shape[0]\n",
    "\n",
    "# 2. Inicializace pro sbƒõr dat\n",
    "detailed_results = [] # Seznam slovn√≠k≈Ø pro DataFrame\n",
    "agg_mse = {\"KNet\": [], \"UKF\": [], \"PF\": []}\n",
    "agg_pos = {\"KNet\": [], \"UKF\": [], \"PF\": []}\n",
    "\n",
    "# Ujist√≠me se, ≈æe KNet je v eval m√≥du\n",
    "state_knet2.eval()\n",
    "\n",
    "# --- HLAVN√ç SMYƒåKA ---\n",
    "for i in tqdm(range(MC_ITERATIONS), desc=\"Simulace\"):\n",
    "    \n",
    "    # A) Generov√°n√≠ nov√©ho mƒõ≈ôen√≠ (s nov√Ωm n√°hodn√Ωm ≈°umem)\n",
    "    # Vol√°me funkci znovu, abychom dostali Y s jinou realizac√≠ ≈°umu (pokud system.measure ≈°um√≠)\n",
    "    _, y_ref_tensor = get_reference_test_set(system_model, real_traj_tensor)\n",
    "    \n",
    "    # B) Inference: KalmanNet\n",
    "    with torch.no_grad():\n",
    "        initial_state = x_ref_tensor_static[:, 0, :] # [1, 4]\n",
    "        state_knet2.reset(batch_size=1, initial_state=initial_state)\n",
    "        \n",
    "        knet_preds = []\n",
    "        y_input = y_ref_tensor \n",
    "        \n",
    "        for t in range(1, seq_len):\n",
    "            y_t = y_input[:, t, :]\n",
    "            x_est = state_knet2.step(y_t)\n",
    "            knet_preds.append(x_est)\n",
    "            \n",
    "        knet_preds_tensor = torch.stack(knet_preds, dim=1)\n",
    "        full_knet_est = torch.cat([initial_state.unsqueeze(1), knet_preds_tensor], dim=1)\n",
    "        x_est_knet = full_knet_est.squeeze().cpu().numpy()\n",
    "\n",
    "    # C) Inference: UKF & PF\n",
    "    y_for_filters = y_ref_tensor.squeeze(0) \n",
    "    \n",
    "    # !!! KL√çƒåOV√Å OPRAVA: Pou≈æijeme SKUTEƒåN√ù startovn√≠ bod trajektorie !!!\n",
    "    true_init_state = x_ref_tensor_static[0, 0, :] \n",
    "    \n",
    "    # UKF\n",
    "    ukf_ideal = Filters.UnscentedKalmanFilter(system_model)\n",
    "    ukf_res = ukf_ideal.process_sequence(\n",
    "        y_seq=y_for_filters,\n",
    "        Ex0=true_init_state, # Spr√°vn√Ω start\n",
    "        P0=system_model.P0\n",
    "    )\n",
    "    x_est_ukf = ukf_res['x_filtered'].cpu().numpy()\n",
    "\n",
    "    # PF\n",
    "    pf = Filters.ParticleFilter(system_model, num_particles=10000) # Poƒçet ƒç√°stic dle v√Ωkonu\n",
    "    pf_res = pf.process_sequence(\n",
    "        y_seq=y_for_filters,\n",
    "        Ex0=true_init_state, # Spr√°vn√Ω start\n",
    "        P0=system_model.P0\n",
    "    )\n",
    "    x_est_pf = pf_res['x_filtered'].cpu().numpy()\n",
    "\n",
    "    \n",
    "    # D) V√Ωpoƒçet chyb pro tento bƒõh\n",
    "    # KNet\n",
    "    diff_knet = x_est_knet - x_gt\n",
    "    mse_knet = np.mean(diff_knet**2)\n",
    "    pos_err_knet = np.mean(np.sqrt(diff_knet[:, 0]**2 + diff_knet[:, 1]**2))\n",
    "    \n",
    "    # UKF\n",
    "    diff_ukf = x_est_ukf - x_gt\n",
    "    mse_ukf = np.mean(diff_ukf**2)\n",
    "    pos_err_ukf = np.mean(np.sqrt(diff_ukf[:, 0]**2 + diff_ukf[:, 1]**2))\n",
    "    \n",
    "    # PF\n",
    "    diff_pf = x_est_pf - x_gt\n",
    "    mse_pf = np.mean(diff_pf**2)\n",
    "    pos_err_pf = np.mean(np.sqrt(diff_pf[:, 0]**2 + diff_pf[:, 1]**2))\n",
    "    \n",
    "    # Ulo≈æen√≠ do agreg√°toru\n",
    "    agg_mse[\"KNet\"].append(mse_knet)\n",
    "    agg_pos[\"KNet\"].append(pos_err_knet)\n",
    "    agg_mse[\"UKF\"].append(mse_ukf)\n",
    "    agg_pos[\"UKF\"].append(pos_err_ukf)\n",
    "    agg_mse[\"PF\"].append(mse_pf)\n",
    "    agg_pos[\"PF\"].append(pos_err_pf)\n",
    "\n",
    "    # Ulo≈æen√≠ do detailn√≠ho seznamu\n",
    "    detailed_results.append({\n",
    "        \"Run_ID\": i + 1,\n",
    "        \"KNet_MSE\": mse_knet,\n",
    "        \"UKF_MSE\": mse_ukf,\n",
    "        \"PF_MSE\": mse_pf,\n",
    "        \"KNet_PosErr\": pos_err_knet,\n",
    "        \"UKF_PosErr\": pos_err_ukf,\n",
    "        \"PF_PosErr\": pos_err_pf\n",
    "    })\n",
    "    \n",
    "    # E) Vykreslen√≠ grafu pro TENTO bƒõh\n",
    "    if PLOT_PER_ITERATION:\n",
    "        fig = plt.figure(figsize=(12, 6))\n",
    "        plt.plot(x_gt[:, 0], x_gt[:, 1], 'k-', linewidth=3, alpha=0.3, label='Ground Truth')\n",
    "        \n",
    "        plt.plot(x_est_knet[:, 0], x_est_knet[:, 1], 'g-', linewidth=1.5, label=f'KalmanNet (MSE: {mse_knet:.1f})')\n",
    "        plt.plot(x_est_ukf[:, 0], x_est_ukf[:, 1], 'b--', linewidth=1, label=f'UKF (MSE: {mse_ukf:.1f})')\n",
    "        plt.plot(x_est_pf[:, 0], x_est_pf[:, 1], 'r:', linewidth=1, alpha=0.8, label=f'PF (MSE: {mse_pf:.1f})')\n",
    "        \n",
    "        plt.title(f\"Run {i+1}/{MC_ITERATIONS}: Trajectory Comparison\")\n",
    "        plt.xlabel(\"X [m]\")\n",
    "        plt.ylabel(\"Y [m]\")\n",
    "        plt.legend()\n",
    "        plt.axis('equal')\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "# --- V√ùPIS V√ùSLEDK≈Æ ---\n",
    "\n",
    "# 1. Detailn√≠ tabulka v≈°ech bƒõh≈Ø\n",
    "df_results = pd.DataFrame(detailed_results)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"DETAILN√ç V√ùSLEDKY PO JEDNOTLIV√ùCH BƒöZ√çCH\")\n",
    "print(\"=\"*80)\n",
    "# Form√°tov√°n√≠ tabulky pro hezƒç√≠ v√Ωpis\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "print(df_results[[\"Run_ID\", \"KNet_MSE\", \"UKF_MSE\", \"PF_MSE\", \"KNet_PosErr\", \"UKF_PosErr\", \"PF_PosErr\"]])\n",
    "\n",
    "# 2. Souhrnn√° statistika\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"SOUHRNN√Å STATISTIKA ({MC_ITERATIONS} bƒõh≈Ø)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def get_stats(key):\n",
    "    return np.mean(agg_mse[key]), np.std(agg_mse[key]), np.mean(agg_pos[key]), np.std(agg_pos[key])\n",
    "\n",
    "knet_stats = get_stats(\"KNet\")\n",
    "ukf_stats = get_stats(\"UKF\")\n",
    "pf_stats = get_stats(\"PF\")\n",
    "\n",
    "print(f\"{'Model':<15} | {'MSE (Mean ¬± Std)':<25} | {'Pos Error (Mean ¬± Std)':<25}\")\n",
    "print(\"-\" * 75)\n",
    "print(f\"{'KalmanNet':<15} | {knet_stats[0]:.1f} ¬± {knet_stats[1]:.1f} | {knet_stats[2]:.2f} ¬± {knet_stats[3]:.2f} m\")\n",
    "print(f\"{'UKF':<15} | {ukf_stats[0]:.1f} ¬± {ukf_stats[1]:.1f} | {ukf_stats[2]:.2f} ¬± {ukf_stats[3]:.2f} m\")\n",
    "print(f\"{'PF':<15} | {pf_stats[0]:.1f} ¬± {pf_stats[1]:.1f} | {pf_stats[2]:.2f} ¬± {pf_stats[3]:.2f} m\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 3. Fin√°ln√≠ Boxplot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.boxplot([agg_pos[\"KNet\"], agg_pos[\"UKF\"], agg_pos[\"PF\"]], labels=['KalmanNet', 'UKF', 'PF'], patch_artist=True)\n",
    "plt.title(f\"Position Error Distribution ({MC_ITERATIONS} runs)\")\n",
    "plt.ylabel(\"Avg Position Error [m]\")\n",
    "plt.grid(True, axis='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47670fcc",
   "metadata": {},
   "source": [
    "# Test na synteticke trajektorii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df30b0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd # Pro hezkou tabulku\n",
    "import Filters\n",
    "from tqdm import tqdm\n",
    "real_traj_np = souradniceGNSS[:2, :].T \n",
    "\n",
    "real_traj_tensor = torch.from_numpy(real_traj_np).float().to(device)\n",
    "train_source_tensor = real_traj_tensor[:, :]\n",
    "# --- POMOCN√Å FUNKCE PRO GENEROW√ÅN√ç DAT ---\n",
    "def get_reference_test_set(system, real_traj_tensor, reverse=False):\n",
    "    # O≈ô√≠znut√≠ trajektorie (pokud je pot≈ôeba)\n",
    "    # real_traj_tensor = real_traj_tensor[:1050,:] \n",
    "    \n",
    "    device = system.Ex0.device\n",
    "    \n",
    "    # P≈ôedpoklad: mat_data je glob√°ln√≠ promƒõnn√° s naƒçten√Ωm .mat souborem\n",
    "    # hB_np = mat_data['hB']\n",
    "    # real_hB_tensor = torch.from_numpy(hB_np).float().to(device).view(-1)\n",
    "\n",
    "    pos_full = real_traj_tensor.clone().to(device)\n",
    "    \n",
    "    deltas = pos_full[1:] - pos_full[:-1] \n",
    "    last_vel = deltas[-1:]\n",
    "    velocities = torch.cat([deltas, last_vel], dim=0) # [T, 2]\n",
    "    \n",
    "    x_traj_flat = torch.cat([pos_full, velocities], dim=1) # [T, 4]\n",
    "    \n",
    "    # Generov√°n√≠ mƒõ≈ôen√≠ (s n√°hodn√Ωm ≈°umem uvnit≈ô system.measure)\n",
    "    y_traj_flat = system.measure(x_traj_flat) # [T, 3]\n",
    "    \n",
    "    # Nahrazen√≠ barometru re√°ln√Ωmi daty (pokud je to ≈æ√°douc√≠)\n",
    "    seq_len = x_traj_flat.shape[0]\n",
    "    # Pokud chce≈° simulovat ƒçistƒõ syntetick√Ω ≈°um barometru, tento ≈ô√°dek zakomentuj:\n",
    "    # y_traj_flat[:, 0] = real_hB_tensor[:seq_len] \n",
    "    \n",
    "    x_ref = x_traj_flat.unsqueeze(0) # [1, T, 4]\n",
    "    y_ref = y_traj_flat.unsqueeze(0) # [1, T, 3]\n",
    "    \n",
    "    return x_ref, y_ref\n",
    "\n",
    "\n",
    "# --- KONFIGURACE MC ---\n",
    "MC_ITERATIONS = 10  # Nastav rozumn√© ƒç√≠slo (pro 100 graf≈Ø by to zahltilo notebook)\n",
    "PLOT_PER_ITERATION = True # Zda vykreslovat grafy pro ka≈æd√Ω bƒõh\n",
    "\n",
    "print(f\"=== SPU≈†TƒöN√ç MONTE CARLO SIMULACE ({MC_ITERATIONS} bƒõh≈Ø) ===\")\n",
    "print(\"Modely: KalmanNet vs. UKF vs. PF\")\n",
    "\n",
    "# 1. P≈ô√≠prava Ground Truth (GT)\n",
    "real_traj_tensor = torch.from_numpy(real_traj_np).float().to(device)\n",
    "# Z√≠sk√°me GT stavy (X) jen jednou, proto≈æe trajektorie je fixn√≠\n",
    "# Mƒõ≈ôen√≠ (Y) se bude mƒõnit v ka≈æd√© iteraci kv≈Øli ≈°umu\n",
    "x_ref_tensor_static, _ = get_reference_test_set(system_model, real_traj_tensor)\n",
    "x_gt = x_ref_tensor_static.squeeze().cpu().numpy()\n",
    "seq_len = x_gt.shape[0]\n",
    "\n",
    "# 2. Inicializace pro sbƒõr dat\n",
    "detailed_results = [] # Seznam slovn√≠k≈Ø pro DataFrame\n",
    "agg_mse = {\"KNet\": [], \"UKF\": [], \"PF\": []}\n",
    "agg_pos = {\"KNet\": [], \"UKF\": [], \"PF\": []}\n",
    "\n",
    "# Ujist√≠me se, ≈æe KNet je v eval m√≥du\n",
    "state_knet2.eval()\n",
    "\n",
    "# --- HLAVN√ç SMYƒåKA ---\n",
    "for i in tqdm(range(MC_ITERATIONS), desc=\"Simulace\"):\n",
    "    \n",
    "    # A) Generov√°n√≠ nov√©ho mƒõ≈ôen√≠ (s nov√Ωm n√°hodn√Ωm ≈°umem)\n",
    "    # Vol√°me funkci znovu, abychom dostali Y s jinou realizac√≠ ≈°umu (pokud system.measure ≈°um√≠)\n",
    "    _, y_ref_tensor = get_reference_test_set(system_model, real_traj_tensor)\n",
    "    \n",
    "    # B) Inference: KalmanNet\n",
    "    with torch.no_grad():\n",
    "        initial_state = x_ref_tensor_static[:, 0, :] # [1, 4]\n",
    "        state_knet2.reset(batch_size=1, initial_state=initial_state)\n",
    "        \n",
    "        knet_preds = []\n",
    "        y_input = y_ref_tensor \n",
    "        \n",
    "        for t in range(1, seq_len):\n",
    "            y_t = y_input[:, t, :]\n",
    "            x_est = state_knet2.step(y_t)\n",
    "            knet_preds.append(x_est)\n",
    "            \n",
    "        knet_preds_tensor = torch.stack(knet_preds, dim=1)\n",
    "        full_knet_est = torch.cat([initial_state.unsqueeze(1), knet_preds_tensor], dim=1)\n",
    "        x_est_knet = full_knet_est.squeeze().cpu().numpy()\n",
    "\n",
    "    # C) Inference: UKF & PF\n",
    "    y_for_filters = y_ref_tensor.squeeze(0) \n",
    "    \n",
    "    # !!! KL√çƒåOV√Å OPRAVA: Pou≈æijeme SKUTEƒåN√ù startovn√≠ bod trajektorie !!!\n",
    "    true_init_state = x_ref_tensor_static[0, 0, :] \n",
    "    \n",
    "    # UKF\n",
    "    ukf_ideal = Filters.UnscentedKalmanFilter(system_model)\n",
    "    ukf_res = ukf_ideal.process_sequence(\n",
    "        y_seq=y_for_filters,\n",
    "        Ex0=true_init_state, # Spr√°vn√Ω start\n",
    "        P0=system_model.P0\n",
    "    )\n",
    "    x_est_ukf = ukf_res['x_filtered'].cpu().numpy()\n",
    "\n",
    "    # PF\n",
    "    pf = Filters.ParticleFilter(system_model, num_particles=10000) # Poƒçet ƒç√°stic dle v√Ωkonu\n",
    "    pf_res = pf.process_sequence(\n",
    "        y_seq=y_for_filters,\n",
    "        Ex0=true_init_state, # Spr√°vn√Ω start\n",
    "        P0=system_model.P0\n",
    "    )\n",
    "    x_est_pf = pf_res['x_filtered'].cpu().numpy()\n",
    "\n",
    "    \n",
    "    # D) V√Ωpoƒçet chyb pro tento bƒõh\n",
    "    # KNet\n",
    "    diff_knet = x_est_knet - x_gt\n",
    "    mse_knet = np.mean(diff_knet**2)\n",
    "    pos_err_knet = np.mean(np.sqrt(diff_knet[:, 0]**2 + diff_knet[:, 1]**2))\n",
    "    \n",
    "    # UKF\n",
    "    diff_ukf = x_est_ukf - x_gt\n",
    "    mse_ukf = np.mean(diff_ukf**2)\n",
    "    pos_err_ukf = np.mean(np.sqrt(diff_ukf[:, 0]**2 + diff_ukf[:, 1]**2))\n",
    "    \n",
    "    # PF\n",
    "    diff_pf = x_est_pf - x_gt\n",
    "    mse_pf = np.mean(diff_pf**2)\n",
    "    pos_err_pf = np.mean(np.sqrt(diff_pf[:, 0]**2 + diff_pf[:, 1]**2))\n",
    "    \n",
    "    # Ulo≈æen√≠ do agreg√°toru\n",
    "    agg_mse[\"KNet\"].append(mse_knet)\n",
    "    agg_pos[\"KNet\"].append(pos_err_knet)\n",
    "    agg_mse[\"UKF\"].append(mse_ukf)\n",
    "    agg_pos[\"UKF\"].append(pos_err_ukf)\n",
    "    agg_mse[\"PF\"].append(mse_pf)\n",
    "    agg_pos[\"PF\"].append(pos_err_pf)\n",
    "\n",
    "    # Ulo≈æen√≠ do detailn√≠ho seznamu\n",
    "    detailed_results.append({\n",
    "        \"Run_ID\": i + 1,\n",
    "        \"KNet_MSE\": mse_knet,\n",
    "        \"UKF_MSE\": mse_ukf,\n",
    "        \"PF_MSE\": mse_pf,\n",
    "        \"KNet_PosErr\": pos_err_knet,\n",
    "        \"UKF_PosErr\": pos_err_ukf,\n",
    "        \"PF_PosErr\": pos_err_pf\n",
    "    })\n",
    "    \n",
    "    # E) Vykreslen√≠ grafu pro TENTO bƒõh\n",
    "    if PLOT_PER_ITERATION:\n",
    "        fig = plt.figure(figsize=(12, 6))\n",
    "        plt.plot(x_gt[:, 0], x_gt[:, 1], 'k-', linewidth=3, alpha=0.3, label='Ground Truth')\n",
    "        \n",
    "        plt.plot(x_est_knet[:, 0], x_est_knet[:, 1], 'g-', linewidth=1.5, label=f'KalmanNet (MSE: {mse_knet:.1f})')\n",
    "        plt.plot(x_est_ukf[:, 0], x_est_ukf[:, 1], 'b--', linewidth=1, label=f'UKF (MSE: {mse_ukf:.1f})')\n",
    "        plt.plot(x_est_pf[:, 0], x_est_pf[:, 1], 'r:', linewidth=1, alpha=0.8, label=f'PF (MSE: {mse_pf:.1f})')\n",
    "        \n",
    "        plt.title(f\"Run {i+1}/{MC_ITERATIONS}: Trajectory Comparison\")\n",
    "        plt.xlabel(\"X [m]\")\n",
    "        plt.ylabel(\"Y [m]\")\n",
    "        plt.legend()\n",
    "        plt.axis('equal')\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "# --- V√ùPIS V√ùSLEDK≈Æ ---\n",
    "\n",
    "# 1. Detailn√≠ tabulka v≈°ech bƒõh≈Ø\n",
    "df_results = pd.DataFrame(detailed_results)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"DETAILN√ç V√ùSLEDKY PO JEDNOTLIV√ùCH BƒöZ√çCH\")\n",
    "print(\"=\"*80)\n",
    "# Form√°tov√°n√≠ tabulky pro hezƒç√≠ v√Ωpis\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "print(df_results[[\"Run_ID\", \"KNet_MSE\", \"UKF_MSE\", \"PF_MSE\", \"KNet_PosErr\", \"UKF_PosErr\", \"PF_PosErr\"]])\n",
    "\n",
    "# 2. Souhrnn√° statistika\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"SOUHRNN√Å STATISTIKA ({MC_ITERATIONS} bƒõh≈Ø)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def get_stats(key):\n",
    "    return np.mean(agg_mse[key]), np.std(agg_mse[key]), np.mean(agg_pos[key]), np.std(agg_pos[key])\n",
    "\n",
    "knet_stats = get_stats(\"KNet\")\n",
    "ukf_stats = get_stats(\"UKF\")\n",
    "pf_stats = get_stats(\"PF\")\n",
    "\n",
    "print(f\"{'Model':<15} | {'MSE (Mean ¬± Std)':<25} | {'Pos Error (Mean ¬± Std)':<25}\")\n",
    "print(\"-\" * 75)\n",
    "print(f\"{'KalmanNet':<15} | {knet_stats[0]:.1f} ¬± {knet_stats[1]:.1f} | {knet_stats[2]:.2f} ¬± {knet_stats[3]:.2f} m\")\n",
    "print(f\"{'UKF':<15} | {ukf_stats[0]:.1f} ¬± {ukf_stats[1]:.1f} | {ukf_stats[2]:.2f} ¬± {ukf_stats[3]:.2f} m\")\n",
    "print(f\"{'PF':<15} | {pf_stats[0]:.1f} ¬± {pf_stats[1]:.1f} | {pf_stats[2]:.2f} ¬± {pf_stats[3]:.2f} m\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 3. Fin√°ln√≠ Boxplot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.boxplot([agg_pos[\"KNet\"], agg_pos[\"UKF\"], agg_pos[\"PF\"]], labels=['KalmanNet', 'UKF', 'PF'], patch_artist=True)\n",
    "plt.title(f\"Position Error Distribution ({MC_ITERATIONS} runs)\")\n",
    "plt.ylabel(\"Avg Position Error [m]\")\n",
    "plt.grid(True, axis='y')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
