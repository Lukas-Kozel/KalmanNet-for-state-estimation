{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generov√°n√≠ Syntetick√Ωch Dat (Sim2Real Strategy)\n",
    "\n",
    "Tento notebook slou≈æ√≠ k vygenerov√°n√≠ tr√©novac√≠ a validaƒçn√≠ sady pro KalmanNet/KalmanFormer.\n",
    "Data jsou generov√°na na z√°kladƒõ statistiky z re√°ln√© trajektorie (`data.mat`), aby se model uƒçil na datech co nejpodobnƒõj≈°√≠ch realitƒõ.\n",
    "\n",
    "**Kl√≠ƒçov√© vlastnosti:**\n",
    "- Resampling rychlost√≠ a √∫hlov√Ωch rychlost√≠ z re√°ln√Ωch dat (zachov√°n√≠ korelace).\n",
    "- Vyhlazov√°n√≠ trajektori√≠ (Setrvaƒçnost).\n",
    "- Validace pomoc√≠ UKF (Odfiltrov√°n√≠ fyzik√°lnƒõ nesmysln√Ωch nebo pro filtr p≈ô√≠li≈° n√°roƒçn√Ωch trajektori√≠).\n",
    "- Generov√°n√≠ dat s biasem a ≈°umem, ale validace na datech bez biasu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a515de88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset path: /home/luky/skola/KalmanNet-for-state-estimation/data/data.mat\n",
      "Project root added: /home/luky/skola/KalmanNet-for-state-estimation\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from scipy.io import loadmat\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Robust path finding for data.mat\n",
    "current_path = Path.cwd()\n",
    "possible_data_paths = [\n",
    "    current_path / 'data' / 'data.mat',\n",
    "    current_path.parent / 'data' / 'data.mat',\n",
    "    current_path.parent.parent / 'data' / 'data.mat',\n",
    "    # Fallback absolute path\n",
    "    Path('/home/luky/skola/KalmanNet-main/data/data.mat')\n",
    "]\n",
    "\n",
    "dataset_path = None\n",
    "for p in possible_data_paths:\n",
    "    if p.exists():\n",
    "        dataset_path = p\n",
    "        break\n",
    "\n",
    "if dataset_path is None or not dataset_path.exists():\n",
    "    print(\"Warning: data.mat not found automatically.\")\n",
    "    dataset_path = Path('data/data.mat')\n",
    "\n",
    "print(f\"Dataset path: {dataset_path}\")\n",
    "\n",
    "# Add project root to sys.path (2 levels up from debug/test)\n",
    "notebook_dir = os.getcwd()\n",
    "project_root = os.path.abspath(os.path.join(notebook_dir, '..', '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "print(f\"Project root added: {project_root}\")\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import RegularGridInterpolator\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import Filters\n",
    "from Systems import DynamicSystemTAN\n",
    "import torch.nn.functional as func\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3f07b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luky/.local/lib/python3.10/site-packages/torch/cuda/__init__.py:118: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "# Nastaven√≠ seed≈Ø pro reprodukovatelnost\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e9fade7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Map X: (2500,), Y: (2500,), Z: (2500, 2500)\n"
     ]
    }
   ],
   "source": [
    "# Naƒçten√≠ dat a mapy\n",
    "mat_data = loadmat(dataset_path)\n",
    "\n",
    "souradniceX_mapa = mat_data['souradniceX']\n",
    "souradniceY_mapa = mat_data['souradniceY']\n",
    "souradniceZ_mapa = mat_data['souradniceZ']\n",
    "souradniceGNSS = mat_data['souradniceGNSS'] \n",
    "x_axis_unique = souradniceX_mapa[0, :]\n",
    "y_axis_unique = souradniceY_mapa[:, 0]\n",
    "\n",
    "print(f\"Map X: {x_axis_unique.shape}, Y: {y_axis_unique.shape}, Z: {souradniceZ_mapa.shape}\")\n",
    "\n",
    "# Interpol√°tor (pro pou≈æit√≠ mimo torch, pokud pot≈ôeba)\n",
    "terMap_interpolator = RegularGridInterpolator(\n",
    "    (y_axis_unique, x_axis_unique),\n",
    "    souradniceZ_mapa,\n",
    "    bounds_error=False, \n",
    "    fill_value=np.nan\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5bad4e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: DynamicSystemTAN inicializov√°n s hranicemi mapy:\n",
      "  X: [1476611.42, 1489541.47]\n",
      "  Y: [6384032.63, 6400441.34]\n",
      "System Model Initialized\n"
     ]
    }
   ],
   "source": [
    "# Definice System Modelu\n",
    "state_dim = 4\n",
    "obs_dim = 3\n",
    "dT = 1\n",
    "q = 1\n",
    "\n",
    "F = torch.tensor([[1.0, 0.0, dT, 0.0],\n",
    "                   [0.0, 1.0, 0.0, dT],\n",
    "                   [0.0, 0.0, 1.0, 0.0],\n",
    "                   [0.0, 0.0, 0.0, 1.0]])\n",
    "\n",
    "Q = q* torch.tensor([[dT**3/3, 0.0, dT**2/2, 0.0],\n",
    "                   [0.0, dT**3/3, 0.0, dT**2/2],\n",
    "                   [dT**2/2, 0.0, dT, 0.0],\n",
    "                   [0.0, dT**2/2, 0.0, dT]])\n",
    "R = torch.tensor([[3.0**2, 0.0, 0.0],\n",
    "                   [0.0, 1.0**2, 0.0],\n",
    "                   [0.0, 0.0, 1.0**2]])\n",
    "\n",
    "initial_velocity = torch.from_numpy(np.array([0,0]))\n",
    "initial_position = torch.from_numpy(souradniceGNSS[:2, 0])\n",
    "x_0 = torch.cat([\n",
    "    initial_position,\n",
    "    initial_velocity\n",
    "]).float()\n",
    "\n",
    "P_0 = torch.tensor([[25.0, 0.0, 0.0, 0.0],\n",
    "                    [0.0, 25.0, 0.0, 0.0],\n",
    "                    [0.0, 0.0, 0.5, 0.0],\n",
    "                    [0.0, 0.0, 0.0, 0.5]])\n",
    "\n",
    "# Diferencovateln√° funkce h(x) pro ter√©n\n",
    "def h_nl_differentiable(x: torch.Tensor, map_tensor, x_min, x_max, y_min, y_max) -> torch.Tensor:\n",
    "    batch_size = x.shape[0]\n",
    "\n",
    "    px = x[:, 0]\n",
    "    py = x[:, 1]\n",
    "\n",
    "    px_norm = 2.0 * (px - x_min) / (x_max - x_min) - 1.0\n",
    "    py_norm = 2.0 * (py - y_min) / (y_max - y_min) - 1.0\n",
    "\n",
    "    sampling_grid = torch.stack((px_norm, py_norm), dim=1).view(batch_size, 1, 1, 2)\n",
    "\n",
    "    vyska_terenu_batch = func.grid_sample(\n",
    "        map_tensor.expand(batch_size, -1, -1, -1),\n",
    "        sampling_grid, \n",
    "        mode='bilinear', \n",
    "        padding_mode='border',\n",
    "        align_corners=True\n",
    "    )\n",
    "\n",
    "    vyska_terenu = vyska_terenu_batch.view(batch_size)\n",
    "\n",
    "    eps = 1e-12\n",
    "    vx_w, vy_w = x[:, 2], x[:, 3]\n",
    "    norm_v_w = torch.sqrt(vx_w**2 + vy_w**2).clamp(min=eps)\n",
    "    cos_psi = vx_w / norm_v_w\n",
    "    sin_psi = vy_w / norm_v_w\n",
    "\n",
    "    vx_b = cos_psi * vx_w - sin_psi * vy_w \n",
    "    vy_b = sin_psi * vx_w + cos_psi * vy_w\n",
    "\n",
    "    result = torch.stack([vyska_terenu, vx_b, vy_b], dim=1)\n",
    "    return result\n",
    "\n",
    "terMap_tensor = torch.from_numpy(souradniceZ_mapa).float().unsqueeze(0).unsqueeze(0).to(device)\n",
    "x_min, x_max = x_axis_unique.min(), x_axis_unique.max()\n",
    "y_min, y_max = y_axis_unique.min(), y_axis_unique.max()\n",
    "\n",
    "h_wrapper = lambda x: h_nl_differentiable(\n",
    "    x, \n",
    "    map_tensor=terMap_tensor, \n",
    "    x_min=x_min, \n",
    "    x_max=x_max, \n",
    "    y_min=y_min, \n",
    "    y_max=y_max\n",
    ")\n",
    "\n",
    "system_model = DynamicSystemTAN(\n",
    "    state_dim=state_dim,\n",
    "    obs_dim=obs_dim,\n",
    "    Q=Q.float(),\n",
    "    R=R.float(),\n",
    "    Ex0=x_0.float(),\n",
    "    P0=P_0.float(),\n",
    "    F=F.float(),\n",
    "    h=h_wrapper,\n",
    "    x_axis_unique=x_axis_unique, \n",
    "    y_axis_unique=y_axis_unique,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "print(\"System Model Initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a38ea396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Statistika: 1263 vzork≈Ø. AvgSpeed: 26.76 m/s\n"
     ]
    }
   ],
   "source": [
    "# === 1. EXTRAKCE STATISTIKY Z RE√ÅLN√â TRAJEKTORIE ===\n",
    "def extract_driving_stats(real_traj_tensor):\n",
    "    positions = real_traj_tensor[:, :2]\n",
    "    deltas = positions[1:] - positions[:-1]\n",
    "    speeds = torch.norm(deltas, dim=1)\n",
    "    headings = torch.atan2(deltas[:, 1], deltas[:, 0])\n",
    "    yaw_rates = headings[1:] - headings[:-1]\n",
    "    # O≈°et≈ôen√≠ p≈ôechodu -pi/pi\n",
    "    yaw_rates = (yaw_rates + np.pi) % (2 * np.pi) - np.pi\n",
    "    speeds = speeds[:-1]\n",
    "    \n",
    "    # Filtrujeme jen rozumn√© rychlosti (nap≈ô. kdy≈æ auto stoj√≠, yaw_rate je ≈°um)\n",
    "    valid_mask = (torch.isfinite(speeds) & torch.isfinite(yaw_rates) & (speeds > 0.5))\n",
    "    clean_speeds = speeds[valid_mask]\n",
    "    clean_yaw_rates = yaw_rates[valid_mask]\n",
    "    \n",
    "    print(f\"‚úÖ Statistika: {len(clean_speeds)} vzork≈Ø. AvgSpeed: {clean_speeds.mean():.2f} m/s\")\n",
    "    return clean_speeds, clean_yaw_rates\n",
    "\n",
    "# P≈ô√≠prava re√°ln√Ωch dat\n",
    "real_traj_np = souradniceGNSS[:2, :].T \n",
    "real_traj_tensor = torch.from_numpy(real_traj_np).float().to(device)\n",
    "real_speeds, real_yaws = extract_driving_stats(real_traj_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0dfb8aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 2. VEKTORIZOVAN√ù GENER√ÅTOR TRAJEKTORI√ç ===\n",
    "def simulate_batch_ackermann(system, batch_size, seq_len, stats_speeds, stats_yaws, speed_scale=0.99):\n",
    "    device = system.Ex0.device\n",
    "    dt = 1.0\n",
    "    \n",
    "    margin = 150.0\n",
    "    x_min, x_max = system.min_x + margin, system.max_x - margin\n",
    "    y_min, y_max = system.min_y + margin, system.max_y - margin\n",
    "    \n",
    "    start_x = (torch.rand(batch_size, 1, device=device) * (x_max - x_min)) + x_min\n",
    "    start_y = (torch.rand(batch_size, 1, device=device) * (y_max - y_min)) + y_min\n",
    "    start_psi = (torch.rand(batch_size, 1, device=device) * 2 * np.pi) - np.pi\n",
    "    \n",
    "    # Resampling z re√°ln√Ωch statistik\n",
    "    # Pou≈æ√≠v√°me stejn√Ω index pro v i omega -> zachov√°n√≠ korelace\n",
    "    rand_idx = torch.randint(0, len(stats_speeds), (batch_size, seq_len), device=device)\n",
    "    chosen_v = stats_speeds[rand_idx] * speed_scale\n",
    "    chosen_omega = stats_yaws[rand_idx]\n",
    "    \n",
    "    # Vyhlazov√°n√≠ (Simulace setrvaƒçnosti)\n",
    "    alpha_v = 0.3      \n",
    "    alpha_omega = 0.4  \n",
    "    \n",
    "    smooth_v = torch.zeros_like(chosen_v)\n",
    "    smooth_omega = torch.zeros_like(chosen_omega)\n",
    "    \n",
    "    curr_v = chosen_v[:, 0]\n",
    "    curr_omega = chosen_omega[:, 0]\n",
    "    \n",
    "    for t in range(seq_len):\n",
    "        curr_v = (1 - alpha_v) * curr_v + alpha_v * chosen_v[:, t]\n",
    "        curr_omega = (1 - alpha_omega) * curr_omega + alpha_omega * chosen_omega[:, t]\n",
    "        smooth_v[:, t] = curr_v\n",
    "        smooth_omega[:, t] = curr_omega\n",
    "        \n",
    "    traj_x = []\n",
    "    traj_y = []\n",
    "    traj_vx = []\n",
    "    traj_vy = []\n",
    "    \n",
    "    curr_x, curr_y, curr_psi = start_x.squeeze(), start_y.squeeze(), start_psi.squeeze()\n",
    "    \n",
    "    for t in range(seq_len):\n",
    "        v = smooth_v[:, t]\n",
    "        omega = smooth_omega[:, t]\n",
    "        vx = v * torch.cos(curr_psi)\n",
    "        vy = v * torch.sin(curr_psi)\n",
    "        \n",
    "        traj_x.append(curr_x)\n",
    "        traj_y.append(curr_y)\n",
    "        traj_vx.append(vx)\n",
    "        traj_vy.append(vy)\n",
    "        \n",
    "        curr_x = curr_x + vx * dt\n",
    "        curr_y = curr_y + vy * dt\n",
    "        curr_psi = curr_psi + omega * dt\n",
    "        \n",
    "    X = torch.stack(traj_x, dim=1)\n",
    "    Y = torch.stack(traj_y, dim=1)\n",
    "    VX = torch.stack(traj_vx, dim=1)\n",
    "    VY = torch.stack(traj_vy, dim=1)\n",
    "    \n",
    "    return torch.stack([X, Y, VX, VY], dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ Generuji sadu (Clean Motion): D√©lka=10 | C√≠l=2200/500 | Max UKF RMSE < 10.0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  -> TRAIN:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1039/2200 [00:07<00:07, 150.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- DEBUG (Batch 5) ---\n",
      "   Gen: 1280 | Acc: 1014 (79.22%)\n",
      "   Drop: RMSE>10.0m=262 (Avg rej: 12.9m)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  -> TRAIN:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2059/2200 [00:14<00:01, 139.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- DEBUG (Batch 10) ---\n",
      "   Gen: 2560 | Acc: 2049 (80.04%)\n",
      "   Drop: RMSE>10.0m=499 (Avg rej: 13.5m)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  -> TRAIN: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2200/2200 [00:15<00:00, 144.56it/s]\n",
      "  -> VAL: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [00:03<00:00, 150.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ Generuji sadu (Clean Motion): D√©lka=100 | C√≠l=2200/500 | Max UKF RMSE < 30.0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  -> TRAIN:  35%|‚ñà‚ñà‚ñà‚ñç      | 765/2200 [00:53<02:04, 11.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- DEBUG (Batch 5) ---\n",
      "   Gen: 1280 | Acc: 762 (59.53%)\n",
      "   Drop: RMSE>30.0m=269 (Avg rej: 63.2m)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  -> TRAIN:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1543/2200 [01:49<00:38, 16.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- DEBUG (Batch 10) ---\n",
      "   Gen: 2560 | Acc: 1543 (60.27%)\n",
      "   Drop: RMSE>30.0m=526 (Avg rej: 57.2m)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  -> TRAIN: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2200/2200 [02:39<00:00, 13.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- DEBUG (Batch 15) ---\n",
      "   Gen: 3840 | Acc: 2200 (57.29%)\n",
      "   Drop: RMSE>30.0m=745 (Avg rej: 54.2m)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  -> VAL: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [00:36<00:00, 13.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ Generuji sadu (Clean Motion): D√©lka=300 | C√≠l=2200/500 | Max UKF RMSE < 70.0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  -> TRAIN:  27%|‚ñà‚ñà‚ñã       | 595/2200 [01:38<04:12,  6.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- DEBUG (Batch 5) ---\n",
      "   Gen: 1280 | Acc: 594 (46.41%)\n",
      "   Drop: RMSE>70.0m=30 (Avg rej: 84.3m)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  -> TRAIN:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1188/2200 [03:17<02:47,  6.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- DEBUG (Batch 10) ---\n",
      "   Gen: 2560 | Acc: 1187 (46.37%)\n",
      "   Drop: RMSE>70.0m=54 (Avg rej: 83.7m)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  -> TRAIN:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1785/2200 [04:54<01:24,  4.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- DEBUG (Batch 15) ---\n",
      "   Gen: 3840 | Acc: 1784 (46.46%)\n",
      "   Drop: RMSE>70.0m=72 (Avg rej: 84.4m)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  -> TRAIN: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2200/2200 [06:06<00:00,  6.00it/s]\n",
      "  -> VAL: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [01:25<00:00,  5.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- DEBUG (Batch 5) ---\n",
      "   Gen: 1280 | Acc: 500 (39.06%)\n",
      "   Drop: RMSE>70.0m=21 (Avg rej: 83.9m)\n",
      "\n",
      "‚ú® Hotovo. Dataset (Synthetic) vygenerov√°n.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# === 3. HLAVN√ç LOOP GENEROV√ÅN√ç ===\n",
    "\n",
    "DATA_DIR = './generated_data_clean_motion'\n",
    "if os.path.exists(DATA_DIR): shutil.rmtree(DATA_DIR)\n",
    "os.makedirs(DATA_DIR)\n",
    "\n",
    "BATCH_SIZE_GEN = 256  \n",
    "filter_model = Filters.UnscentedKalmanFilter(system_model)\n",
    "filter_name = \"UKF\"\n",
    "\n",
    "# Konfigurace dataset≈Ø\n",
    "CONFIGS = [\n",
    "    # (D√©lka, C√≠l Train, C√≠l Val, Max RMSE [m])\n",
    "    (10,  2200, 500, 10.0),\n",
    "    (100, 2200, 500, 30.0), \n",
    "    (300, 2200, 500, 70.0) \n",
    "]\n",
    "\n",
    "for seq_len, n_train, n_val, filter_thresh in CONFIGS:\n",
    "    subset_dir = os.path.join(DATA_DIR, f'len_{seq_len}')\n",
    "    os.makedirs(subset_dir, exist_ok=True)\n",
    "    \n",
    "    print(f\"\\nüöÄ Generuji sadu (Clean Motion): D√©lka={seq_len} | C√≠l={n_train}/{n_val} | Max {filter_name} RMSE < {filter_thresh}m\")\n",
    "    \n",
    "    for split, target_count in [('train', n_train), ('val', n_val)]:\n",
    "        valid_x_list = []\n",
    "        valid_y_list = []\n",
    "        \n",
    "        stats = {\n",
    "            'generated': 0, 'dropped_bounds': 0, 'dropped_flat': 0,\n",
    "            'dropped_filter_crash': 0, 'dropped_rmse_high': 0,\n",
    "            'accepted': 0, 'avg_rmse_rejected': 0.0\n",
    "        }\n",
    "        \n",
    "        pbar = tqdm(total=target_count, desc=f\"  -> {split.upper()}\")\n",
    "        batch_counter = 0\n",
    "        \n",
    "        while len(valid_x_list) < target_count:\n",
    "            batch_counter += 1\n",
    "            x_batch = simulate_batch_ackermann(system_model, BATCH_SIZE_GEN, seq_len, real_speeds, real_yaws)\n",
    "            stats['generated'] += BATCH_SIZE_GEN\n",
    "            \n",
    "            # Pre-filter (Hranice mapy)\n",
    "            in_bounds = (\n",
    "                (x_batch[:, :, 0].min(dim=1).values > system_model.min_x) &\n",
    "                (x_batch[:, :, 0].max(dim=1).values < system_model.max_x) &\n",
    "                (x_batch[:, :, 1].min(dim=1).values > system_model.min_y) &\n",
    "                (x_batch[:, :, 1].max(dim=1).values < system_model.max_y)\n",
    "            )\n",
    "            x_cands = x_batch[in_bounds]\n",
    "            stats['dropped_bounds'] += (BATCH_SIZE_GEN - len(x_cands))\n",
    "            if len(x_cands) == 0: continue\n",
    "            \n",
    "            try:\n",
    "                batch_size_real = x_cands.shape[0]\n",
    "                flat_x = x_cands.reshape(-1, 4)\n",
    "                flat_y = system_model.measure(flat_x) \n",
    "                y_ideal = flat_y.reshape(batch_size_real, seq_len, 3)\n",
    "                \n",
    "                # 1. B√≠l√Ω ≈°um\n",
    "                noise_std = torch.tensor([9.0, 3.0, 3.0], device=system_model.Ex0.device)\n",
    "                white_noise = torch.randn_like(y_ideal) * noise_std\n",
    "                \n",
    "                # Verze bez biasu a bez odometry scale (pro validaci)\n",
    "                y_for_validation = y_ideal + white_noise\n",
    "\n",
    "                # 2. Bias Barometru (Rozsah -5 a≈æ +5)\n",
    "                bias_min = -5.0\n",
    "                bias_max = 5.0\n",
    "                bias_span = bias_max - bias_min\n",
    "                \n",
    "                baro_bias = (torch.rand(batch_size_real, 1, 1, device=system_model.Ex0.device) * bias_span) + bias_min\n",
    "                bias_tensor = torch.zeros_like(y_ideal)\n",
    "                bias_tensor[:, :, 0] = baro_bias[:, :, 0]\n",
    "                \n",
    "                # --- VERZE PRO DATASET (Hardcore: ≈†um + Bias) ---\n",
    "                # Pozn: Odometry scale error byl odstranƒõn na p≈ô√°n√≠ u≈æivatele.\n",
    "                y_for_dataset = y_for_validation.clone() # Zaƒçneme s ≈°umem\n",
    "                y_for_dataset += bias_tensor             # P≈ôid√°me bias\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Chyba mƒõ≈ôen√≠: {e}\")\n",
    "                continue\n",
    "\n",
    "            # Filter Validace\n",
    "            rmse_sum_rejected = 0\n",
    "            rmse_count_rejected = 0\n",
    "            \n",
    "            for i in range(len(x_cands)):\n",
    "                if len(valid_x_list) >= target_count: break\n",
    "                \n",
    "                # Kontrola roviny\n",
    "                if torch.std(y_for_dataset[i, :, 0]) < 0.5: \n",
    "                    stats['dropped_flat'] += 1\n",
    "                    continue\n",
    "                \n",
    "                try:\n",
    "                    x_gt = x_cands[i]\n",
    "                    \n",
    "                    # Validujeme ƒçist≈°√≠ data (y_for_validation)\n",
    "                    res = filter_model.process_sequence(y_for_validation[i], Ex0=x_gt[0], P0=system_model.P0)\n",
    "                    x_est = res['x_filtered']\n",
    "                    \n",
    "                    len_est = x_est.shape[0]\n",
    "                    len_gt = x_gt.shape[0]\n",
    "                    min_len = min(len_est, len_gt)\n",
    "                    \n",
    "                    diff = x_est[:min_len, :2] - x_gt[:min_len, :2]\n",
    "                    rmse = torch.sqrt(torch.mean(torch.sum(diff**2, dim=1))).item()\n",
    "                    \n",
    "                    if rmse < filter_thresh:\n",
    "                        valid_x_list.append(x_gt.cpu())\n",
    "                        valid_y_list.append(y_for_dataset[i].cpu())\n",
    "                        stats['accepted'] += 1\n",
    "                        pbar.update(1)\n",
    "                    else:\n",
    "                        stats['dropped_rmse_high'] += 1\n",
    "                        rmse_sum_rejected += rmse\n",
    "                        rmse_count_rejected += 1\n",
    "                        \n",
    "                except Exception:\n",
    "                    stats['dropped_filter_crash'] += 1\n",
    "                    continue\n",
    "            \n",
    "            if rmse_count_rejected > 0:\n",
    "                current_avg = rmse_sum_rejected / rmse_count_rejected\n",
    "                if stats['avg_rmse_rejected'] == 0: stats['avg_rmse_rejected'] = current_avg\n",
    "                else: stats['avg_rmse_rejected'] = 0.9 * stats['avg_rmse_rejected'] + 0.1 * current_avg\n",
    "\n",
    "            if batch_counter % 5 == 0:\n",
    "                acc_rate = (stats['accepted'] / stats['generated']) * 100\n",
    "                tqdm.write(f\"\\n--- DEBUG (Batch {batch_counter}) ---\")\n",
    "                tqdm.write(f\"   Gen: {stats['generated']} | Acc: {stats['accepted']} ({acc_rate:.2f}%)\")\n",
    "                tqdm.write(f\"   Drop: RMSE>{filter_thresh}m={stats['dropped_rmse_high']} (Avg rej: {stats['avg_rmse_rejected']:.1f}m)\")\n",
    "                    \n",
    "        pbar.close()\n",
    "        torch.save({'x': torch.stack(valid_x_list), 'y': torch.stack(valid_y_list)}, os.path.join(subset_dir, f'{split}.pt'))\n",
    "\n",
    "print(\"\\n‚ú® Hotovo. Dataset (Synthetic) vygenerov√°n.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
