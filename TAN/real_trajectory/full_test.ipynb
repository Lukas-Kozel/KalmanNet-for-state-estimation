{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15959426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset path: /home/luky/skola/KalmanNet-main/data/data.mat\n",
      "Project root added: /home/luky/skola/KalmanNet-main\n",
      "dict_keys(['__header__', '__version__', '__globals__', 'hB', 'souradniceGNSS', 'souradniceX', 'souradniceY', 'souradniceZ'])\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from scipy.io import loadmat\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Robust path finding for data.mat\n",
    "current_path = Path.cwd()\n",
    "possible_data_paths = [\n",
    "    current_path / 'data' / 'data.mat',\n",
    "    current_path.parent / 'data' / 'data.mat',\n",
    "    current_path.parent.parent / 'data' / 'data.mat',\n",
    "    # Fallback absolute path\n",
    "    Path('/home/luky/skola/KalmanNet-for-state-estimation/data/data.mat')\n",
    "]\n",
    "\n",
    "dataset_path = None\n",
    "for p in possible_data_paths:\n",
    "    if p.exists():\n",
    "        dataset_path = p\n",
    "        break\n",
    "\n",
    "if dataset_path is None or not dataset_path.exists():\n",
    "    print(\"Warning: data.mat not found automatically.\")\n",
    "    dataset_path = Path('data/data.mat')\n",
    "\n",
    "print(f\"Dataset path: {dataset_path}\")\n",
    "\n",
    "# Add project root to sys.path (2 levels up from debug/test)\n",
    "notebook_dir = os.getcwd()\n",
    "project_root = os.path.abspath(os.path.join(notebook_dir, '..', '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "print(f\"Project root added: {project_root}\")\n",
    "\n",
    "mat_data = loadmat(dataset_path)\n",
    "print(mat_data.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94742705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import trainer\n",
    "from utils import utils\n",
    "from Systems import DynamicSystem\n",
    "import Filters\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "from scipy.interpolate import RegularGridInterpolator\n",
    "import random\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51f00243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of 1D X axis: (2500,)\n",
      "Dimensions of 1D Y axis: (2500,)\n",
      "Dimensions of 2D elevation data Z: (2500, 2500)\n"
     ]
    }
   ],
   "source": [
    "mat_data = loadmat(dataset_path)\n",
    "\n",
    "souradniceX_mapa = mat_data['souradniceX']\n",
    "souradniceY_mapa = mat_data['souradniceY']\n",
    "souradniceZ_mapa = mat_data['souradniceZ']\n",
    "souradniceGNSS = mat_data['souradniceGNSS'] \n",
    "x_axis_unique = souradniceX_mapa[0, :]\n",
    "y_axis_unique = souradniceY_mapa[:, 0]\n",
    "\n",
    "print(f\"Dimensions of 1D X axis: {x_axis_unique.shape}\")\n",
    "print(f\"Dimensions of 1D Y axis: {y_axis_unique.shape}\")\n",
    "print(f\"Dimensions of 2D elevation data Z: {souradniceZ_mapa.shape}\")\n",
    "\n",
    "terMap_interpolator = RegularGridInterpolator(\n",
    "    (y_axis_unique, x_axis_unique),\n",
    "    souradniceZ_mapa,\n",
    "    bounds_error=False, \n",
    "    fill_value=np.nan\n",
    ")\n",
    "\n",
    "def terMap(px, py):\n",
    "    # Query bilinear interpolation over the terrain map\n",
    "    points_to_query = np.column_stack((py, px))\n",
    "    return terMap_interpolator(points_to_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2c2c2b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1487547.1250, 6395520.5000,       0.0000,       0.0000])\n",
      "INFO: DynamicSystemTAN inicializov√°n s hranicemi mapy:\n",
      "  X: [1476611.42, 1489541.47]\n",
      "  Y: [6384032.63, 6400441.34]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from Systems import DynamicSystemTAN\n",
    "\n",
    "state_dim = 4\n",
    "obs_dim = 3\n",
    "dT = 1\n",
    "q = 1\n",
    "\n",
    "F = torch.tensor([[1.0, 0.0, dT, 0.0],\n",
    "                   [0.0, 1.0, 0.0, dT],\n",
    "                   [0.0, 0.0, 1.0, 0.0],\n",
    "                   [0.0, 0.0, 0.0, 1.0]])\n",
    "\n",
    "Q = q* torch.tensor([[dT**3/3, 0.0, dT**2/2, 0.0],\n",
    "                   [0.0, dT**3/3, 0.0, dT**2/2],\n",
    "                   [dT**2/2, 0.0, dT, 0.0],\n",
    "                   [0.0, dT**2/2, 0.0, dT]])\n",
    "R = torch.tensor([[3.0**2, 0.0, 0.0],\n",
    "                   [0.0, 1.0**2, 0.0],\n",
    "                   [0.0, 0.0, 1.0**2]])\n",
    "\n",
    "initial_velocity_np = souradniceGNSS[:2, 1] - souradniceGNSS[:2, 0]\n",
    "# initial_velocity_np = torch.from_numpy()\n",
    "initial_velocity = torch.from_numpy(np.array([0,0]))\n",
    "\n",
    "initial_position = torch.from_numpy(souradniceGNSS[:2, 0])\n",
    "x_0 = torch.cat([\n",
    "    initial_position,\n",
    "    initial_velocity\n",
    "]).float()\n",
    "print(x_0)\n",
    "\n",
    "P_0 = torch.tensor([[25.0, 0.0, 0.0, 0.0],\n",
    "                    [0.0, 25.0, 0.0, 0.0],\n",
    "                    [0.0, 0.0, 0.5, 0.0],\n",
    "                    [0.0, 0.0, 0.0, 0.5]])\n",
    "import torch.nn.functional as func\n",
    "\n",
    "def h_nl_differentiable(x: torch.Tensor, map_tensor, x_min, x_max, y_min, y_max) -> torch.Tensor:\n",
    "    batch_size = x.shape[0]\n",
    "\n",
    "    px = x[:, 0]\n",
    "    py = x[:, 1]\n",
    "\n",
    "    px_norm = 2.0 * (px - x_min) / (x_max - x_min) - 1.0\n",
    "    py_norm = 2.0 * (py - y_min) / (y_max - y_min) - 1.0\n",
    "\n",
    "    sampling_grid = torch.stack((px_norm, py_norm), dim=1).view(batch_size, 1, 1, 2)\n",
    "\n",
    "    vyska_terenu_batch = func.grid_sample(\n",
    "        map_tensor.expand(batch_size, -1, -1, -1),\n",
    "        sampling_grid, \n",
    "        mode='bilinear', \n",
    "        padding_mode='border',\n",
    "        align_corners=True\n",
    "    )\n",
    "\n",
    "    vyska_terenu = vyska_terenu_batch.view(batch_size)\n",
    "\n",
    "    eps = 1e-12\n",
    "    vx_w, vy_w = x[:, 2], x[:, 3]\n",
    "    norm_v_w = torch.sqrt(vx_w**2 + vy_w**2).clamp(min=eps)\n",
    "    cos_psi = vx_w / norm_v_w\n",
    "    sin_psi = vy_w / norm_v_w\n",
    "\n",
    "    vx_b = cos_psi * vx_w - sin_psi * vy_w \n",
    "    vy_b = sin_psi * vx_w + cos_psi * vy_w\n",
    "\n",
    "    result = torch.stack([vyska_terenu, vx_b, vy_b], dim=1)\n",
    "\n",
    "    return result\n",
    "\n",
    "x_axis_unique = souradniceX_mapa[0, :]\n",
    "y_axis_unique = souradniceY_mapa[:, 0]\n",
    "terMap_tensor = torch.from_numpy(souradniceZ_mapa).float().unsqueeze(0).unsqueeze(0).to(device)\n",
    "x_min, x_max = x_axis_unique.min(), x_axis_unique.max()\n",
    "y_min, y_max = y_axis_unique.min(), y_axis_unique.max()\n",
    "\n",
    "h_wrapper = lambda x: h_nl_differentiable(\n",
    "    x, \n",
    "    map_tensor=terMap_tensor, \n",
    "    x_min=x_min, \n",
    "    x_max=x_max, \n",
    "    y_min=y_min, \n",
    "    y_max=y_max\n",
    ")\n",
    "\n",
    "system_model = DynamicSystemTAN(\n",
    "    state_dim=state_dim,\n",
    "    obs_dim=obs_dim,\n",
    "    Q=Q.float(),\n",
    "    R=R.float(),\n",
    "    Ex0=x_0.float(),\n",
    "    P0=P_0.float(),\n",
    "    F=F.float(),\n",
    "    h=h_wrapper,\n",
    "    x_axis_unique=x_axis_unique, \n",
    "    y_axis_unique=y_axis_unique,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0770f72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from utils import utils\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from copy import deepcopy\n",
    "from state_NN_models import TAN\n",
    "from utils import trainer \n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af0b11ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== NAƒå√çT√ÅN√ç RAW DAT Z DISKU (BEZ EXT. NORMALIZACE) ===\n",
      "üì• Naƒç√≠t√°m F√°zi 1: Seq=10 | Batch=256 ...\n",
      "   üîé Uk√°zka RAW dat (y): [362.96917724609375, -12.126676559448242, 0.16327548027038574]\n",
      "üì• Naƒç√≠t√°m F√°zi 2: Seq=100 | Batch=128 ...\n",
      "üì• Naƒç√≠t√°m F√°zi 3: Seq=300 | Batch=64 ...\n",
      "\n",
      "‚úÖ Data p≈ôipravena. Normalizaci ≈ôe≈°√≠ model.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import os\n",
    "from utils import trainer # P≈ôedpokl√°d√°m, ≈æe toto m√°≈°\n",
    "\n",
    "# === 1. ZJEDNODU≈†EN√ù DATA MANAGER (BEZ NORMALIZACE) ===\n",
    "class NavigationDataManager:\n",
    "    def __init__(self, data_dir):\n",
    "        \"\"\"\n",
    "        Jen dr≈æ√°k na cestu k dat≈Øm. ≈Ω√°dn√° statistika, ≈æ√°dn√° normalizace.\n",
    "        \"\"\"\n",
    "        self.data_dir = data_dir\n",
    "        \n",
    "    def get_dataloader(self, seq_len, split='train', shuffle=True, batch_size=32):\n",
    "        # Sestaven√≠ cesty: ./generated_data/len_100/train.pt\n",
    "        path = os.path.join(self.data_dir, f'len_{seq_len}', f'{split}.pt')\n",
    "        \n",
    "        if not os.path.exists(path):\n",
    "            raise FileNotFoundError(f\"‚ùå Dataset nenalezen: {path}\")\n",
    "            \n",
    "        # Naƒçten√≠ tenzor≈Ø\n",
    "        data = torch.load(path)\n",
    "        x = data['x'] # Stav [Batch, Seq, DimX]\n",
    "        y = data['y'] # Mƒõ≈ôen√≠ [Batch, Seq, DimY] - RAW DATA\n",
    "        \n",
    "        # Vytvo≈ôen√≠ datasetu\n",
    "        dataset = TensorDataset(x, y)\n",
    "        \n",
    "        return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "# === 2. KONFIGURACE CURRICULA ===\n",
    "DATA_DIR = './generated_data_clean_motion'\n",
    "\n",
    "# Inicializace mana≈æera (teƒè je to jen wrapper pro naƒç√≠t√°n√≠ soubor≈Ø)\n",
    "data_manager = NavigationDataManager(DATA_DIR)\n",
    "\n",
    "# Definice f√°z√≠ (zde ≈ô√≠d√≠≈°, jak se tr√©nink vyv√≠j√≠)\n",
    "curriculum_schedule = [\n",
    "    # F√ÅZE 1: Warm-up (Kr√°tk√© sekvence)\n",
    "    {\n",
    "        'phase_id': 1,\n",
    "        'seq_len': 10,          \n",
    "        'epochs': 500,           \n",
    "        'lr': 1e-3, \n",
    "        'batch_size': 256\n",
    "    },\n",
    "    \n",
    "    # F√ÅZE 2: Stabilizace (St≈ôedn√≠ d√©lka)\n",
    "    {\n",
    "        'phase_id': 2,\n",
    "        'seq_len': 100, \n",
    "        'epochs': 200, \n",
    "        'lr': 1e-4,             \n",
    "        'batch_size': 128\n",
    "    },\n",
    "    \n",
    "    # F√ÅZE 3: Long-term Reality (Pln√° d√©lka)\n",
    "    {\n",
    "        'phase_id': 3,\n",
    "        'seq_len': 300,         \n",
    "        'epochs': 200, \n",
    "        'lr': 5e-5,             \n",
    "        'batch_size': 64       # Men≈°√≠ batch kv≈Øli pamƒõti GPU u dlouh√Ωch sekvenc√≠\n",
    "    }\n",
    "]\n",
    "\n",
    "# === 3. NAƒå√çT√ÅN√ç DO PAMƒöTI (CACHING) ===\n",
    "print(\"\\n=== NAƒå√çT√ÅN√ç RAW DAT Z DISKU (BEZ EXT. NORMALIZACE) ===\")\n",
    "datasets_cache = {} \n",
    "\n",
    "for phase in curriculum_schedule:\n",
    "    seq_len = phase['seq_len']\n",
    "    bs = phase['batch_size']\n",
    "    \n",
    "    print(f\"üì• Naƒç√≠t√°m F√°zi {phase['phase_id']}: Seq={seq_len} | Batch={bs} ...\")\n",
    "    \n",
    "    try:\n",
    "        # Pou≈æit√≠ DataManageru\n",
    "        train_loader = data_manager.get_dataloader(seq_len=seq_len, split='train', shuffle=True, batch_size=bs)\n",
    "        val_loader = data_manager.get_dataloader(seq_len=seq_len, split='val', shuffle=False, batch_size=bs)\n",
    "        \n",
    "        # Ulo≈æen√≠ do cache\n",
    "        datasets_cache[phase['phase_id']] = (train_loader, val_loader)\n",
    "        \n",
    "        # Rychl√° kontrola pro jistotu\n",
    "        x_ex, y_ex = next(iter(train_loader))\n",
    "        if phase['phase_id'] == 1:\n",
    "            print(f\"   üîé Uk√°zka RAW dat (y): {y_ex[0, 0, :].tolist()}\") \n",
    "            # Mƒõl bys vidƒõt velk√° ƒç√≠sla (nap≈ô. 250.0) a mal√° (0.2), ne ~0.0\n",
    "        \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"   ‚ö†Ô∏è CHYBA: {e}\")\n",
    "        # raise e # Odkomentuj, pokud chce≈°, aby to spadlo p≈ôi chybƒõ\n",
    "\n",
    "print(\"\\n‚úÖ Data p≈ôipravena. Normalizaci ≈ôe≈°√≠ model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a5daecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== INICIALIZACE NOV√âHO MODELU ===\n",
      "DEBUG: Layer 'output_final_linear.0' initialized near zero (Start K=0).\n",
      "StateKalmanNetTAN(\n",
      "  (dnn): DNN_KalmanNetTAN(\n",
      "    (input_layer): Sequential(\n",
      "      (0): Linear(in_features=14, out_features=560, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (gru): GRU(560, 150)\n",
      "    (output_hidden_layer): Sequential(\n",
      "      (0): Linear(in_features=150, out_features=48, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (output_final_linear): Sequential(\n",
      "      (0): Linear(in_features=48, out_features=12, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# --- A) KONFIGURACE S√çTƒö ---\n",
    "print(\"=== INICIALIZACE NOV√âHO MODELU ===\")\n",
    "state_knet2 = TAN.StateKalmanNetTAN(\n",
    "        system_model=system_model, \n",
    "        device=device,\n",
    "        hidden_size_multiplier=10,       \n",
    "        output_layer_multiplier=4,\n",
    "        num_gru_layers=1,\n",
    "        gru_hidden_dim_multiplier=6      \n",
    ").to(device)\n",
    "\n",
    "print(state_knet2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a41ed491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Naƒç√≠t√°n√≠ vah ze slo≈æky: /home/luky/skola/KalmanNet-main/TAN/real_trajectory/weights ---\n",
      "\n",
      "‚úÖ State KalmanNet: V√°hy √∫spƒõ≈°nƒõ naƒçteny z 'most_consistent_knet.pth'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "# ==========================================\n",
    "# 1. NASTAVEN√ç N√ÅZV≈Æ SOUBOR≈Æ (Manu√°ln√≠ vstup)\n",
    "# ==========================================\n",
    "# Slo≈æka, kde jsou v√°hy ulo≈æeny\n",
    "WEIGHTS_DIR = 'weights'\n",
    "\n",
    "# Zde dopl≈à p≈ôesn√© n√°zvy soubor≈Ø .pth\n",
    "# KNET_FILENAME = 'best_Knet_test_results.pth'                                          # P≈ô√≠klad\n",
    "KNET_FILENAME = 'most_consistent_knet.pth'\n",
    "\n",
    "# ==========================================\n",
    "# 2. FUNKCE PRO BEZPEƒåN√â NAƒåTEN√ç\n",
    "# ==========================================\n",
    "def load_pretrained_weights(model, filename, model_name):\n",
    "    filepath = os.path.join(WEIGHTS_DIR, filename)\n",
    "    \n",
    "    if not os.path.exists(filepath):\n",
    "        print(f\"‚ö†Ô∏è  VAROV√ÅN√ç: Soubor '{filename}' pro {model_name} nebyl nalezen v '{WEIGHTS_DIR}'.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        # Naƒçten√≠ na spr√°vn√© za≈ô√≠zen√≠ (CPU/GPU)\n",
    "        checkpoint = torch.load(filepath, map_location=device)\n",
    "        \n",
    "        # Detekce, zda jde o ƒçist√Ω state_dict nebo slovn√≠k checkpointu\n",
    "        if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:\n",
    "            # Pokud je to checkpoint z traineru, vyt√°hneme jen v√°hy modelu\n",
    "            state_dict = checkpoint['model_state_dict']\n",
    "        elif isinstance(checkpoint, dict) and 'state_dict' in checkpoint:\n",
    "            state_dict = checkpoint['state_dict']\n",
    "        else:\n",
    "            # P≈ôedpokl√°d√°me, ≈æe je to p≈ô√≠mo state_dict\n",
    "            state_dict = checkpoint\n",
    "\n",
    "        # Nahr√°n√≠ vah do modelu\n",
    "        model.load_state_dict(state_dict)\n",
    "        \n",
    "        # D≈Øle≈æit√©: P≈ôepnut√≠ do evaluaƒçn√≠ho m√≥du (vypne Dropout, fixuje BatchNorm)\n",
    "        model.eval()\n",
    "        \n",
    "        print(f\"‚úÖ {model_name}: V√°hy √∫spƒõ≈°nƒõ naƒçteny z '{filename}'.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå CHYBA: Nepoda≈ôilo se naƒç√≠st v√°hy pro {model_name}.\\n   D≈Øvod: {e}\")\n",
    "\n",
    "# ==========================================\n",
    "# 3. SPU≈†TƒöN√ç NAƒå√çT√ÅN√ç\n",
    "# ==========================================\n",
    "print(f\"--- Naƒç√≠t√°n√≠ vah ze slo≈æky: {os.path.abspath(WEIGHTS_DIR)} ---\\n\")\n",
    "\n",
    "# Naƒçten√≠ State KalmanNet\n",
    "load_pretrained_weights(state_knet2, KNET_FILENAME, \"State KalmanNet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c0a86e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    # save model.\n",
    "    save_path = f'most_consistent_knet.pth'\n",
    "    torch.save(state_knet2.state_dict(), save_path)\n",
    "    print(f\"Model saved to '{save_path}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1ec4ec",
   "metadata": {},
   "source": [
    "# Test na realne trajektorii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6d79a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SPU≈†TƒöN√ç MONTE CARLO SIMULACE (20 bƒõh≈Ø) ===\n",
      "Modely: KalmanNet vs. UKF vs. PF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Simulace:   0%|          | 0/20 [00:05<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 99\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m# UKF\u001b[39;00m\n\u001b[1;32m     98\u001b[0m ukf_ideal \u001b[38;5;241m=\u001b[39m Filters\u001b[38;5;241m.\u001b[39mUnscentedKalmanFilter(system_model)\n\u001b[0;32m---> 99\u001b[0m ukf_res \u001b[38;5;241m=\u001b[39m \u001b[43mukf_ideal\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_sequence\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_seq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_for_filters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m    \u001b[49m\u001b[43mEx0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrue_init_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Spr√°vn√Ω start\u001b[39;49;00m\n\u001b[1;32m    102\u001b[0m \u001b[43m    \u001b[49m\u001b[43mP0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msystem_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mP0\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m x_est_ukf \u001b[38;5;241m=\u001b[39m ukf_res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx_filtered\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m    106\u001b[0m \u001b[38;5;66;03m# PF\u001b[39;00m\n",
      "File \u001b[0;32m~/skola/KalmanNet-main/Filters/UnscentedKalmanFilter.py:131\u001b[0m, in \u001b[0;36mUnscentedKalmanFilter.process_sequence\u001b[0;34m(self, y_seq, Ex0, P0)\u001b[0m\n\u001b[1;32m    129\u001b[0m P_predict_k \u001b[38;5;241m=\u001b[39m P0\u001b[38;5;241m.\u001b[39mclone()\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(seq_len):\n\u001b[0;32m--> 131\u001b[0m     x_filtered, P_filtered, K, innovation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_predict_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mP_predict_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_seq\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m     x_predict_k_plus_1, P_predict_k_plus_1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict_step(x_filtered, P_filtered)\n\u001b[1;32m    135\u001b[0m     x_predict_k \u001b[38;5;241m=\u001b[39m x_predict_k_plus_1\n",
      "File \u001b[0;32m~/skola/KalmanNet-main/Filters/UnscentedKalmanFilter.py:79\u001b[0m, in \u001b[0;36mUnscentedKalmanFilter.update_step\u001b[0;34m(self, x_predict, P_predict, y_t)\u001b[0m\n\u001b[1;32m     75\u001b[0m y_t \u001b[38;5;241m=\u001b[39m y_t\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobs_dim, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     77\u001b[0m sigma_points \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sigma_points(x_predict, P_predict)\n\u001b[0;32m---> 79\u001b[0m measurement_points \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mh\u001b[49m\u001b[43m(\u001b[49m\u001b[43msigma_points\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m     81\u001b[0m y_hat \u001b[38;5;241m=\u001b[39m (measurement_points \u001b[38;5;241m@\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     83\u001b[0m y_diff \u001b[38;5;241m=\u001b[39m measurement_points \u001b[38;5;241m-\u001b[39m y_hat\n",
      "File \u001b[0;32m~/skola/KalmanNet-main/Systems/DynamicSystem_for_TAN.py:90\u001b[0m, in \u001b[0;36mDynamicSystemTAN.h\u001b[0;34m(self, x_in)\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mbmm(H_batch, x_batch\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;66;03m# Aplikujeme neline√°rn√≠ funkci p≈ô√≠mo na cel√Ω d√°vkov√Ω tenzor.\u001b[39;00m\n\u001b[0;32m---> 90\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_h_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_batch\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 79\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     76\u001b[0m x_min, x_max \u001b[38;5;241m=\u001b[39m x_axis_unique\u001b[38;5;241m.\u001b[39mmin(), x_axis_unique\u001b[38;5;241m.\u001b[39mmax()\n\u001b[1;32m     77\u001b[0m y_min, y_max \u001b[38;5;241m=\u001b[39m y_axis_unique\u001b[38;5;241m.\u001b[39mmin(), y_axis_unique\u001b[38;5;241m.\u001b[39mmax()\n\u001b[0;32m---> 79\u001b[0m h_wrapper \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mh_nl_differentiable\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmap_tensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mterMap_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_min\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_min\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_max\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_min\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_min\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_max\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_max\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m system_model \u001b[38;5;241m=\u001b[39m DynamicSystemTAN(\n\u001b[1;32m     89\u001b[0m     state_dim\u001b[38;5;241m=\u001b[39mstate_dim,\n\u001b[1;32m     90\u001b[0m     obs_dim\u001b[38;5;241m=\u001b[39mobs_dim,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     99\u001b[0m     device\u001b[38;5;241m=\u001b[39mdevice\n\u001b[1;32m    100\u001b[0m )\n",
      "Cell \u001b[0;32mIn[4], line 62\u001b[0m, in \u001b[0;36mh_nl_differentiable\u001b[0;34m(x, map_tensor, x_min, x_max, y_min, y_max)\u001b[0m\n\u001b[1;32m     60\u001b[0m eps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-12\u001b[39m\n\u001b[1;32m     61\u001b[0m vx_w, vy_w \u001b[38;5;241m=\u001b[39m x[:, \u001b[38;5;241m2\u001b[39m], x[:, \u001b[38;5;241m3\u001b[39m]\n\u001b[0;32m---> 62\u001b[0m norm_v_w \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msqrt(\u001b[43mvx_w\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m \u001b[38;5;241m+\u001b[39m vy_w\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mclamp(\u001b[38;5;28mmin\u001b[39m\u001b[38;5;241m=\u001b[39meps)\n\u001b[1;32m     63\u001b[0m cos_psi \u001b[38;5;241m=\u001b[39m vx_w \u001b[38;5;241m/\u001b[39m norm_v_w\n\u001b[1;32m     64\u001b[0m sin_psi \u001b[38;5;241m=\u001b[39m vy_w \u001b[38;5;241m/\u001b[39m norm_v_w\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor.py:40\u001b[0m, in \u001b[0;36m_handle_torch_function_and_wrap_type_error_to_not_implemented.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m has_torch_function(args):\n\u001b[1;32m     39\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(wrapped, args, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd # Pro hezkou tabulku\n",
    "import Filters\n",
    "from tqdm import tqdm\n",
    "real_traj_np = souradniceGNSS[:2, :].T \n",
    "\n",
    "real_traj_tensor = torch.from_numpy(real_traj_np).float().to(device)\n",
    "train_source_tensor = real_traj_tensor[:, :]\n",
    "# --- POMOCN√Å FUNKCE PRO GENEROW√ÅN√ç DAT ---\n",
    "def get_reference_test_set(system, real_traj_tensor, reverse=False):\n",
    "    # O≈ô√≠znut√≠ trajektorie (pokud je pot≈ôeba)\n",
    "    # real_traj_tensor = real_traj_tensor[:1050,:] \n",
    "    \n",
    "    device = system.Ex0.device\n",
    "    \n",
    "    # P≈ôedpoklad: mat_data je glob√°ln√≠ promƒõnn√° s naƒçten√Ωm .mat souborem\n",
    "    hB_np = mat_data['hB']\n",
    "    real_hB_tensor = torch.from_numpy(hB_np).float().to(device).view(-1)\n",
    "\n",
    "    pos_full = real_traj_tensor.clone().to(device)\n",
    "    \n",
    "    deltas = pos_full[1:] - pos_full[:-1] \n",
    "    last_vel = deltas[-1:]\n",
    "    velocities = torch.cat([deltas, last_vel], dim=0) # [T, 2]\n",
    "    \n",
    "    x_traj_flat = torch.cat([pos_full, velocities], dim=1) # [T, 4]\n",
    "    \n",
    "    # Generov√°n√≠ mƒõ≈ôen√≠ (s n√°hodn√Ωm ≈°umem uvnit≈ô system.measure)\n",
    "    y_traj_flat = system.measure(x_traj_flat) # [T, 3]\n",
    "    \n",
    "    # Nahrazen√≠ barometru re√°ln√Ωmi daty (pokud je to ≈æ√°douc√≠)\n",
    "    seq_len = x_traj_flat.shape[0]\n",
    "    # Pokud chce≈° simulovat ƒçistƒõ syntetick√Ω ≈°um barometru, tento ≈ô√°dek zakomentuj:\n",
    "    y_traj_flat[:, 0] = real_hB_tensor[:seq_len] \n",
    "    \n",
    "    x_ref = x_traj_flat.unsqueeze(0) # [1, T, 4]\n",
    "    y_ref = y_traj_flat.unsqueeze(0) # [1, T, 3]\n",
    "    \n",
    "    return x_ref, y_ref\n",
    "\n",
    "\n",
    "# --- KONFIGURACE MC ---\n",
    "MC_ITERATIONS = 20  # Nastav rozumn√© ƒç√≠slo (pro 100 graf≈Ø by to zahltilo notebook)\n",
    "PLOT_PER_ITERATION = True # Zda vykreslovat grafy pro ka≈æd√Ω bƒõh\n",
    "\n",
    "print(f\"=== SPU≈†TƒöN√ç MONTE CARLO SIMULACE ({MC_ITERATIONS} bƒõh≈Ø) ===\")\n",
    "print(\"Modely: KalmanNet vs. UKF vs. PF\")\n",
    "\n",
    "# 1. P≈ô√≠prava Ground Truth (GT)\n",
    "real_traj_tensor = torch.from_numpy(real_traj_np).float().to(device)\n",
    "# Z√≠sk√°me GT stavy (X) jen jednou, proto≈æe trajektorie je fixn√≠\n",
    "# Mƒõ≈ôen√≠ (Y) se bude mƒõnit v ka≈æd√© iteraci kv≈Øli ≈°umu\n",
    "x_ref_tensor_static, _ = get_reference_test_set(system_model, real_traj_tensor)\n",
    "x_gt = x_ref_tensor_static.squeeze().cpu().numpy()\n",
    "seq_len = x_gt.shape[0]\n",
    "\n",
    "# 2. Inicializace pro sbƒõr dat\n",
    "detailed_results = [] # Seznam slovn√≠k≈Ø pro DataFrame\n",
    "agg_mse = {\"KNet\": [], \"UKF\": [], \"PF\": []}\n",
    "agg_pos = {\"KNet\": [], \"UKF\": [], \"PF\": []}\n",
    "\n",
    "# Ujist√≠me se, ≈æe KNet je v eval m√≥du\n",
    "state_knet2.eval()\n",
    "\n",
    "# --- HLAVN√ç SMYƒåKA ---\n",
    "for i in tqdm(range(MC_ITERATIONS), desc=\"Simulace\"):\n",
    "    \n",
    "    # A) Generov√°n√≠ nov√©ho mƒõ≈ôen√≠ (s nov√Ωm n√°hodn√Ωm ≈°umem)\n",
    "    # Vol√°me funkci znovu, abychom dostali Y s jinou realizac√≠ ≈°umu (pokud system.measure ≈°um√≠)\n",
    "    _, y_ref_tensor = get_reference_test_set(system_model, real_traj_tensor)\n",
    "    \n",
    "    # B) Inference: KalmanNet\n",
    "    with torch.no_grad():\n",
    "        initial_state = x_ref_tensor_static[:, 0, :] # [1, 4]\n",
    "        state_knet2.reset(batch_size=1, initial_state=initial_state)\n",
    "        \n",
    "        knet_preds = []\n",
    "        y_input = y_ref_tensor \n",
    "        \n",
    "        for t in range(1, seq_len):\n",
    "            y_t = y_input[:, t, :]\n",
    "            x_est = state_knet2.step(y_t)\n",
    "            knet_preds.append(x_est)\n",
    "            \n",
    "        knet_preds_tensor = torch.stack(knet_preds, dim=1)\n",
    "        full_knet_est = torch.cat([initial_state.unsqueeze(1), knet_preds_tensor], dim=1)\n",
    "        x_est_knet = full_knet_est.squeeze().cpu().numpy()\n",
    "\n",
    "    # C) Inference: UKF & PF\n",
    "    y_for_filters = y_ref_tensor.squeeze(0) \n",
    "    \n",
    "    # !!! KL√çƒåOV√Å OPRAVA: Pou≈æijeme SKUTEƒåN√ù startovn√≠ bod trajektorie !!!\n",
    "    true_init_state = x_ref_tensor_static[0, 0, :] \n",
    "    \n",
    "    # UKF\n",
    "    ukf_ideal = Filters.UnscentedKalmanFilter(system_model)\n",
    "    ukf_res = ukf_ideal.process_sequence(\n",
    "        y_seq=y_for_filters,\n",
    "        Ex0=true_init_state, # Spr√°vn√Ω start\n",
    "        P0=system_model.P0\n",
    "    )\n",
    "    x_est_ukf = ukf_res['x_filtered'].cpu().numpy()\n",
    "\n",
    "    # PF\n",
    "    pf = Filters.ParticleFilter(system_model, num_particles=10000) # Poƒçet ƒç√°stic dle v√Ωkonu\n",
    "    pf_res = pf.process_sequence(\n",
    "        y_seq=y_for_filters,\n",
    "        Ex0=true_init_state, # Spr√°vn√Ω start\n",
    "        P0=system_model.P0\n",
    "    )\n",
    "    x_est_pf = pf_res['x_filtered'].cpu().numpy()\n",
    "\n",
    "    \n",
    "    # D) V√Ωpoƒçet chyb pro tento bƒõh\n",
    "    # KNet\n",
    "    diff_knet = x_est_knet - x_gt\n",
    "    mse_knet = np.mean(diff_knet**2)\n",
    "    pos_err_knet = np.mean(np.sqrt(diff_knet[:, 0]**2 + diff_knet[:, 1]**2))\n",
    "    \n",
    "    # UKF\n",
    "    diff_ukf = x_est_ukf - x_gt\n",
    "    mse_ukf = np.mean(diff_ukf**2)\n",
    "    pos_err_ukf = np.mean(np.sqrt(diff_ukf[:, 0]**2 + diff_ukf[:, 1]**2))\n",
    "    \n",
    "    # PF\n",
    "    diff_pf = x_est_pf - x_gt\n",
    "    mse_pf = np.mean(diff_pf**2)\n",
    "    pos_err_pf = np.mean(np.sqrt(diff_pf[:, 0]**2 + diff_pf[:, 1]**2))\n",
    "    \n",
    "    # Ulo≈æen√≠ do agreg√°toru\n",
    "    agg_mse[\"KNet\"].append(mse_knet)\n",
    "    agg_pos[\"KNet\"].append(pos_err_knet)\n",
    "    agg_mse[\"UKF\"].append(mse_ukf)\n",
    "    agg_pos[\"UKF\"].append(pos_err_ukf)\n",
    "    agg_mse[\"PF\"].append(mse_pf)\n",
    "    agg_pos[\"PF\"].append(pos_err_pf)\n",
    "\n",
    "    # Ulo≈æen√≠ do detailn√≠ho seznamu\n",
    "    detailed_results.append({\n",
    "        \"Run_ID\": i + 1,\n",
    "        \"KNet_MSE\": mse_knet,\n",
    "        \"UKF_MSE\": mse_ukf,\n",
    "        \"PF_MSE\": mse_pf,\n",
    "        \"KNet_PosErr\": pos_err_knet,\n",
    "        \"UKF_PosErr\": pos_err_ukf,\n",
    "        \"PF_PosErr\": pos_err_pf\n",
    "    })\n",
    "    \n",
    "    # E) Vykreslen√≠ grafu pro TENTO bƒõh\n",
    "    if PLOT_PER_ITERATION:\n",
    "        fig = plt.figure(figsize=(12, 6))\n",
    "        plt.plot(x_gt[:, 0], x_gt[:, 1], 'k-', linewidth=3, alpha=0.3, label='Ground Truth')\n",
    "        \n",
    "        plt.plot(x_est_knet[:, 0], x_est_knet[:, 1], 'g-', linewidth=1.5, label=f'KalmanNet (MSE: {mse_knet:.1f})')\n",
    "        plt.plot(x_est_ukf[:, 0], x_est_ukf[:, 1], 'b--', linewidth=1, label=f'UKF (MSE: {mse_ukf:.1f})')\n",
    "        plt.plot(x_est_pf[:, 0], x_est_pf[:, 1], 'r:', linewidth=1, alpha=0.8, label=f'PF (MSE: {mse_pf:.1f})')\n",
    "        \n",
    "        plt.title(f\"Run {i+1}/{MC_ITERATIONS}: Trajectory Comparison\")\n",
    "        plt.xlabel(\"X [m]\")\n",
    "        plt.ylabel(\"Y [m]\")\n",
    "        plt.legend()\n",
    "        plt.axis('equal')\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "# --- V√ùPIS V√ùSLEDK≈Æ ---\n",
    "\n",
    "# 1. Detailn√≠ tabulka v≈°ech bƒõh≈Ø\n",
    "df_results = pd.DataFrame(detailed_results)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"DETAILN√ç V√ùSLEDKY PO JEDNOTLIV√ùCH BƒöZ√çCH\")\n",
    "print(\"=\"*80)\n",
    "# Form√°tov√°n√≠ tabulky pro hezƒç√≠ v√Ωpis\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "print(df_results[[\"Run_ID\", \"KNet_MSE\", \"UKF_MSE\", \"PF_MSE\", \"KNet_PosErr\", \"UKF_PosErr\", \"PF_PosErr\"]])\n",
    "\n",
    "# 2. Souhrnn√° statistika\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"SOUHRNN√Å STATISTIKA ({MC_ITERATIONS} bƒõh≈Ø)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def get_stats(key):\n",
    "    return np.mean(agg_mse[key]), np.std(agg_mse[key]), np.mean(agg_pos[key]), np.std(agg_pos[key])\n",
    "\n",
    "knet_stats = get_stats(\"KNet\")\n",
    "ukf_stats = get_stats(\"UKF\")\n",
    "pf_stats = get_stats(\"PF\")\n",
    "\n",
    "print(f\"{'Model':<15} | {'MSE (Mean ¬± Std)':<25} | {'Pos Error (Mean ¬± Std)':<25}\")\n",
    "print(\"-\" * 75)\n",
    "print(f\"{'KalmanNet':<15} | {knet_stats[0]:.1f} ¬± {knet_stats[1]:.1f} | {knet_stats[2]:.2f} ¬± {knet_stats[3]:.2f} m\")\n",
    "print(f\"{'UKF':<15} | {ukf_stats[0]:.1f} ¬± {ukf_stats[1]:.1f} | {ukf_stats[2]:.2f} ¬± {ukf_stats[3]:.2f} m\")\n",
    "print(f\"{'PF':<15} | {pf_stats[0]:.1f} ¬± {pf_stats[1]:.1f} | {pf_stats[2]:.2f} ¬± {pf_stats[3]:.2f} m\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 3. Fin√°ln√≠ Boxplot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.boxplot([agg_pos[\"KNet\"], agg_pos[\"UKF\"], agg_pos[\"PF\"]], labels=['KalmanNet', 'UKF', 'PF'], patch_artist=True)\n",
    "plt.title(f\"Position Error Distribution ({MC_ITERATIONS} runs)\")\n",
    "plt.ylabel(\"Avg Position Error [m]\")\n",
    "plt.grid(True, axis='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47670fcc",
   "metadata": {},
   "source": [
    "# Test na synteticke trajektorii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df30b0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd # Pro hezkou tabulku\n",
    "import Filters\n",
    "from tqdm import tqdm\n",
    "real_traj_np = souradniceGNSS[:2, :].T \n",
    "\n",
    "real_traj_tensor = torch.from_numpy(real_traj_np).float().to(device)\n",
    "train_source_tensor = real_traj_tensor[:, :]\n",
    "# --- POMOCN√Å FUNKCE PRO GENEROW√ÅN√ç DAT ---\n",
    "def get_reference_test_set(system, real_traj_tensor, reverse=False):\n",
    "    # O≈ô√≠znut√≠ trajektorie (pokud je pot≈ôeba)\n",
    "    # real_traj_tensor = real_traj_tensor[:1050,:] \n",
    "    \n",
    "    device = system.Ex0.device\n",
    "    \n",
    "    # P≈ôedpoklad: mat_data je glob√°ln√≠ promƒõnn√° s naƒçten√Ωm .mat souborem\n",
    "    # hB_np = mat_data['hB']\n",
    "    # real_hB_tensor = torch.from_numpy(hB_np).float().to(device).view(-1)\n",
    "\n",
    "    pos_full = real_traj_tensor.clone().to(device)\n",
    "    \n",
    "    deltas = pos_full[1:] - pos_full[:-1] \n",
    "    last_vel = deltas[-1:]\n",
    "    velocities = torch.cat([deltas, last_vel], dim=0) # [T, 2]\n",
    "    \n",
    "    x_traj_flat = torch.cat([pos_full, velocities], dim=1) # [T, 4]\n",
    "    \n",
    "    # Generov√°n√≠ mƒõ≈ôen√≠ (s n√°hodn√Ωm ≈°umem uvnit≈ô system.measure)\n",
    "    y_traj_flat = system.measure(x_traj_flat) # [T, 3]\n",
    "    \n",
    "    # Nahrazen√≠ barometru re√°ln√Ωmi daty (pokud je to ≈æ√°douc√≠)\n",
    "    seq_len = x_traj_flat.shape[0]\n",
    "    # Pokud chce≈° simulovat ƒçistƒõ syntetick√Ω ≈°um barometru, tento ≈ô√°dek zakomentuj:\n",
    "    # y_traj_flat[:, 0] = real_hB_tensor[:seq_len] \n",
    "    \n",
    "    x_ref = x_traj_flat.unsqueeze(0) # [1, T, 4]\n",
    "    y_ref = y_traj_flat.unsqueeze(0) # [1, T, 3]\n",
    "    \n",
    "    return x_ref, y_ref\n",
    "\n",
    "\n",
    "# --- KONFIGURACE MC ---\n",
    "MC_ITERATIONS = 10  # Nastav rozumn√© ƒç√≠slo (pro 100 graf≈Ø by to zahltilo notebook)\n",
    "PLOT_PER_ITERATION = True # Zda vykreslovat grafy pro ka≈æd√Ω bƒõh\n",
    "\n",
    "print(f\"=== SPU≈†TƒöN√ç MONTE CARLO SIMULACE ({MC_ITERATIONS} bƒõh≈Ø) ===\")\n",
    "print(\"Modely: KalmanNet vs. UKF vs. PF\")\n",
    "\n",
    "# 1. P≈ô√≠prava Ground Truth (GT)\n",
    "real_traj_tensor = torch.from_numpy(real_traj_np).float().to(device)\n",
    "# Z√≠sk√°me GT stavy (X) jen jednou, proto≈æe trajektorie je fixn√≠\n",
    "# Mƒõ≈ôen√≠ (Y) se bude mƒõnit v ka≈æd√© iteraci kv≈Øli ≈°umu\n",
    "x_ref_tensor_static, _ = get_reference_test_set(system_model, real_traj_tensor)\n",
    "x_gt = x_ref_tensor_static.squeeze().cpu().numpy()\n",
    "seq_len = x_gt.shape[0]\n",
    "\n",
    "# 2. Inicializace pro sbƒõr dat\n",
    "detailed_results = [] # Seznam slovn√≠k≈Ø pro DataFrame\n",
    "agg_mse = {\"KNet\": [], \"UKF\": [], \"PF\": []}\n",
    "agg_pos = {\"KNet\": [], \"UKF\": [], \"PF\": []}\n",
    "\n",
    "# Ujist√≠me se, ≈æe KNet je v eval m√≥du\n",
    "state_knet2.eval()\n",
    "\n",
    "# --- HLAVN√ç SMYƒåKA ---\n",
    "for i in tqdm(range(MC_ITERATIONS), desc=\"Simulace\"):\n",
    "    \n",
    "    # A) Generov√°n√≠ nov√©ho mƒõ≈ôen√≠ (s nov√Ωm n√°hodn√Ωm ≈°umem)\n",
    "    # Vol√°me funkci znovu, abychom dostali Y s jinou realizac√≠ ≈°umu (pokud system.measure ≈°um√≠)\n",
    "    _, y_ref_tensor = get_reference_test_set(system_model, real_traj_tensor)\n",
    "    \n",
    "    # B) Inference: KalmanNet\n",
    "    with torch.no_grad():\n",
    "        initial_state = x_ref_tensor_static[:, 0, :] # [1, 4]\n",
    "        state_knet2.reset(batch_size=1, initial_state=initial_state)\n",
    "        \n",
    "        knet_preds = []\n",
    "        y_input = y_ref_tensor \n",
    "        \n",
    "        for t in range(1, seq_len):\n",
    "            y_t = y_input[:, t, :]\n",
    "            x_est = state_knet2.step(y_t)\n",
    "            knet_preds.append(x_est)\n",
    "            \n",
    "        knet_preds_tensor = torch.stack(knet_preds, dim=1)\n",
    "        full_knet_est = torch.cat([initial_state.unsqueeze(1), knet_preds_tensor], dim=1)\n",
    "        x_est_knet = full_knet_est.squeeze().cpu().numpy()\n",
    "\n",
    "    # C) Inference: UKF & PF\n",
    "    y_for_filters = y_ref_tensor.squeeze(0) \n",
    "    \n",
    "    # !!! KL√çƒåOV√Å OPRAVA: Pou≈æijeme SKUTEƒåN√ù startovn√≠ bod trajektorie !!!\n",
    "    true_init_state = x_ref_tensor_static[0, 0, :] \n",
    "    \n",
    "    # UKF\n",
    "    ukf_ideal = Filters.UnscentedKalmanFilter(system_model)\n",
    "    ukf_res = ukf_ideal.process_sequence(\n",
    "        y_seq=y_for_filters,\n",
    "        Ex0=true_init_state, # Spr√°vn√Ω start\n",
    "        P0=system_model.P0\n",
    "    )\n",
    "    x_est_ukf = ukf_res['x_filtered'].cpu().numpy()\n",
    "\n",
    "    # PF\n",
    "    pf = Filters.ParticleFilter(system_model, num_particles=10000) # Poƒçet ƒç√°stic dle v√Ωkonu\n",
    "    pf_res = pf.process_sequence(\n",
    "        y_seq=y_for_filters,\n",
    "        Ex0=true_init_state, # Spr√°vn√Ω start\n",
    "        P0=system_model.P0\n",
    "    )\n",
    "    x_est_pf = pf_res['x_filtered'].cpu().numpy()\n",
    "\n",
    "    \n",
    "    # D) V√Ωpoƒçet chyb pro tento bƒõh\n",
    "    # KNet\n",
    "    diff_knet = x_est_knet - x_gt\n",
    "    mse_knet = np.mean(diff_knet**2)\n",
    "    pos_err_knet = np.mean(np.sqrt(diff_knet[:, 0]**2 + diff_knet[:, 1]**2))\n",
    "    \n",
    "    # UKF\n",
    "    diff_ukf = x_est_ukf - x_gt\n",
    "    mse_ukf = np.mean(diff_ukf**2)\n",
    "    pos_err_ukf = np.mean(np.sqrt(diff_ukf[:, 0]**2 + diff_ukf[:, 1]**2))\n",
    "    \n",
    "    # PF\n",
    "    diff_pf = x_est_pf - x_gt\n",
    "    mse_pf = np.mean(diff_pf**2)\n",
    "    pos_err_pf = np.mean(np.sqrt(diff_pf[:, 0]**2 + diff_pf[:, 1]**2))\n",
    "    \n",
    "    # Ulo≈æen√≠ do agreg√°toru\n",
    "    agg_mse[\"KNet\"].append(mse_knet)\n",
    "    agg_pos[\"KNet\"].append(pos_err_knet)\n",
    "    agg_mse[\"UKF\"].append(mse_ukf)\n",
    "    agg_pos[\"UKF\"].append(pos_err_ukf)\n",
    "    agg_mse[\"PF\"].append(mse_pf)\n",
    "    agg_pos[\"PF\"].append(pos_err_pf)\n",
    "\n",
    "    # Ulo≈æen√≠ do detailn√≠ho seznamu\n",
    "    detailed_results.append({\n",
    "        \"Run_ID\": i + 1,\n",
    "        \"KNet_MSE\": mse_knet,\n",
    "        \"UKF_MSE\": mse_ukf,\n",
    "        \"PF_MSE\": mse_pf,\n",
    "        \"KNet_PosErr\": pos_err_knet,\n",
    "        \"UKF_PosErr\": pos_err_ukf,\n",
    "        \"PF_PosErr\": pos_err_pf\n",
    "    })\n",
    "    \n",
    "    # E) Vykreslen√≠ grafu pro TENTO bƒõh\n",
    "    if PLOT_PER_ITERATION:\n",
    "        fig = plt.figure(figsize=(12, 6))\n",
    "        plt.plot(x_gt[:, 0], x_gt[:, 1], 'k-', linewidth=3, alpha=0.3, label='Ground Truth')\n",
    "        \n",
    "        plt.plot(x_est_knet[:, 0], x_est_knet[:, 1], 'g-', linewidth=1.5, label=f'KalmanNet (MSE: {mse_knet:.1f})')\n",
    "        plt.plot(x_est_ukf[:, 0], x_est_ukf[:, 1], 'b--', linewidth=1, label=f'UKF (MSE: {mse_ukf:.1f})')\n",
    "        plt.plot(x_est_pf[:, 0], x_est_pf[:, 1], 'r:', linewidth=1, alpha=0.8, label=f'PF (MSE: {mse_pf:.1f})')\n",
    "        \n",
    "        plt.title(f\"Run {i+1}/{MC_ITERATIONS}: Trajectory Comparison\")\n",
    "        plt.xlabel(\"X [m]\")\n",
    "        plt.ylabel(\"Y [m]\")\n",
    "        plt.legend()\n",
    "        plt.axis('equal')\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "# --- V√ùPIS V√ùSLEDK≈Æ ---\n",
    "\n",
    "# 1. Detailn√≠ tabulka v≈°ech bƒõh≈Ø\n",
    "df_results = pd.DataFrame(detailed_results)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"DETAILN√ç V√ùSLEDKY PO JEDNOTLIV√ùCH BƒöZ√çCH\")\n",
    "print(\"=\"*80)\n",
    "# Form√°tov√°n√≠ tabulky pro hezƒç√≠ v√Ωpis\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "print(df_results[[\"Run_ID\", \"KNet_MSE\", \"UKF_MSE\", \"PF_MSE\", \"KNet_PosErr\", \"UKF_PosErr\", \"PF_PosErr\"]])\n",
    "\n",
    "# 2. Souhrnn√° statistika\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"SOUHRNN√Å STATISTIKA ({MC_ITERATIONS} bƒõh≈Ø)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def get_stats(key):\n",
    "    return np.mean(agg_mse[key]), np.std(agg_mse[key]), np.mean(agg_pos[key]), np.std(agg_pos[key])\n",
    "\n",
    "knet_stats = get_stats(\"KNet\")\n",
    "ukf_stats = get_stats(\"UKF\")\n",
    "pf_stats = get_stats(\"PF\")\n",
    "\n",
    "print(f\"{'Model':<15} | {'MSE (Mean ¬± Std)':<25} | {'Pos Error (Mean ¬± Std)':<25}\")\n",
    "print(\"-\" * 75)\n",
    "print(f\"{'KalmanNet':<15} | {knet_stats[0]:.1f} ¬± {knet_stats[1]:.1f} | {knet_stats[2]:.2f} ¬± {knet_stats[3]:.2f} m\")\n",
    "print(f\"{'UKF':<15} | {ukf_stats[0]:.1f} ¬± {ukf_stats[1]:.1f} | {ukf_stats[2]:.2f} ¬± {ukf_stats[3]:.2f} m\")\n",
    "print(f\"{'PF':<15} | {pf_stats[0]:.1f} ¬± {pf_stats[1]:.1f} | {pf_stats[2]:.2f} ¬± {pf_stats[3]:.2f} m\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 3. Fin√°ln√≠ Boxplot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.boxplot([agg_pos[\"KNet\"], agg_pos[\"UKF\"], agg_pos[\"PF\"]], labels=['KalmanNet', 'UKF', 'PF'], patch_artist=True)\n",
    "plt.title(f\"Position Error Distribution ({MC_ITERATIONS} runs)\")\n",
    "plt.ylabel(\"Avg Position Error [m]\")\n",
    "plt.grid(True, axis='y')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
