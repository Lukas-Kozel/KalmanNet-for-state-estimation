{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24e3857",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from scipy.io import loadmat\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Use the actual notebook working directory\n",
    "nb_dir = Path.cwd()\n",
    "print(f\"Current notebook path: {nb_dir}\")\n",
    "\n",
    "# Optionally add the notebook dir (for local-only imports)\n",
    "if str(nb_dir) not in sys.path:\n",
    "    sys.path.insert(0, str(nb_dir))\n",
    "    print(f\"Added {nb_dir} to sys.path\")\n",
    "\n",
    "# Critically: add the repository root so top-level packages like 'utils' are importable\n",
    "# Notebook path: /home/luky/skola/KalmanNet-main/navigation NCLT dataset/linear_velocity_integration\n",
    "# Repo root is two levels up: /home/luky/skola/KalmanNet-main\n",
    "repo_root = nb_dir.parents[1]\n",
    "if str(repo_root) not in sys.path:\n",
    "    sys.path.insert(0, str(repo_root))\n",
    "    print(f\"Added {repo_root} to sys.path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47109e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import trainer\n",
    "from utils import utils\n",
    "from Systems import DynamicSystem\n",
    "import Filters\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "from scipy.interpolate import RegularGridInterpolator\n",
    "import random\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a3c33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# === 1. KONFIGURACE ===\n",
    "# Cesta k adresáři, který vytvořil preprocess skript\n",
    "data_dir = '../preprocessed_NCLT_trajectory-2012-01-22-angle-update'\n",
    "\n",
    "print(f\"Načítám data z: {data_dir}...\")\n",
    "\n",
    "try:\n",
    "    # === 2. NAČTENÍ DAT (.pt soubory) ===\n",
    "    # Data jsou uložena jako list slovníků [{'ground_truth': ..., 'filtered_gps': ...}]\n",
    "    # filtered_gps zde ale obsahuje náš 4D vektor [GPS_X, ODO_VX, GPS_Y, ODO_VY]\n",
    "    \n",
    "    train_data = torch.load(os.path.join(data_dir, 'train.pt'))\n",
    "    val_data = torch.load(os.path.join(data_dir, 'val.pt'))\n",
    "    test_data = torch.load(os.path.join(data_dir, 'test.pt'))\n",
    "\n",
    "    # Extrakce tensorů (předpokládáme 1 trajektorii v listu)\n",
    "    X_train, Y_train = train_data[0]['ground_truth'], train_data[0]['filtered_gps']\n",
    "    X_val, Y_val     = val_data[0]['ground_truth'],   val_data[0]['filtered_gps']\n",
    "    X_test, Y_test   = test_data[0]['ground_truth'],  test_data[0]['filtered_gps']\n",
    "\n",
    "    # Spojení zpět do jedné sekvence pro vizualizaci celé trajektorie\n",
    "    X_full = torch.cat([X_train, X_val, X_test], dim=0)\n",
    "    Y_full = torch.cat([Y_train, Y_val, Y_test], dim=0)\n",
    "\n",
    "    print(f\"✅ Data úspěšně načtena.\")\n",
    "    print(f\"  -> Celkový počet vzorků: {X_full.shape[0]}\")\n",
    "    print(f\"  -> Input Shape (Měření): {Y_full.shape} ... [GPS_X, ODO_VX, GPS_Y, ODO_VY]\")\n",
    "    print(f\"  -> Target Shape (GT):    {X_full.shape} ... [PX, VX, PY, VY]\")\n",
    "\n",
    "    # === 3. VIZUALIZACE ===\n",
    "    # Převedeme na numpy pro matplotlib\n",
    "    gt_np = X_full.numpy()\n",
    "    meas_np = Y_full.numpy()\n",
    "    time_steps = np.arange(len(gt_np)) # Předpoklad 1Hz (DT=1.0)\n",
    "\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "    # --- A) Trajektorie (X-Y) ---\n",
    "    # Ground Truth (Sloupce 0 a 2 v Targetu)\n",
    "    ax[0].plot(gt_np[:, 0], gt_np[:, 2], 'k-', linewidth=2, label='Ground Truth')\n",
    "    \n",
    "    # GPS Měření (Sloupce 0 a 2 v Inputu)\n",
    "    # Vykreslíme jen každý 20. bod, aby graf nebyl přeplácaný\n",
    "    ax[0].plot(meas_np[::20, 0], meas_np[::20, 2], 'r.', markersize=2, alpha=0.6, label='GPS Měření')\n",
    "\n",
    "    ax[0].set_title('Trajektorie (X vs Y)')\n",
    "    ax[0].set_xlabel('Pozice X [m]')\n",
    "    ax[0].set_ylabel('Pozice Y [m]')\n",
    "    ax[0].axis('equal')\n",
    "    ax[0].legend()\n",
    "    ax[0].grid(True, alpha=0.3)\n",
    "\n",
    "    # --- B) Rychlost X (VX) ---\n",
    "    # GT Rychlost (Sloupec 1 v Targetu)\n",
    "    ax[1].plot(time_steps, gt_np[:, 1], 'b-', linewidth=1.5, label='GT Rychlost X')\n",
    "    # ODO Rychlost (Sloupec 1 v Inputu)\n",
    "    ax[1].plot(time_steps, meas_np[:, 1], 'g--', linewidth=1, alpha=0.8, label='Odometrie VX')\n",
    "\n",
    "    ax[1].set_title('Rychlostní profil X')\n",
    "    ax[1].set_xlabel('Čas [s]')\n",
    "    ax[1].set_ylabel('Rychlost [m/s]')\n",
    "    ax[1].legend()\n",
    "    ax[1].grid(True, alpha=0.3)\n",
    "\n",
    "    # --- C) Rychlost Y (VY) ---\n",
    "    # GT Rychlost (Sloupec 3 v Targetu)\n",
    "    ax[2].plot(time_steps, gt_np[:, 3], 'b-', linewidth=1.5, label='GT Rychlost Y')\n",
    "    # ODO Rychlost (Sloupec 3 v Inputu)\n",
    "    ax[2].plot(time_steps, meas_np[:, 3], 'g--', linewidth=1, alpha=0.8, label='Odometrie VY')\n",
    "\n",
    "    ax[2].set_title('Rychlostní profil Y')\n",
    "    ax[2].set_xlabel('Čas [s]')\n",
    "    ax[2].set_ylabel('Rychlost [m/s]')\n",
    "    ax[2].legend()\n",
    "    ax[2].grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"❌ CHYBA: Adresář '{data_dir}' nebo soubory .pt nenalezeny.\")\n",
    "    print(\"Spustil jsi předtím skript 'preprocess_NCLT_trajectory_linear_test.py'?\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ CHYBA: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae272c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# === VIZUALIZACE ROZDĚLENÍ DATASETU ===\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# Používáme proměnné z předchozího kroku: X_train, X_val, X_test\n",
    "# Konverze .numpy() funguje, pokud jsou tensory na CPU (což po načtení torch.load obvykle jsou)\n",
    "\n",
    "# 1. Testovací část (Podle tvého 'save_splits' je Test na začátku - prvních cca 10%)\n",
    "plt.plot(X_test[:, 0].numpy(), \n",
    "         X_test[:, 2].numpy(), \n",
    "         label='Test Set (Začátek)', color='#2ca02c', linewidth=2) # Zelená\n",
    "\n",
    "# 2. Trénovací část (Navazuje na Test - středních 70%)\n",
    "plt.plot(X_train[:, 0].numpy(), \n",
    "         X_train[:, 2].numpy(), \n",
    "         label='Train Set (Střed)', color='#1f77b4', linewidth=2) # Modrá\n",
    "\n",
    "# 3. Validační část (Navazuje na Train - koncových 20%)\n",
    "plt.plot(X_val[:, 0].numpy(), \n",
    "         X_val[:, 2].numpy(), \n",
    "         label='Validation Set (Konec)', color='#ff7f0e', linewidth=2) # Oranžová\n",
    "\n",
    "# Zvýraznění začátku a konce celé trajektorie\n",
    "# Začátek je v prvním bodě Testovací sady\n",
    "plt.plot(X_test[0, 0], X_test[0, 2], 'ko', markersize=10, label='Start Trajektorie')\n",
    "\n",
    "# Konec je v posledním bodě Validační sady\n",
    "plt.plot(X_val[-1, 0], X_val[-1, 2], 'rx', markersize=10, markeredgewidth=3, label='Konec Trajektorie')\n",
    "\n",
    "# Formátování grafu\n",
    "# N_samples a DT vezmeme z kontextu předchozího cellu nebo definujeme\n",
    "N_samples = X_full.shape[0] \n",
    "DT = 1.0 \n",
    "\n",
    "plt.title(f'NCLT Dataset: Rozdělení trajektorie\\n(Total samples: {N_samples}, dt={DT}s)', fontsize=14)\n",
    "plt.xlabel('Pozice X [m] (East)', fontsize=12)\n",
    "plt.ylabel('Pozice Y [m] (North)', fontsize=12)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.axis('equal')  # Důležité: Aby mapa nebyla deformovaná\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa30f26",
   "metadata": {},
   "source": [
    "# Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec3145c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import Systems \n",
    "\n",
    "# Nastavení zařízení\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#########################\n",
    "### Design Parameters ###\n",
    "### (OPTIMALIZOVANÉ)  ###\n",
    "#########################\n",
    "\n",
    "# 1. Rozměry\n",
    "# Stav: [px, vx, py, vy]\n",
    "m = 4 \n",
    "n = 4 \n",
    "delta_t = 1.0 \n",
    "\n",
    "# 2. Dynamika (F)\n",
    "# x_{t+1} = x_t + v_t * dt\n",
    "F_dim = torch.tensor([[1.0, delta_t],\n",
    "                      [0.0, 1.0]])\n",
    "\n",
    "F_design = torch.block_diag(F_dim, F_dim).float()\n",
    "\n",
    "# 3. Měření (H)\n",
    "H_design = torch.eye(n).float()\n",
    "\n",
    "# ==========================================\n",
    "# 4. Šum procesu (Q) - OPTIMALIZOVÁNO\n",
    "# ==========================================\n",
    "# Hodnota z Optuny (MSE ~760)\n",
    "q_scale = 0.00006806\n",
    "\n",
    "# Používáme kinematický model (Discrete White Noise Acceleration), \n",
    "# který byl použit v optimalizačním skriptu.\n",
    "# Blok pro jednu dimenzi (pozice + rychlost):\n",
    "Q_block_val = torch.tensor([\n",
    "    [(delta_t**3)/3, (delta_t**2)/2],\n",
    "    [(delta_t**2)/2,  delta_t      ]\n",
    "]) * q_scale\n",
    "\n",
    "# Výsledná Q pro [px, vx, py, vy]\n",
    "Q_design = torch.block_diag(Q_block_val, Q_block_val).float()\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 5. Šum měření (R) - OPTIMALIZOVÁNO\n",
    "# ==========================================\n",
    "# Hodnoty z Optuny\n",
    "var_gps = 38.370833  # Vysoká nedůvěra v GPS (odpovídá realitě NCLT)\n",
    "var_odo = 0.000560   # Extrémní důvěra v Odometrii\n",
    "\n",
    "# Pořadí stavů: [Pos_X, Vel_X, Pos_Y, Vel_Y]\n",
    "# Takže střídáme: [GPS, ODO, GPS, ODO]\n",
    "R_design = torch.tensor([\n",
    "    [var_gps, 0.0,     0.0,     0.0],\n",
    "    [0.0,     var_odo, 0.0,     0.0],\n",
    "    [0.0,     0.0,     var_gps, 0.0],\n",
    "    [0.0,     0.0,     0.0,     var_odo]\n",
    "]).float()\n",
    "\n",
    "# 6. Počáteční podmínky\n",
    "m1x_0 = torch.zeros(m, 1).float()\n",
    "m2x_0 = torch.eye(m).float() * 1.0 # Zvýšena počáteční nejistota, aby se filtr rychleji chytil\n",
    "\n",
    "print(\"\\nInicializuji systém dle OPTIMALIZOVANÝCH parametrů (NCLT)...\")\n",
    "print(f\"Dimenze stavu: {m}, Dimenze měření: {n}\")\n",
    "print(f\"Q scale: {q_scale}\")\n",
    "print(f\"R diagonal: {torch.diagonal(R_design)}\")\n",
    "\n",
    "# === INICIALIZACE SYSTÉMŮ ===\n",
    "\n",
    "sys_true = Systems.DynamicSystem(\n",
    "    state_dim=m, obs_dim=n,\n",
    "    Ex0=m1x_0, P0=m2x_0,\n",
    "    Q=Q_design, R=R_design,\n",
    "    F=F_design, H=H_design,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "sys_model = Systems.DynamicSystem(\n",
    "    state_dim=m, obs_dim=n,\n",
    "    Ex0=m1x_0, P0=m2x_0,\n",
    "    Q=Q_design, R=R_design,\n",
    "    F=F_design, H=H_design,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "print(\"... Systémy inicializovány.\")\n",
    "print(\"POZOR: Tento model očekává pořadí stavů [px, vx, py, vy].\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea11b3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# === 1. KONFIGURACE ===\n",
    "# Dynamicky zjistíme délku testovací sady z proměnné X_test (kterou máme z minula)\n",
    "# Pokud by X_test neexistovalo, kód spadne, ale to by znamenalo, že jsi nenačetl data.\n",
    "TEST_SEQ_LEN = X_test.shape[0] \n",
    "\n",
    "TRAIN_SEQ_LEN = 50    # Délka sekvence pro trénink (krátká okna)\n",
    "VAL_SEQ_LEN = 200     # Validace po delších úsecích\n",
    "STRIDE = 10           # Posun okna (překryv)\n",
    "BATCH_SIZE = 128      # Velikost dávky\n",
    "\n",
    "def create_sequences(X, Y, seq_len, stride=1):\n",
    "    \"\"\"\n",
    "    Rozseká dlouhé tenzory [Total_Len, Dim] na sekvence [N_seq, Seq_Len, Dim].\n",
    "    \"\"\"\n",
    "    xs = []\n",
    "    ys = []\n",
    "    num_samples = X.shape[0]\n",
    "    \n",
    "    # Pokud je seq_len větší než data (např. u testu), vezmeme prostě to, co máme\n",
    "    if seq_len > num_samples:\n",
    "        seq_len = num_samples\n",
    "    \n",
    "    for i in range(0, num_samples - seq_len + 1, stride):\n",
    "        x_seq = X[i : i+seq_len, :]\n",
    "        y_seq = Y[i : i+seq_len, :]\n",
    "        xs.append(x_seq)\n",
    "        ys.append(y_seq)\n",
    "        \n",
    "    if len(xs) == 0:\n",
    "        # Fallback: Pokud by data byla kratší než seq_len, vrátíme prázdné nebo 1 kus\n",
    "        return X.unsqueeze(0), Y.unsqueeze(0)\n",
    "        \n",
    "    return torch.stack(xs), torch.stack(ys)\n",
    "\n",
    "def clean_sequences(X_seq, Y_seq, name=\"Dataset\"):\n",
    "    \"\"\"\n",
    "    Filtruje sekvence, které obsahují jakékoliv NaN nebo Inf hodnoty.\n",
    "    \"\"\"\n",
    "    if X_seq.numel() == 0:\n",
    "        print(f\"⚠️ {name}: Prázdný vstup!\")\n",
    "        return X_seq, Y_seq\n",
    "\n",
    "    # Zkontrolujeme NaN/Inf pro každou sekvenci zvlášť\n",
    "    is_nan_x = torch.isnan(X_seq).reshape(X_seq.shape[0], -1).any(dim=1)\n",
    "    is_inf_x = torch.isinf(X_seq).reshape(X_seq.shape[0], -1).any(dim=1)\n",
    "    \n",
    "    is_nan_y = torch.isnan(Y_seq).reshape(Y_seq.shape[0], -1).any(dim=1)\n",
    "    is_inf_y = torch.isinf(Y_seq).reshape(Y_seq.shape[0], -1).any(dim=1)\n",
    "    \n",
    "    invalid_mask = is_nan_x | is_inf_x | is_nan_y | is_inf_y\n",
    "    valid_mask = ~invalid_mask\n",
    "    \n",
    "    X_clean = X_seq[valid_mask]\n",
    "    Y_clean = Y_seq[valid_mask]\n",
    "    \n",
    "    n_dropped = invalid_mask.sum().item()\n",
    "    if n_dropped > 0:\n",
    "        print(f\"⚠️ {name}: Odstraněno {n_dropped} vadných sekvencí (NaN/Inf). Zbývá: {len(X_clean)}\")\n",
    "    else:\n",
    "        print(f\"✅ {name}: Data jsou čistá. ({len(X_clean)} sekvencí)\")\n",
    "        \n",
    "    return X_clean, Y_clean\n",
    "\n",
    "print(\"--- ZPRACOVÁNÍ DAT ---\")\n",
    "\n",
    "# === 2. TVORBA SEKVENCÍ A PŘETYPOVÁNÍ ===\n",
    "# OPRAVA PROMĚNNÝCH: Používáme X_train, Y_train atd. místo train_target/input\n",
    "# X = Ground Truth, Y = Měření (Input)\n",
    "print(f\"Generuji sekvence (Test délka: {TEST_SEQ_LEN})...\")\n",
    "\n",
    "# Train: Krátká okna s překryvem\n",
    "train_X_raw, train_Y_raw = create_sequences(X_train.float(), Y_train.float(), TRAIN_SEQ_LEN, STRIDE)\n",
    "\n",
    "# Val: Delší okna (bez překryvu)\n",
    "val_X_raw, val_Y_raw = create_sequences(X_val.float(), Y_val.float(), VAL_SEQ_LEN, VAL_SEQ_LEN)\n",
    "\n",
    "# Test: Jedna dlouhá sekvence (pro kontinuální vyhodnocení)\n",
    "# Stride = TEST_SEQ_LEN zajistí, že dostaneme právě jeden (nebo málo) dlouhých kusů\n",
    "test_X_raw, test_Y_raw = create_sequences(X_test.float(), Y_test.float(), TEST_SEQ_LEN, TEST_SEQ_LEN)\n",
    "\n",
    "# === 3. ČIŠTĚNÍ DAT (NAN/INF FILTER) ===\n",
    "print(\"\\nFiltruji NaN hodnoty...\")\n",
    "train_X_seq, train_Y_seq = clean_sequences(train_X_raw, train_Y_raw, \"Train\")\n",
    "val_X_seq, val_Y_seq = clean_sequences(val_X_raw, val_Y_raw, \"Val\")\n",
    "test_X_seq, test_Y_seq = clean_sequences(test_X_raw, test_Y_raw, \"Test\")\n",
    "\n",
    "# === 4. VYTVOŘENÍ DATALOADERŮ ===\n",
    "print(\"\\nVytvářím DataLoadery...\")\n",
    "# Train: Shuffle=True (Důležité pro trénink)\n",
    "train_dataset = TensorDataset(train_X_seq, train_Y_seq)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# Val/Test: Shuffle=False (Abychom viděli průběh)\n",
    "val_dataset = TensorDataset(val_X_seq, val_Y_seq)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "test_dataset = TensorDataset(test_X_seq, test_Y_seq)\n",
    "# Pro test batch_size=1, protože máme jednu obří sekvenci (nebo pár velkých)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "print(f\"\\n✅ HOTOVO. Připraveno k tréninku.\")\n",
    "print(f\"Train batches: {len(train_loader)} (Batch shape: {next(iter(train_loader))[0].shape})\")\n",
    "print(f\"Test batches:  {len(test_loader)} (Seq len: {test_X_seq.shape[1]})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3adc603",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import os\n",
    "from state_NN_models import StateBayesianKalmanNet,StateKalmanNet\n",
    "from utils import trainer\n",
    "\n",
    "state_bkn = StateBayesianKalmanNet(sys_model, device=device, hidden_size_multiplier=10,\n",
    "                                   output_layer_multiplier=4,num_gru_layers=1,\n",
    "                                    init_max_dropout=0.3,init_min_dropout=0.1, norm_states=True).to(device)\n",
    "\n",
    "print(state_bkn)\n",
    "\n",
    "\n",
    "state_knet = state_knet = StateKalmanNet(sys_model, device=device, hidden_size_multiplier=8,\n",
    "                                         output_layer_multiplier=4,num_gru_layers=1,\n",
    "                                         gru_hidden_dim_multiplier=4,\n",
    "                                         returns_covariance=True).to(device)\n",
    "print(state_knet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80db97e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "# ==========================================\n",
    "# 1. NASTAVENÍ NÁZVŮ SOUBORŮ (Manuální vstup)\n",
    "# ==========================================\n",
    "# Složka, kde jsou váhy uloženy\n",
    "WEIGHTS_DIR = 'NN_weights'\n",
    "\n",
    "# Zde doplň přesné názvy souborů .pth\n",
    "# KNET_FILENAME = 'best_Knet_test_results.pth'                                          # Příklad\n",
    "KNET_FILENAME = 'KalmanNet_test.pth' #best_MSE_KalmanNet_linear_trajectory\n",
    "BKN_FILENAME = 'best_MSE_BayesianKalmanNet_linear_trajectory-MSE2.3662|ANEES7.9216.pth'  \n",
    "\n",
    "# ==========================================\n",
    "# 2. FUNKCE PRO BEZPEČNÉ NAČTENÍ\n",
    "# ==========================================\n",
    "def load_pretrained_weights(model, filename, model_name):\n",
    "    filepath = os.path.join(WEIGHTS_DIR, filename)\n",
    "    \n",
    "    if not os.path.exists(filepath):\n",
    "        print(f\"⚠️  VAROVÁNÍ: Soubor '{filename}' pro {model_name} nebyl nalezen v '{WEIGHTS_DIR}'.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        # Načtení na správné zařízení (CPU/GPU)\n",
    "        checkpoint = torch.load(filepath, map_location=device)\n",
    "        \n",
    "        # Detekce, zda jde o čistý state_dict nebo slovník checkpointu\n",
    "        if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:\n",
    "            # Pokud je to checkpoint z traineru, vytáhneme jen váhy modelu\n",
    "            state_dict = checkpoint['model_state_dict']\n",
    "        elif isinstance(checkpoint, dict) and 'state_dict' in checkpoint:\n",
    "            state_dict = checkpoint['state_dict']\n",
    "        else:\n",
    "            # Předpokládáme, že je to přímo state_dict\n",
    "            state_dict = checkpoint\n",
    "\n",
    "        # Nahrání vah do modelu\n",
    "        model.load_state_dict(state_dict)\n",
    "        \n",
    "        # Důležité: Přepnutí do evaluačního módu (vypne Dropout, fixuje BatchNorm)\n",
    "        model.eval()\n",
    "        \n",
    "        print(f\"✅ {model_name}: Váhy úspěšně načteny z '{filename}'.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ CHYBA: Nepodařilo se načíst váhy pro {model_name}.\\n   Důvod: {e}\")\n",
    "\n",
    "# ==========================================\n",
    "# 3. SPUŠTĚNÍ NAČÍTÁNÍ\n",
    "# ==========================================\n",
    "print(f\"--- Načítání vah ze složky: {os.path.abspath(WEIGHTS_DIR)} ---\\n\")\n",
    "\n",
    "# Načtení State KalmanNet\n",
    "load_pretrained_weights(state_knet, KNET_FILENAME, \"State KalmanNet\")\n",
    "\n",
    "# Načtení Bayesian KalmanNet\n",
    "load_pretrained_weights(state_bkn, BKN_FILENAME, \"State BKN\")\n",
    "\n",
    "print(\"\\n--- Hotovo ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a36112",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import Filters  # Tvůj modul s filtry\n",
    "from utils import utils # Tvůj modul pro ANEES\n",
    "\n",
    "# ==============================================================================\n",
    "# 0. KONFIGURACE\n",
    "# ==============================================================================\n",
    "J_SAMPLES = 5  # Počet vzorků pro Monte Carlo Dropout (Ensemble)\n",
    "\n",
    "# 1. Příprava BKN modelu (Bayesian)\n",
    "try:\n",
    "    trained_model_bkn = state_bkn\n",
    "    # DŮLEŽITÉ: Pro BKN musí být model v režimu TRAIN (aby fungoval Dropout)\n",
    "    trained_model_bkn.train() \n",
    "    print(f\"INFO: Bayesian KalmanNet (BKN) připraven (J={J_SAMPLES}).\")\n",
    "except NameError:\n",
    "    raise NameError(\"Chyba: Proměnná 'state_knet' (BKN) neexistuje.\")\n",
    "\n",
    "# 2. Příprava KalmanNet modelu (Classic)\n",
    "try:\n",
    "    # Předpokládám, že klasický KalmanNet máš v proměnné 'state_knet_classic'\n",
    "    # Pokud používáš stejnou třídu, jen bez dropoutu, změň název proměnné dle potřeby.\n",
    "    trained_model_classic = state_knet \n",
    "    trained_model_classic.eval() # Klasický KNet chceme v eval módu (vypnout dropout, pokud tam je)\n",
    "    print(f\"INFO: KalmanNet (Classic) připraven.\")\n",
    "except NameError:\n",
    "    print(\"VAROVÁNÍ: Proměnná 'state_knet_classic' nenalezena. KNet bude přeskočen.\")\n",
    "    trained_model_classic = None\n",
    "\n",
    "# 3. Inicializace klasických filtrů\n",
    "print(\"Inicializuji EKF, UKF, PF, AKF, KF...\")\n",
    "ekf_filter = Filters.ExtendedKalmanFilter(sys_model)\n",
    "ukf_filter = Filters.UnscentedKalmanFilter(sys_model)\n",
    "# pf_filter = Filters.ParticleFilter(sys_model, num_particles=1000000) # Sníženo pro rychlost\n",
    "pf_filter = Filters.AuxiliaryParticleFilter(sys_model, num_particles=1000) # Sníženo pro rychlost\n",
    "akf_filter = Filters.StructuredAdaptiveKalmanFilter(sys_model, mdm_L=10, mdm_version=1, forgetting_factor=0.98)\n",
    "kf_filter = Filters.KalmanFilter(sys_model)\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. VYHODNOCOVACÍ SMYČKA\n",
    "# ==============================================================================\n",
    "# Slovník pro ukládání výsledků (jednodušší než seznamy seznamů)\n",
    "results = {\n",
    "    'BKN':  {'mse': [], 'anees': []},\n",
    "    'KNet': {'mse': [], 'anees': []},\n",
    "    'EKF':  {'mse': [], 'anees': []},\n",
    "    'UKF':  {'mse': [], 'anees': []},\n",
    "    'PF':   {'mse': [], 'anees': []},\n",
    "    'AKF':  {'mse': [], 'anees': []},\n",
    "    'KF':   {'mse': [], 'anees': []}\n",
    "}\n",
    "\n",
    "traj_idx = 0\n",
    "total_trajectories = len(test_loader.dataset)\n",
    "state_dim = sys_model.state_dim\n",
    "\n",
    "print(f\"\\nVyhodnocuji {total_trajectories} sekvencí z testovací sady...\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x_true_batch, y_meas_batch in test_loader:\n",
    "        \n",
    "        batch_size = x_true_batch.shape[0]\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            traj_idx += 1\n",
    "            \n",
    "            # Příprava dat pro jednu trajektorii\n",
    "            y_seq = y_meas_batch[i].to(device)    # [Seq_Len, Obs_Dim]\n",
    "            x_true = x_true_batch[i].to(device)   # [Seq_Len, State_Dim]\n",
    "            seq_len = y_seq.shape[0]\n",
    "\n",
    "            # Inicializační stavy\n",
    "            knet_init_state = x_true[0, :].unsqueeze(0) # [1, Dim]\n",
    "            filter_init_state = x_true[0, :].unsqueeze(1) # [Dim, 1]\n",
    "\n",
    "            # ==================================================================\n",
    "            # 1. Bayesian KalmanNet (Ensemble)\n",
    "            # ==================================================================\n",
    "            ensemble_preds = []\n",
    "            \n",
    "            for j in range(J_SAMPLES):\n",
    "                trained_model_bkn.reset(batch_size=1, initial_state=knet_init_state)\n",
    "                sample_seq = [knet_init_state] \n",
    "                \n",
    "                for t in range(1, seq_len):\n",
    "                    y_t = y_seq[t, :].unsqueeze(0)\n",
    "                    x_val, _ = trained_model_bkn.step(y_t) \n",
    "                    sample_seq.append(x_val)\n",
    "                ensemble_preds.append(torch.cat(sample_seq, dim=0))\n",
    "            \n",
    "            # Statistiky BKN\n",
    "            ensemble_tensor = torch.stack(ensemble_preds, dim=0) # [J, T, Dim]\n",
    "            x_hat_bkn = ensemble_tensor.mean(dim=0) \n",
    "            P_diag_bkn = ensemble_tensor.var(dim=0) + 1e-9 # Epistemická variance\n",
    "            \n",
    "            # Konstrukce plné P pro ANEES\n",
    "            full_P_hat_bkn = torch.zeros(seq_len, state_dim, state_dim, device=device)\n",
    "            for t_step in range(seq_len):\n",
    "                full_P_hat_bkn[t_step] = torch.diag(P_diag_bkn[t_step])\n",
    "\n",
    "            results['BKN']['mse'].append(F.mse_loss(x_hat_bkn[1:], x_true[1:]).item())\n",
    "            results['BKN']['anees'].append(utils.calculate_anees_vectorized(x_true, x_hat_bkn, full_P_hat_bkn))\n",
    "\n",
    "            # ==================================================================\n",
    "            # 2. Deterministický KalmanNet (KNet)\n",
    "            # ==================================================================\n",
    "            if trained_model_classic is not None:\n",
    "                trained_model_classic.reset(batch_size=1, initial_state=knet_init_state)\n",
    "                knet_preds = [knet_init_state]\n",
    "                knet_covs = [sys_model.P0.unsqueeze(0)] # P0 pro t=0\n",
    "                \n",
    "                for t in range(1, seq_len):\n",
    "                    y_t = y_seq[t, :].unsqueeze(0)\n",
    "                    # Očekáváme, že step vrací (x, P) nebo jen x\n",
    "                    out = trained_model_classic.step(y_t)\n",
    "                    if isinstance(out, tuple):\n",
    "                        x_val, P_val = out\n",
    "                    else:\n",
    "                        x_val, P_val = out, sys_model.P0.unsqueeze(0) # Fallback P0\n",
    "                    \n",
    "                    knet_preds.append(x_val)\n",
    "                    knet_covs.append(P_val)\n",
    "                \n",
    "                x_hat_knet = torch.cat(knet_preds, dim=0)\n",
    "                P_hat_knet = torch.cat(knet_covs, dim=0)\n",
    "                \n",
    "                results['KNet']['mse'].append(F.mse_loss(x_hat_knet[1:], x_true[1:]).item())\n",
    "                results['KNet']['anees'].append(utils.calculate_anees_vectorized(x_true, x_hat_knet, P_hat_knet))\n",
    "\n",
    "            # ==================================================================\n",
    "            # 3. Klasické Filtry\n",
    "            # ==================================================================\n",
    "            \n",
    "            # Helper pro uložení výsledků filtru\n",
    "            def save_filter_res(name, res_dict):\n",
    "                if res_dict is None: return # Skip failed filter\n",
    "                x_filt = res_dict['x_filtered']\n",
    "                P_filt = res_dict['P_filtered']\n",
    "                results[name]['mse'].append(F.mse_loss(x_filt[1:], x_true[1:]).item())\n",
    "                results[name]['anees'].append(utils.calculate_anees_vectorized(x_true, x_filt, P_filt))\n",
    "\n",
    "            # Adaptive KF\n",
    "            try:\n",
    "                res_akf, _, _ = akf_filter.process_sequence_adaptively(y_seq, Ex0=filter_init_state, P0=sys_model.P0)\n",
    "                save_filter_res('AKF', res_akf)\n",
    "            except:\n",
    "                pass # AKF občas diverguje\n",
    "\n",
    "            # Standard KF\n",
    "            res_kf = kf_filter.process_sequence(y_seq, Ex0=filter_init_state, P0=sys_model.P0)\n",
    "            save_filter_res('KF', res_kf)\n",
    "\n",
    "            # EKF\n",
    "            res_ekf = ekf_filter.process_sequence(y_seq, Ex0=filter_init_state, P0=sys_model.P0)\n",
    "            save_filter_res('EKF', res_ekf)\n",
    "\n",
    "            # UKF\n",
    "            res_ukf = ukf_filter.process_sequence(y_seq, Ex0=filter_init_state, P0=sys_model.P0)\n",
    "            save_filter_res('UKF', res_ukf)\n",
    "\n",
    "            # PF\n",
    "            res_pf = pf_filter.process_sequence(y_seq, Ex0=filter_init_state, P0=sys_model.P0)\n",
    "            save_filter_res('PF', res_pf)\n",
    "\n",
    "            if traj_idx % 20 == 0:\n",
    "                print(f\"  -> Zpracováno {traj_idx}/{total_trajectories}\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. FINÁLNÍ VÝPIS\n",
    "# ==============================================================================\n",
    "def avg(lst): return np.mean(lst) if len(lst) > 0 else np.nan\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(f\"FINÁLNÍ VÝSLEDKY: KOMPLEXNÍ SROVNÁNÍ (MSE a ANEES)\")\n",
    "print(\"=\"*100)\n",
    "print(f\"{'Model':<30} | {'Průměrné MSE':<20} | {'RMSE [m]':<20} | {'Průměrný ANEES':<20}\")\n",
    "print(\"-\" * 100)\n",
    "print(f\"Cílové ANEES ≈ {state_dim:.2f}\")\n",
    "print(\"-\" * 100)\n",
    "\n",
    "models_list = ['BKN', 'KNet', 'AKF', 'KF', 'EKF', 'UKF', 'PF']\n",
    "# Odebereme KNet, pokud nebyl načten\n",
    "if trained_model_classic is None: \n",
    "    models_list.remove('KNet')\n",
    "\n",
    "for m_name in models_list:\n",
    "    mse_val = avg(results[m_name]['mse'])\n",
    "    anees_val = avg(results[m_name]['anees'])\n",
    "    rmse_val = np.sqrt(mse_val)\n",
    "    \n",
    "    print(f\"{m_name:<30} | {mse_val:<20.4f} | {rmse_val:<20.4f} | {anees_val:<20.4f}\")\n",
    "\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad617a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# === 1. ZÍSKÁNÍ DAT PRO VIZUALIZACI (RE-RUN NA JEDNOM BATCHI) ===\n",
    "# Musíme znovu spustit modely na jednom vzorku dat, abychom měli co kreslit.\n",
    "x_true_batch, y_meas_batch = next(iter(test_loader))\n",
    "i = 0 \n",
    "\n",
    "y_seq = y_meas_batch[i].to(device)\n",
    "x_true = x_true_batch[i].to(device)\n",
    "seq_len = y_seq.shape[0]\n",
    "\n",
    "# Inicializace\n",
    "knet_init_state = x_true[0, :].unsqueeze(0)      # [1, 4]\n",
    "filter_init_state = x_true[0, :].unsqueeze(1)    # [4, 1]\n",
    "\n",
    "# !!! DŮLEŽITÉ: Vypnout počítání gradientů pro ušetření paměti !!!\n",
    "with torch.no_grad():\n",
    "    \n",
    "    # --- A) BKN RUN ---\n",
    "    ensemble_preds = []\n",
    "    \n",
    "    for j in range(J_SAMPLES):\n",
    "        trained_model_bkn.reset(batch_size=1, initial_state=knet_init_state)\n",
    "        # Ukládáme na CPU, abychom nehltili GPU paměť\n",
    "        sample_seq = [knet_init_state.cpu()] \n",
    "        \n",
    "        for t in range(1, seq_len):\n",
    "            y_t = y_seq[t, :].unsqueeze(0)\n",
    "            x_val, _ = trained_model_bkn.step(y_t) \n",
    "            # Okamžitě přesunout výsledek kroku na CPU\n",
    "            sample_seq.append(x_val.cpu())\n",
    "            \n",
    "        # Spojíme sekvenci na CPU\n",
    "        ensemble_preds.append(torch.cat(sample_seq, dim=0))\n",
    "\n",
    "    # Nyní máme list tensorů na CPU, stackneme je\n",
    "    ensemble_tensor = torch.stack(ensemble_preds, dim=0) # [J, Seq, Dim]\n",
    "    \n",
    "    # Průměr a varianci spočítáme na CPU (pro vizualizaci to stačí a je to bezpečné)\n",
    "    x_hat_bkn = ensemble_tensor.mean(dim=0) \n",
    "    P_diag_bkn = ensemble_tensor.var(dim=0) + 1e-9\n",
    "\n",
    "    # --- B) KNET RUN (Classic) ---\n",
    "    if trained_model_classic is not None:\n",
    "        trained_model_classic.reset(batch_size=1, initial_state=knet_init_state)\n",
    "        \n",
    "        # Ukládáme na CPU\n",
    "        knet_preds = [knet_init_state.cpu()]\n",
    "        \n",
    "        P0_diag = torch.diagonal(sys_model.P0.cpu(), dim1=-2, dim2=-1).unsqueeze(0)\n",
    "        knet_vars = [P0_diag]\n",
    "\n",
    "        for t in range(1, seq_len):\n",
    "            y_t = y_seq[t, :].unsqueeze(0)\n",
    "            out = trained_model_classic.step(y_t)\n",
    "            \n",
    "            if isinstance(out, tuple): \n",
    "                x_val, P_val = out\n",
    "                knet_preds.append(x_val.cpu())\n",
    "                \n",
    "                # Extrakce diagonály a přesun na CPU\n",
    "                P_diag = torch.diagonal(P_val[0], dim1=-2, dim2=-1).unsqueeze(0).cpu()\n",
    "                knet_vars.append(P_diag)\n",
    "            else: \n",
    "                x_val = out\n",
    "                knet_preds.append(x_val.cpu())\n",
    "                knet_vars.append(torch.zeros_like(P0_diag))\n",
    "        \n",
    "        x_hat_knet = torch.cat(knet_preds, dim=0)\n",
    "        knet_std_np = np.sqrt(torch.cat(knet_vars, dim=0).numpy()) # Už je na CPU\n",
    "    else:\n",
    "        x_hat_knet = None\n",
    "        knet_std_np = None\n",
    "\n",
    "    # --- C) AKF RUN (Adaptive KF) ---\n",
    "    # Tento filtr vrací (results_dict, Q_hist, R_hist)\n",
    "    res_akf_raw, _, _ = akf_filter.process_sequence_adaptively(y_seq, Ex0=filter_init_state, P0=sys_model.P0)\n",
    "    \n",
    "    # --- D) KF RUN (Standard) ---\n",
    "    res_kf = kf_filter.process_sequence(y_seq, Ex0=filter_init_state, P0=sys_model.P0)\n",
    "\n",
    "\n",
    "# === 2. PŘÍPRAVA DAT PRO PLOTTING ===\n",
    "# Převod na numpy\n",
    "gt_np = x_true.cpu().numpy()\n",
    "time_steps = np.arange(len(gt_np))\n",
    "\n",
    "# BKN výsledky (už jsou na CPU)\n",
    "bkn_est_np = x_hat_bkn.numpy()\n",
    "bkn_std_np = np.sqrt(P_diag_bkn.numpy())\n",
    "\n",
    "# AKF výsledky\n",
    "akf_est_np = res_akf_raw['x_filtered'].detach().cpu().numpy()\n",
    "akf_std_np = np.sqrt(np.diagonal(res_akf_raw['P_filtered'].detach().cpu().numpy(), axis1=1, axis2=2))\n",
    "\n",
    "# KF výsledky\n",
    "kf_est_np = res_kf['x_filtered'].detach().cpu().numpy()\n",
    "kf_std_np = np.sqrt(np.diagonal(res_kf['P_filtered'].detach().cpu().numpy(), axis1=1, axis2=2))\n",
    "\n",
    "if x_hat_knet is not None:\n",
    "    knet_est_np = x_hat_knet.numpy()\n",
    "else:\n",
    "    knet_est_np = None\n",
    "\n",
    "# === 3. VIZUALIZACE (4 řádky) ===\n",
    "# Změna: 4 řádky místo 3\n",
    "fig, axs = plt.subplots(4, 2, figsize=(18, 20), constrained_layout=True)\n",
    "\n",
    "# Výpočet MSE pro titulky\n",
    "mse_bkn = np.mean((bkn_est_np[1:] - gt_np[1:])**2)\n",
    "mse_akf = np.mean((akf_est_np[1:] - gt_np[1:])**2)\n",
    "mse_kf = np.mean((kf_est_np[1:] - gt_np[1:])**2)\n",
    "\n",
    "fig.suptitle(f\"Srovnání modelů na testovací trajektorii\", fontsize=20)\n",
    "\n",
    "# --- ŘÁDEK 1: Bayesian KalmanNet ---\n",
    "axs[0, 0].plot(gt_np[:, 0], gt_np[:, 2], 'k--', label='GT', alpha=0.7)\n",
    "axs[0, 0].plot(bkn_est_np[:, 0], bkn_est_np[:, 2], 'b-', linewidth=2, label='BKN')\n",
    "axs[0, 0].set_title(f\"BKN (MSE: {mse_bkn:.2f}): Trajektorie X-Y\", fontweight='bold')\n",
    "axs[0, 0].set_ylabel(\"Y [m]\")\n",
    "axs[0, 0].legend()\n",
    "axs[0, 0].grid(True)\n",
    "axs[0, 0].axis('equal')\n",
    "\n",
    "axs[0, 1].plot(time_steps, gt_np[:, 0], 'k--', label='GT')\n",
    "axs[0, 1].plot(time_steps, bkn_est_np[:, 0], 'b-', label='BKN')\n",
    "axs[0, 1].fill_between(time_steps, \n",
    "                       bkn_est_np[:, 0] - 3*bkn_std_np[:, 0], \n",
    "                       bkn_est_np[:, 0] + 3*bkn_std_np[:, 0], \n",
    "                       color='blue', alpha=0.2, label='$\\pm 3\\sigma$')\n",
    "axs[0, 1].set_title(\"BKN: Pozice X s nejistotou\", fontweight='bold')\n",
    "axs[0, 1].set_ylabel(\"X [m]\")\n",
    "axs[0, 1].legend()\n",
    "axs[0, 1].grid(True)\n",
    "\n",
    "# --- ŘÁDEK 2: KNet (Classic) ---\n",
    "if knet_est_np is not None:\n",
    "    mse_knet = np.mean((knet_est_np[1:] - gt_np[1:])**2)\n",
    "    axs[1, 0].plot(gt_np[:, 0], gt_np[:, 2], 'k--', alpha=0.7)\n",
    "    axs[1, 0].plot(knet_est_np[:, 0], knet_est_np[:, 2], 'g-', linewidth=2, label='KNet')\n",
    "    axs[1, 0].set_title(f\"KNet (MSE: {mse_knet:.2f}): Trajektorie X-Y\", fontweight='bold')\n",
    "    axs[1, 0].set_ylabel(\"Y [m]\")\n",
    "    axs[1, 0].legend()\n",
    "    axs[1, 0].grid(True)\n",
    "    axs[1, 0].axis('equal')\n",
    "\n",
    "    axs[1, 1].plot(time_steps, gt_np[:, 0], 'k--')\n",
    "    axs[1, 1].plot(time_steps, knet_est_np[:, 0], 'g-', label='KNet')\n",
    "    axs[1, 1].fill_between(time_steps, \n",
    "                           knet_est_np[:, 0] - 3*knet_std_np[:, 0], \n",
    "                           knet_est_np[:, 0] + 3*knet_std_np[:, 0], \n",
    "                           color='green', alpha=0.2, label='$\\pm 3\\sigma$')\n",
    "    axs[1, 1].set_title(\"KNet: Pozice X s nejistotou\", fontweight='bold')\n",
    "    axs[1, 1].set_ylabel(\"X [m]\")\n",
    "    axs[1, 1].legend()\n",
    "    axs[1, 1].grid(True)\n",
    "\n",
    "# --- ŘÁDEK 3: Adaptive KF (AKF) - NOVÉ ---\n",
    "axs[2, 0].plot(gt_np[:, 0], gt_np[:, 2], 'k--', alpha=0.7)\n",
    "axs[2, 0].plot(akf_est_np[:, 0], akf_est_np[:, 2], color='purple', linewidth=2, label='AKF')\n",
    "axs[2, 0].set_title(f\"Adaptive KF (MSE: {mse_akf:.2f}): Trajektorie X-Y\", fontweight='bold')\n",
    "axs[2, 0].set_ylabel(\"Y [m]\")\n",
    "axs[2, 0].legend()\n",
    "axs[2, 0].grid(True)\n",
    "axs[2, 0].axis('equal')\n",
    "\n",
    "axs[2, 1].plot(time_steps, gt_np[:, 0], 'k--')\n",
    "axs[2, 1].plot(time_steps, akf_est_np[:, 0], color='purple', label='AKF')\n",
    "axs[2, 1].fill_between(time_steps, \n",
    "                       akf_est_np[:, 0] - 3*akf_std_np[:, 0], \n",
    "                       akf_est_np[:, 0] + 3*akf_std_np[:, 0], \n",
    "                       color='purple', alpha=0.2, label='$\\pm 3\\sigma$')\n",
    "axs[2, 1].set_title(\"Adaptive KF: Pozice X s nejistotou\", fontweight='bold')\n",
    "axs[2, 1].set_ylabel(\"X [m]\")\n",
    "axs[2, 1].legend()\n",
    "axs[2, 1].grid(True)\n",
    "\n",
    "# --- ŘÁDEK 4: Standard KF ---\n",
    "axs[3, 0].plot(gt_np[:, 0], gt_np[:, 2], 'k--', alpha=0.7)\n",
    "axs[3, 0].plot(kf_est_np[:, 0], kf_est_np[:, 2], 'r-', linewidth=2, label='KF')\n",
    "axs[3, 0].set_title(f\"Standard KF (MSE: {mse_kf:.2f}): Trajektorie X-Y\", fontweight='bold')\n",
    "axs[3, 0].set_xlabel(\"X [m]\")\n",
    "axs[3, 0].set_ylabel(\"Y [m]\")\n",
    "axs[3, 0].legend()\n",
    "axs[3, 0].grid(True)\n",
    "axs[3, 0].axis('equal')\n",
    "\n",
    "axs[3, 1].plot(time_steps, gt_np[:, 0], 'k--')\n",
    "axs[3, 1].plot(time_steps, kf_est_np[:, 0], 'r-', label='KF')\n",
    "axs[3, 1].fill_between(time_steps, \n",
    "                       kf_est_np[:, 0] - 3*kf_std_np[:, 0], \n",
    "                       kf_est_np[:, 0] + 3*kf_std_np[:, 0], \n",
    "                       color='red', alpha=0.2, label='$\\pm 3\\sigma$')\n",
    "axs[3, 1].set_title(\"Standard KF: Pozice X s nejistotou\", fontweight='bold')\n",
    "axs[3, 1].set_xlabel(\"Čas [kroky]\")\n",
    "axs[3, 1].set_ylabel(\"X [m]\")\n",
    "axs[3, 1].grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4506dde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# ==============================================================================\n",
    "# DIAGNOSTIKA: Structured AKF vs Standard KF (Full Trajectory)\n",
    "# ==============================================================================\n",
    "full_traj_path = '../preprocessed_NCLT_FULL/test_full_trajectory.pt' \n",
    "full_dataset = torch.load(full_traj_path)\n",
    "\n",
    "# Načtení dat\n",
    "x_true = full_dataset[0]['ground_truth'].to(device)\n",
    "y_seq = full_dataset[0]['filtered_gps'].to(device)\n",
    "seq_len = y_seq.shape[0]\n",
    "\n",
    "# Init stavy\n",
    "Ex0 = x_true[0, :].unsqueeze(1) \n",
    "P0 = sys_model.P0\n",
    "\n",
    "print(f\"Diagnostika pro sekvenci délky {seq_len}...\")\n",
    "\n",
    "# --- 1. SPUŠTĚNÍ AKF (Adaptive) ---\n",
    "print(\"Spouštím Adaptivní KF...\")\n",
    "# Zde si nastav parametry, které ti fungují nejlépe (např. s regularizací nebo limity)\n",
    "akf_filter = Filters.StructuredAdaptiveKalmanFilter(\n",
    "    sys_model, \n",
    "    mdm_L=10, \n",
    "    mdm_version=1, \n",
    "    forgetting_factor=0.98,\n",
    "    estimate_q_scale=True, \n",
    "    diagonal_R=True\n",
    ")\n",
    "res_akf, Q_hist, R_hist = akf_filter.process_sequence_adaptively(y_seq, Ex0=Ex0, P0=P0)\n",
    "\n",
    "# --- 2. SPUŠTĚNÍ STANDARD KF (Baseline) ---\n",
    "print(\"Spouštím Standardní KF...\")\n",
    "kf_filter = Filters.KalmanFilter(sys_model)\n",
    "res_kf = kf_filter.process_sequence(y_seq, Ex0=Ex0, P0=P0)\n",
    "\n",
    "# --- 3. EXTRAKCE DAT ---\n",
    "# AKF\n",
    "x_est_akf = res_akf['x_filtered'].detach().cpu().numpy()\n",
    "P_est_akf = res_akf['P_filtered'].detach().cpu().numpy()\n",
    "\n",
    "# KF\n",
    "x_est_kf = res_kf['x_filtered'].detach().cpu().numpy()\n",
    "\n",
    "# GT a Měření\n",
    "x_gt = x_true.detach().cpu().numpy()\n",
    "y_meas = y_seq.detach().cpu().numpy()\n",
    "\n",
    "# Historie Q a R (pro AKF)\n",
    "q_scale_est = np.array([q[0, 0].item() for q in Q_hist]) / sys_model.Q[0, 0].item()\n",
    "r_gps_hist = np.array([r[0, 0].item() for r in R_hist]) \n",
    "r_odo_hist = np.array([r[1, 1].item() for r in R_hist]) \n",
    "\n",
    "# Referenční hodnoty\n",
    "r_base_gps = sys_model.R[0, 0].item()\n",
    "r_base_odo = sys_model.R[1, 1].item()\n",
    "\n",
    "# Čas\n",
    "t = np.arange(seq_len)\n",
    "\n",
    "# --- 4. VÝPOČET METRIK (MSE) ---\n",
    "# Počítáme celkovou polohovou chybu (MSE Position = MSE_X + MSE_Y)\n",
    "mse_akf_x = np.mean((x_est_akf[:, 0] - x_gt[:, 0])**2)\n",
    "mse_akf_y = np.mean((x_est_akf[:, 2] - x_gt[:, 2])**2)\n",
    "mse_akf_total = mse_akf_x + mse_akf_y\n",
    "\n",
    "mse_kf_x = np.mean((x_est_kf[:, 0] - x_gt[:, 0])**2)\n",
    "mse_kf_y = np.mean((x_est_kf[:, 2] - x_gt[:, 2])**2)\n",
    "mse_kf_total = mse_kf_x + mse_kf_y\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(f\"VÝSLEDKY SROVNÁNÍ (Full Trajectory):\")\n",
    "print(f\"Standard KF MSE: {mse_kf_total:.4f} (RMSE: {np.sqrt(mse_kf_total):.4f} m)\")\n",
    "print(f\"Adaptive KF MSE: {mse_akf_total:.4f} (RMSE: {np.sqrt(mse_akf_total):.4f} m)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Chyba a sigma pro AKF (pro graf konzistence)\n",
    "error_x_akf = x_est_akf[:, 0] - x_gt[:, 0]\n",
    "sigma_x_akf = np.sqrt(P_est_akf[:, 0, 0])\n",
    "\n",
    "# ==============================================================================\n",
    "# 5. VIZUALIZACE\n",
    "# ==============================================================================\n",
    "fig = plt.figure(figsize=(20, 18))\n",
    "gs = fig.add_gridspec(4, 2)\n",
    "\n",
    "# A) Trajektorie (Top-down view) - SROVNÁNÍ\n",
    "ax1 = fig.add_subplot(gs[0, :])\n",
    "ax1.plot(x_gt[:, 0], x_gt[:, 2], 'k--', label='Ground Truth', linewidth=2, alpha=0.8)\n",
    "ax1.plot(x_est_kf[:, 0], x_est_kf[:, 2], 'r-', label=f'Standard KF (MSE={mse_kf_total:.1f})', linewidth=1.5, alpha=0.7)\n",
    "ax1.plot(x_est_akf[:, 0], x_est_akf[:, 2], 'm-', label=f'AKF Estimate (MSE={mse_akf_total:.1f})', linewidth=2)\n",
    "# Volitelně: vykreslit měření (často to dělá graf nepřehledným, zakomentuj dle potřeby)\n",
    "# ax1.scatter(y_meas[:, 0], y_meas[:, 2], c='gray', s=1, alpha=0.2, label='GPS Raw')\n",
    "\n",
    "ax1.set_title(f'Srovnání trajektorií: AKF vs KF', fontweight='bold', fontsize=14)\n",
    "ax1.set_xlabel('X [m]')\n",
    "ax1.set_ylabel('Y [m]')\n",
    "ax1.legend()\n",
    "ax1.axis('equal')\n",
    "ax1.grid(True)\n",
    "\n",
    "# B) Konzistence AKF (Chyba vs P)\n",
    "ax2 = fig.add_subplot(gs[1, 0])\n",
    "ax2.plot(t, error_x_akf, 'k-', label='Chyba AKF (X)', linewidth=1)\n",
    "ax2.plot(t, 3*sigma_x_akf, 'r--', label='+3 $\\sigma$ Bounds')\n",
    "ax2.plot(t, -3*sigma_x_akf, 'r--', label='-3 $\\sigma$ Bounds')\n",
    "ax2.set_title('Konzistence AKF (Chyba vs. Kovariance)', fontweight='bold')\n",
    "ax2.set_ylabel('Chyba X [m]')\n",
    "ax2.legend()\n",
    "ax2.grid(True)\n",
    "\n",
    "# C) Adaptace R (Measurement Noise)\n",
    "ax3 = fig.add_subplot(gs[2, 0])\n",
    "ax3.plot(t, r_gps_hist, 'b-', label='Est. R (GPS)', linewidth=2)\n",
    "ax3.axhline(r_base_gps, color='b', linestyle='--', alpha=0.5, label='Nominal R (GPS)')\n",
    "ax3.set_title('Adaptace R (Šum GPS)', fontweight='bold')\n",
    "ax3.set_ylabel('Variance [m²]')\n",
    "ax3.set_yscale('log') \n",
    "ax3.legend()\n",
    "ax3.grid(True)\n",
    "\n",
    "ax4 = fig.add_subplot(gs[2, 1])\n",
    "ax4.plot(t, r_odo_hist, 'g-', label='Est. R (Odometry)', linewidth=2)\n",
    "ax4.axhline(r_base_odo, color='g', linestyle='--', alpha=0.5, label='Nominal R (ODO)')\n",
    "ax4.set_title('Adaptace R (Šum Odometrie)', fontweight='bold')\n",
    "ax4.set_ylabel('Variance [(m/s)²]')\n",
    "ax4.set_yscale('log')\n",
    "ax4.legend()\n",
    "ax4.grid(True)\n",
    "\n",
    "# D) Adaptace Q (Process Noise)\n",
    "ax5 = fig.add_subplot(gs[3, :])\n",
    "ax5.plot(t, q_scale_est, 'purple', label='Q Scale Factor', linewidth=2)\n",
    "ax5.axhline(1.0, color='k', linestyle='--', label='Nominal Model (Scale=1.0)')\n",
    "ax5.set_title('Adaptace Q (Škálování procesního šumu)', fontweight='bold')\n",
    "ax5.set_ylabel('Násobek Q_base')\n",
    "ax5.set_yscale('log')\n",
    "ax5.legend()\n",
    "ax5.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
