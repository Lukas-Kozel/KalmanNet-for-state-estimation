{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434435b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "notebook_path = os.getcwd() \n",
    "parent_dir = os.path.dirname(notebook_path)\n",
    "project_root = os.path.dirname(parent_dir)\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63665f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d034973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import state_NN_models\n",
    "import Filters\n",
    "import utils\n",
    "import Systems\n",
    "from utils import losses, trainer, utils\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "from state_NN_models.StateBayesianKalmanNet import StateBayesianKalmanNet\n",
    "from state_NN_models.StateKalmanNet import StateKalmanNet\n",
    "from state_NN_models.RecursiveKalmanNet import StateRecursiveKalmanNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e61754ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pou≈æ√≠van√© za≈ô√≠zen√≠: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Pou≈æ√≠van√© za≈ô√≠zen√≠: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f446aa0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6180, 0.6180],\n",
      "        [0.0000, 0.6180]])\n",
      "\n",
      "Inicializuji 2D Linear_Canonical syst√©m (replikace autor≈Ø)...\n",
      "... 2D syst√©m inicializov√°n.\n"
     ]
    }
   ],
   "source": [
    "state_dim_2d = 2\n",
    "obs_dim_2d = 2\n",
    "\n",
    "F_base_2d = torch.tensor([[1.0, 1.0], \n",
    "                          [0.0, 1.0]])\n",
    "\n",
    "svd_F = torch.linalg.svd(F_base_2d)\n",
    "F_true_2d = F_base_2d / svd_F.S[0]\n",
    "print(F_true_2d)\n",
    "\n",
    "H_true_2d = torch.eye(obs_dim_2d)\n",
    "\n",
    "Q_true_2d = torch.eye(state_dim_2d) * 0.5 # ≈†um procesu\n",
    "R_true_2d = torch.eye(obs_dim_2d) * 0.1 # ≈†um mƒõ≈ôen√≠\n",
    "\n",
    "# Poƒç√°teƒçn√≠ podm√≠nky\n",
    "Ex0_true_2d = torch.tensor([[1.0], [0.0]])\n",
    "P0_true_2d = torch.eye(state_dim_2d) * 1.5\n",
    "F_model_2d = F_true_2d\n",
    "H_model_2d = H_true_2d\n",
    "Q_model_2d = torch.eye(state_dim_2d) * 0.1\n",
    "R_model_2d = R_true_2d\n",
    "Ex0_model_2d = torch.tensor([[0.5], [0.5]])\n",
    "P0_model_2d = torch.eye(state_dim_2d) * 1.0\n",
    "\n",
    "print(\"\\nInicializuji 2D Linear_Canonical syst√©m (replikace autor≈Ø)...\")\n",
    "sys_true = Systems.DynamicSystem(\n",
    "    state_dim=state_dim_2d, obs_dim=obs_dim_2d,\n",
    "    Ex0=Ex0_true_2d, P0=P0_true_2d,\n",
    "    Q=Q_true_2d, R=R_true_2d,\n",
    "    F=F_true_2d, H=H_true_2d,\n",
    "    device=device\n",
    ")\n",
    "sys_model = Systems.DynamicSystem(\n",
    "    state_dim=state_dim_2d, obs_dim=obs_dim_2d,\n",
    "    Ex0=Ex0_model_2d, P0=P0_model_2d,\n",
    "    Q=Q_model_2d, R=R_model_2d,\n",
    "    F=F_model_2d, H=H_model_2d,\n",
    "    device=device\n",
    ")\n",
    "print(\"... 2D syst√©m inicializov√°n.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a83c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "\n",
    "def train_RKN(\n",
    "    model, \n",
    "    train_loader, \n",
    "    val_loader, \n",
    "    device, \n",
    "    epochs=100, \n",
    "    lr=1e-3, \n",
    "    clip_grad=1.0, \n",
    "    early_stopping_patience=20, \n",
    "    optimizer_type=torch.optim.AdamW,\n",
    "    weight_decay=1e-5,\n",
    "    use_nll_loss=False\n",
    "):\n",
    "    if use_nll_loss and not model.returns_covariance:\n",
    "        raise ValueError(\"Cannot use NLL Loss if model.returns_covariance is False.\")\n",
    "\n",
    "    optimizer = optimizer_type(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.9)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    best_val_mse_at_opt = float('inf')\n",
    "    optimal_epoch = 0\n",
    "    epochs_no_improve = 0\n",
    "    best_model_state = None\n",
    "\n",
    "    print(f\"üöÄ START RKN Training (Epochs: {epochs}, LR: {lr}, NLL Loss: {use_nll_loss})\")\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss_sum = 0.0\n",
    "        train_mse_metric_sum = 0.0\n",
    "\n",
    "        for x_true_batch, y_meas_batch in train_loader:\n",
    "            x_true_batch = x_true_batch.to(device)\n",
    "            y_meas_batch = y_meas_batch.to(device)\n",
    "            batch_size, seq_len, _ = x_true_batch.shape\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            model.reset(batch_size=batch_size, initial_state=x_true_batch[:, 0, :])\n",
    "\n",
    "            predictions_x = []\n",
    "            predictions_P = []\n",
    "\n",
    "            for t in range(1, seq_len):\n",
    "                y_t = y_meas_batch[:, t, :]\n",
    "                \n",
    "                if model.returns_covariance:\n",
    "                    x_filtered_t, P_filtered_t, _ = model.step(y_t)\n",
    "                    predictions_P.append(P_filtered_t)\n",
    "                else:\n",
    "                    x_filtered_t, _ = model.step(y_t)\n",
    "                predictions_x.append(x_filtered_t)\n",
    "\n",
    "            predicted_trajectory = torch.stack(predictions_x, dim=1)\n",
    "            target_trajectory = x_true_batch[:, 1:, :]\n",
    "\n",
    "            if use_nll_loss:\n",
    "                predicted_cov_trajectory = torch.stack(predictions_P, dim=1)\n",
    "                I_eps = torch.eye(model.state_dim, device=device).view(1, 1, model.state_dim, model.state_dim) * 1e-6\n",
    "                safe_cov = predicted_cov_trajectory + I_eps\n",
    "                \n",
    "                error = (target_trajectory - predicted_trajectory).unsqueeze(-1)\n",
    "                flat_cov = safe_cov.view(-1, model.state_dim, model.state_dim)\n",
    "                flat_err = error.view(-1, model.state_dim, 1)\n",
    "                \n",
    "                try:\n",
    "                    cov_inv = torch.linalg.pinv(flat_cov, hermitian=True)\n",
    "                    mahalanobis = torch.bmm(torch.bmm(flat_err.transpose(1, 2), cov_inv), flat_err).squeeze()\n",
    "                    sign, logdet = torch.linalg.slogdet(flat_cov)\n",
    "                    loss = 0.5 * (mahalanobis + logdet).mean()\n",
    "                except torch._C._LinAlgError:\n",
    "                    loss = F.mse_loss(predicted_trajectory, target_trajectory)\n",
    "            else:\n",
    "                loss = F.mse_loss(predicted_trajectory, target_trajectory)\n",
    "\n",
    "            loss.backward()\n",
    "            if clip_grad > 0:\n",
    "                nn.utils.clip_grad_norm_(model.parameters(), clip_grad)\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss_sum += loss.item()\n",
    "            with torch.no_grad():\n",
    "                train_mse_metric_sum += F.mse_loss(predicted_trajectory, target_trajectory).item()\n",
    "\n",
    "        scheduler.step()\n",
    "        avg_train_loss = train_loss_sum / len(train_loader)\n",
    "        avg_train_mse = train_mse_metric_sum / len(train_loader)\n",
    "\n",
    "        # === Validation Phase ===\n",
    "        model.eval()\n",
    "        val_loss_sum = 0.0\n",
    "        val_mse_sum = 0.0\n",
    "        val_anees_sum = 0.0  # <--- Sbƒõr ANEES\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for x_true_val, y_meas_val in val_loader:\n",
    "                x_true_val = x_true_val.to(device)\n",
    "                y_meas_val = y_meas_val.to(device)\n",
    "                batch_size_val, seq_len_val, _ = x_true_val.shape\n",
    "\n",
    "                model.reset(batch_size=batch_size_val, initial_state=x_true_val[:, 0, :])\n",
    "                \n",
    "                val_predictions_x = []\n",
    "                val_predictions_P = []\n",
    "\n",
    "                for t in range(1, seq_len_val):\n",
    "                    y_t_val = y_meas_val[:, t, :]\n",
    "                    if model.returns_covariance:\n",
    "                        x_filtered_t_val, P_filtered_t_val, _ = model.step(y_t_val)\n",
    "                        val_predictions_P.append(P_filtered_t_val)\n",
    "                    else:\n",
    "                        x_filtered_t_val, _ = model.step(y_t_val)\n",
    "                    val_predictions_x.append(x_filtered_t_val)\n",
    "                    \n",
    "                predicted_val_trajectory = torch.stack(val_predictions_x, dim=1)\n",
    "                target_val_trajectory = x_true_val[:, 1:, :]\n",
    "\n",
    "                if use_nll_loss:\n",
    "                    predicted_cov_val = torch.stack(val_predictions_P, dim=1)\n",
    "                    safe_cov_val = predicted_cov_val + I_eps\n",
    "                    error_val = (target_val_trajectory - predicted_val_trajectory).unsqueeze(-1)\n",
    "                    flat_cov_v = safe_cov_val.view(-1, model.state_dim, model.state_dim)\n",
    "                    flat_err_v = error_val.view(-1, model.state_dim, 1)\n",
    "                    \n",
    "                    try:\n",
    "                        cov_inv_v = torch.linalg.pinv(flat_cov_v, hermitian=True)\n",
    "                        mahal_v = torch.bmm(torch.bmm(flat_err_v.transpose(1, 2), cov_inv_v), flat_err_v).squeeze()\n",
    "                        _, logdet_v = torch.linalg.slogdet(flat_cov_v)\n",
    "                        loss_v = 0.5 * (mahal_v + logdet_v).mean()\n",
    "                        \n",
    "                        val_anees_sum += mahal_v.mean().item()  # <--- Ukl√°d√°me pr≈Ømƒõrn√Ω ANEES za d√°vku\n",
    "                    except torch._C._LinAlgError:\n",
    "                        loss_v = F.mse_loss(predicted_val_trajectory, target_val_trajectory)\n",
    "                        val_anees_sum += float('nan')\n",
    "                else:\n",
    "                    loss_v = F.mse_loss(predicted_val_trajectory, target_val_trajectory)\n",
    "                \n",
    "                val_loss_sum += loss_v.item()\n",
    "                val_mse_sum += F.mse_loss(predicted_val_trajectory, target_val_trajectory).item()\n",
    "\n",
    "        avg_val_loss = val_loss_sum / len(val_loader)\n",
    "        avg_val_mse = val_mse_sum / len(val_loader)\n",
    "        avg_val_anees = val_anees_sum / len(val_loader) if use_nll_loss else float('nan')\n",
    "        \n",
    "        # --- Nov√Ω logovac√≠ form√°t s ANEES ---\n",
    "        if use_nll_loss:\n",
    "            print(f\"Epoch: {epoch+1}/{epochs} | Train NLL: {avg_train_loss:.4f} | Val NLL: {avg_val_loss:.4f} | MSE: {avg_val_mse:.4f} | ANEES: {avg_val_anees:.2f} | LR: {scheduler.get_last_lr()[0]:.2e}\")\n",
    "        else:\n",
    "            print(f\"Epoch: {epoch+1}/{epochs} | Train MSE: {avg_train_loss:.4f} | Val MSE: {avg_val_loss:.4f} | LR: {scheduler.get_last_lr()[0]:.2e}\")\n",
    "        \n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            best_val_mse_at_opt = avg_val_mse\n",
    "            optimal_epoch = epoch + 1\n",
    "            epochs_no_improve = 0\n",
    "            best_model_state = deepcopy(model.state_dict())\n",
    "            print(f\"  >>> Optimal idx: {optimal_epoch} | Optimal Val Loss: {best_val_loss:.4f} <<<\")\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        if epochs_no_improve >= early_stopping_patience:\n",
    "            print(f\"\\nEarly stopping triggered after {epoch + 1} epochs.\")\n",
    "            break\n",
    "            \n",
    "    print(\"\\nTraining complete. Best Validation Loss:\", best_val_loss)\n",
    "    if best_model_state:\n",
    "        model.load_state_dict(best_model_state)\n",
    "        print(\"Optimal model loaded.\")\n",
    "        \n",
    "    return {\n",
    "        \"final_model\": model,\n",
    "        \"best_epoch\": optimal_epoch,\n",
    "        \"best_val_loss\": best_val_loss,\n",
    "        \"best_val_mse\": best_val_mse_at_opt\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9c41ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SEQ_LEN = 10      # Kr√°tk√© sekvence pro stabiln√≠ tr√©nink (TBPTT)\n",
    "VALID_SEQ_LEN = 20      # Stejn√° d√©lka pro konzistentn√≠ validaci\n",
    "TEST_SEQ_LEN = 100      # Dlouh√© sekvence pro testov√°n√≠ generalizace\n",
    "\n",
    "NUM_TRAIN_TRAJ = 500   # Hodnƒõ tr√©novac√≠ch p≈ô√≠klad≈Ø\n",
    "NUM_VALID_TRAJ = 200    # Dostatek pro spolehlivou validaci\n",
    "NUM_TEST_TRAJ = 100     # Pro robustn√≠ vyhodnocen√≠\n",
    "\n",
    "BATCH_SIZE = 8         # Dobr√Ω kompromis\n",
    "\n",
    "x_train, y_train = utils.generate_data(sys_true, num_trajectories=NUM_TRAIN_TRAJ, seq_len=TRAIN_SEQ_LEN)\n",
    "x_val, y_val = utils.generate_data(sys_true, num_trajectories=NUM_VALID_TRAJ, seq_len=VALID_SEQ_LEN)\n",
    "x_test, y_test = utils.generate_data(sys_true, num_trajectories=1, seq_len=TEST_SEQ_LEN)\n",
    "\n",
    "train_dataset = TensorDataset(x_train, y_train)\n",
    "val_dataset = TensorDataset(x_val, y_val)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad00e88f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Spou≈°t√≠m jeden plnohodnotn√Ω tr√©ninkov√Ω bƒõh (Recursive KalmanNet)...\n",
      "Parametry architektury: {'nb_layer_FC1': 1, 'FC1_mult': 10, 'nbr_GRU': 1, 'hidden_size_mult': 10, 'nb_layer_FC2': 1, 'FC2_mult': 20}\n",
      "Parametry tr√©ninku: {'epochs': 100, 'lr': 0.001, 'clip_grad': 10.0, 'early_stopping_patience': 20, 'use_nll_loss': True}\n",
      "================================================================================\n",
      "üöÄ START RKN Training (Epochs: 100, LR: 0.001, NLL Loss: True)\n",
      "Epoch: 1/100 | Train Loss: 103.5805 | Val Loss: -1.3828 (MSE: 0.0907) | LR: 1.00e-03\n",
      "  >>> Optimal idx: 1 | Optimal Val Loss: -1.3828 <<<\n",
      "Epoch: 2/100 | Train Loss: -1.4447 | Val Loss: -1.4508 (MSE: 0.0853) | LR: 1.00e-03\n",
      "  >>> Optimal idx: 2 | Optimal Val Loss: -1.4508 <<<\n",
      "Epoch: 3/100 | Train Loss: -1.4589 | Val Loss: -1.4392 (MSE: 0.0862) | LR: 1.00e-03\n",
      "Epoch: 4/100 | Train Loss: -1.4630 | Val Loss: -1.4588 (MSE: 0.0852) | LR: 1.00e-03\n",
      "  >>> Optimal idx: 4 | Optimal Val Loss: -1.4588 <<<\n",
      "Epoch: 5/100 | Train Loss: -1.4607 | Val Loss: -1.4510 (MSE: 0.0856) | LR: 1.00e-03\n",
      "Epoch: 6/100 | Train Loss: -1.4601 | Val Loss: -1.4470 (MSE: 0.0864) | LR: 1.00e-03\n",
      "Epoch: 7/100 | Train Loss: -1.4621 | Val Loss: -1.4466 (MSE: 0.0856) | LR: 1.00e-03\n",
      "Epoch: 8/100 | Train Loss: -1.4717 | Val Loss: -1.4319 (MSE: 0.0870) | LR: 1.00e-03\n",
      "Epoch: 9/100 | Train Loss: -1.4597 | Val Loss: -1.4472 (MSE: 0.0862) | LR: 1.00e-03\n",
      "Epoch: 10/100 | Train Loss: -1.4714 | Val Loss: -1.4602 (MSE: 0.0850) | LR: 9.00e-04\n",
      "  >>> Optimal idx: 10 | Optimal Val Loss: -1.4602 <<<\n",
      "Epoch: 11/100 | Train Loss: -1.4719 | Val Loss: -1.4578 (MSE: 0.0854) | LR: 9.00e-04\n",
      "Epoch: 12/100 | Train Loss: -1.4672 | Val Loss: -1.4617 (MSE: 0.0848) | LR: 9.00e-04\n",
      "  >>> Optimal idx: 12 | Optimal Val Loss: -1.4617 <<<\n",
      "Epoch: 13/100 | Train Loss: -1.4719 | Val Loss: -1.4537 (MSE: 0.0856) | LR: 9.00e-04\n",
      "Epoch: 14/100 | Train Loss: -1.4685 | Val Loss: -1.4424 (MSE: 0.0860) | LR: 9.00e-04\n",
      "Epoch: 15/100 | Train Loss: -1.4691 | Val Loss: -1.4449 (MSE: 0.0850) | LR: 9.00e-04\n",
      "Epoch: 16/100 | Train Loss: -1.4801 | Val Loss: -1.4512 (MSE: 0.0853) | LR: 9.00e-04\n",
      "Epoch: 17/100 | Train Loss: -1.4748 | Val Loss: -1.4495 (MSE: 0.0862) | LR: 9.00e-04\n",
      "Epoch: 18/100 | Train Loss: -1.4720 | Val Loss: -1.4152 (MSE: 0.0889) | LR: 9.00e-04\n",
      "Epoch: 19/100 | Train Loss: -1.4676 | Val Loss: -1.4596 (MSE: 0.0850) | LR: 9.00e-04\n",
      "Epoch: 20/100 | Train Loss: -1.4763 | Val Loss: -1.4566 (MSE: 0.0852) | LR: 8.10e-04\n",
      "Epoch: 21/100 | Train Loss: -1.4714 | Val Loss: -1.4558 (MSE: 0.0853) | LR: 8.10e-04\n",
      "Epoch: 22/100 | Train Loss: -1.4748 | Val Loss: -1.4478 (MSE: 0.0860) | LR: 8.10e-04\n",
      "Epoch: 23/100 | Train Loss: -1.4743 | Val Loss: -1.4490 (MSE: 0.0858) | LR: 8.10e-04\n",
      "Epoch: 24/100 | Train Loss: -1.4719 | Val Loss: -1.4569 (MSE: 0.0853) | LR: 8.10e-04\n",
      "Epoch: 25/100 | Train Loss: -1.4828 | Val Loss: -1.4548 (MSE: 0.0854) | LR: 8.10e-04\n",
      "Epoch: 26/100 | Train Loss: -1.4837 | Val Loss: -1.4514 (MSE: 0.0855) | LR: 8.10e-04\n",
      "Epoch: 27/100 | Train Loss: -1.4803 | Val Loss: -1.4385 (MSE: 0.0862) | LR: 8.10e-04\n",
      "Epoch: 28/100 | Train Loss: -1.4790 | Val Loss: -1.4553 (MSE: 0.0854) | LR: 8.10e-04\n",
      "Epoch: 29/100 | Train Loss: -1.4796 | Val Loss: -1.4461 (MSE: 0.0857) | LR: 8.10e-04\n",
      "Epoch: 30/100 | Train Loss: -1.4713 | Val Loss: -1.4466 (MSE: 0.0859) | LR: 7.29e-04\n",
      "Epoch: 31/100 | Train Loss: -1.4854 | Val Loss: -1.4517 (MSE: 0.0855) | LR: 7.29e-04\n",
      "Epoch: 32/100 | Train Loss: -1.4847 | Val Loss: -1.4422 (MSE: 0.0860) | LR: 7.29e-04\n",
      "\n",
      "Early stopping triggered after 32 epochs.\n",
      "\n",
      "Training complete. Best Validation Loss: -1.4617158317565917\n",
      "Optimal model loaded.\n",
      "\n",
      "================================================================================\n",
      "TR√âNINK DOKONƒåEN - FIN√ÅLN√ç V√ùSLEDKY Z NEJLEP≈†√çHO MODELU\n",
      "================================================================================\n",
      "Nejlep≈°√≠ model byl nalezen v epo≈°e: 12\n",
      "--- Metriky odpov√≠daj√≠c√≠ tomuto nejlep≈°√≠mu modelu ---\n",
      "  MSE na validaƒçn√≠ sadƒõ:       0.0848\n",
      "  Validaƒçn√≠ Loss (NLL):        -1.4617\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "rkn_architecture_config = {\n",
    "    'nb_layer_FC1': 1,\n",
    "    'FC1_mult': 10,\n",
    "    'nbr_GRU': 1,\n",
    "    'hidden_size_mult': 10,\n",
    "    'nb_layer_FC2': 1,\n",
    "    'FC2_mult': 20,\n",
    "}\n",
    "\n",
    "# Parametry pro konstruktor StateRecursiveKalmanNet\n",
    "model_config = {\n",
    "    \"config\": rkn_architecture_config,\n",
    "    \"weight_factor\": 0.1,         # Auto≈ôi pou≈æ√≠vaj√≠ pro zmen≈°en√≠ inici√°ln√≠ch vah\n",
    "    \"returns_covariance\": True    # Povol√≠ v√Ωpoƒçet matice P (nutn√©, pokud chceme zkusit NLL Loss)\n",
    "}\n",
    "\n",
    "# Parametry pro tr√©novac√≠ funkci train_RKN\n",
    "train_config = {\n",
    "    \"epochs\": 100,               # RKN zpracov√°v√° sekvence celostnƒõ, pou≈æ√≠v√°me epochy\n",
    "    \"lr\": 1e-3,\n",
    "    \"clip_grad\": 10.0,\n",
    "    \"early_stopping_patience\": 20,\n",
    "    \"use_nll_loss\": True        # Zpoƒç√°tku doporuƒçuji False (ƒçist√© MSE) pro maxim√°ln√≠ stabilitu\n",
    "}\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"Spou≈°t√≠m jeden plnohodnotn√Ω tr√©ninkov√Ω bƒõh (Recursive KalmanNet)...\")\n",
    "print(f\"Parametry architektury: {rkn_architecture_config}\")\n",
    "print(f\"Parametry tr√©ninku: {train_config}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Nastaven√≠ seedu\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Vytvo≈ôen√≠ modelu (P≈ôedpokl√°d√°m, ≈æe t≈ô√≠da StateRecursiveKalmanNet je spu≈°tƒõna v bu≈àce nad t√≠mto)\n",
    "state_rkn = StateRecursiveKalmanNet(\n",
    "    sys_model,\n",
    "    device=device,\n",
    "    **model_config\n",
    ").to(device)\n",
    "\n",
    "# Spu≈°tƒõn√≠ tr√©ninku pomoc√≠ nov√© funkce\n",
    "results = train_RKN(\n",
    "    model=state_rkn,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    device=device,\n",
    "    **train_config\n",
    ")\n",
    "\n",
    "trained_model = results['final_model']\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TR√âNINK DOKONƒåEN - FIN√ÅLN√ç V√ùSLEDKY Z NEJLEP≈†√çHO MODELU\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Nejlep≈°√≠ model byl nalezen v epo≈°e: {results['best_epoch']}\")\n",
    "print(\"--- Metriky odpov√≠daj√≠c√≠ tomuto nejlep≈°√≠mu modelu ---\")\n",
    "print(f\"  MSE na validaƒçn√≠ sadƒõ:       {results['best_val_mse']:.4f}\")\n",
    "\n",
    "# NLL a ANEES vypisujeme pouze pokud jsme optimalizovali s NLL\n",
    "if train_config['use_nll_loss']:\n",
    "    print(f\"  Validaƒçn√≠ Loss (NLL):        {results['best_val_loss']:.4f}\")\n",
    "else:\n",
    "    print(f\"  Validaƒçn√≠ Loss (MSE):        {results['best_val_loss']:.4f}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b62217b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Layer 'output_final_linear.0' initialized near zero (Start K=0).\n",
      "New best model saved! Epoch [1/100], Train Loss: 0.704641, Val Loss: 0.585440\n",
      "New best model saved! Epoch [2/100], Train Loss: 0.475780, Val Loss: 0.391406\n",
      "New best model saved! Epoch [3/100], Train Loss: 0.338607, Val Loss: 0.287173\n",
      "New best model saved! Epoch [4/100], Train Loss: 0.254932, Val Loss: 0.218205\n",
      "Epoch [5/100] | Train Loss: 0.1936 (Pos: 0.00, Vel: 0.00) | Val Loss: 0.1633 | Val MSE: 0.16\n",
      "Epoch [4/100], Train Loss: 0.254932, Val Loss: 0.218205\n",
      "New best model saved! Epoch [5/100], Train Loss: 0.193583, Val Loss: 0.163264\n",
      "New best model saved! Epoch [6/100], Train Loss: 0.143375, Val Loss: 0.120105\n",
      "New best model saved! Epoch [7/100], Train Loss: 0.110473, Val Loss: 0.099017\n",
      "New best model saved! Epoch [8/100], Train Loss: 0.095222, Val Loss: 0.090171\n",
      "New best model saved! Epoch [9/100], Train Loss: 0.088264, Val Loss: 0.086727\n",
      "Epoch [10/100] | Train Loss: 0.0857 (Pos: 0.00, Vel: 0.00) | Val Loss: 0.0855 | Val MSE: 0.09\n",
      "Epoch [9/100], Train Loss: 0.088264, Val Loss: 0.086727\n",
      "New best model saved! Epoch [10/100], Train Loss: 0.085749, Val Loss: 0.085458\n",
      "New best model saved! Epoch [11/100], Train Loss: 0.084586, Val Loss: 0.085141\n",
      "New best model saved! Epoch [12/100], Train Loss: 0.084240, Val Loss: 0.085061\n",
      "New best model saved! Epoch [13/100], Train Loss: 0.083939, Val Loss: 0.085045\n",
      "Epoch [15/100] | Train Loss: 0.0840 (Pos: 0.00, Vel: 0.00) | Val Loss: 0.0851 | Val MSE: 0.09\n",
      "Epoch [13/100], Train Loss: 0.083939, Val Loss: 0.085045\n",
      "New best model saved! Epoch [17/100], Train Loss: 0.084040, Val Loss: 0.085024\n",
      "New best model saved! Epoch [18/100], Train Loss: 0.083908, Val Loss: 0.085023\n",
      "New best model saved! Epoch [19/100], Train Loss: 0.083823, Val Loss: 0.085006\n",
      "Epoch [20/100] | Train Loss: 0.0839 (Pos: 0.00, Vel: 0.00) | Val Loss: 0.0850 | Val MSE: 0.08\n",
      "Epoch [19/100], Train Loss: 0.083823, Val Loss: 0.085006\n",
      "New best model saved! Epoch [20/100], Train Loss: 0.083935, Val Loss: 0.084998\n",
      "New best model saved! Epoch [21/100], Train Loss: 0.083817, Val Loss: 0.084971\n",
      "New best model saved! Epoch [23/100], Train Loss: 0.083782, Val Loss: 0.084954\n",
      "New best model saved! Epoch [24/100], Train Loss: 0.084150, Val Loss: 0.084928\n",
      "Epoch [25/100] | Train Loss: 0.0837 (Pos: 0.00, Vel: 0.00) | Val Loss: 0.0849 | Val MSE: 0.08\n",
      "Epoch [24/100], Train Loss: 0.084150, Val Loss: 0.084928\n",
      "New best model saved! Epoch [25/100], Train Loss: 0.083740, Val Loss: 0.084923\n",
      "New best model saved! Epoch [29/100], Train Loss: 0.083829, Val Loss: 0.084898\n",
      "Epoch [30/100] | Train Loss: 0.0835 (Pos: 0.00, Vel: 0.00) | Val Loss: 0.0849 | Val MSE: 0.08\n",
      "Epoch [29/100], Train Loss: 0.083829, Val Loss: 0.084898\n",
      "New best model saved! Epoch [30/100], Train Loss: 0.083512, Val Loss: 0.084889\n",
      "New best model saved! Epoch [32/100], Train Loss: 0.083667, Val Loss: 0.084885\n",
      "New best model saved! Epoch [33/100], Train Loss: 0.083769, Val Loss: 0.084857\n",
      "Epoch [35/100] | Train Loss: 0.0837 (Pos: 0.00, Vel: 0.00) | Val Loss: 0.0849 | Val MSE: 0.08\n",
      "Epoch [33/100], Train Loss: 0.083769, Val Loss: 0.084857\n",
      "New best model saved! Epoch [35/100], Train Loss: 0.083736, Val Loss: 0.084851\n",
      "New best model saved! Epoch [36/100], Train Loss: 0.083672, Val Loss: 0.084849\n",
      "Epoch [40/100] | Train Loss: 0.0836 (Pos: 0.00, Vel: 0.00) | Val Loss: 0.0848 | Val MSE: 0.08\n",
      "Epoch [36/100], Train Loss: 0.083672, Val Loss: 0.084849\n",
      "New best model saved! Epoch [40/100], Train Loss: 0.083632, Val Loss: 0.084834\n",
      "New best model saved! Epoch [41/100], Train Loss: 0.083831, Val Loss: 0.084818\n",
      "Epoch [45/100] | Train Loss: 0.0837 (Pos: 0.00, Vel: 0.00) | Val Loss: 0.0848 | Val MSE: 0.08\n",
      "Epoch [41/100], Train Loss: 0.083831, Val Loss: 0.084818\n",
      "New best model saved! Epoch [46/100], Train Loss: 0.083723, Val Loss: 0.084795\n",
      "Epoch [50/100] | Train Loss: 0.0837 (Pos: 0.00, Vel: 0.00) | Val Loss: 0.0848 | Val MSE: 0.08\n",
      "Epoch [46/100], Train Loss: 0.083723, Val Loss: 0.084795\n",
      "New best model saved! Epoch [51/100], Train Loss: 0.083597, Val Loss: 0.084786\n",
      "Epoch [55/100] | Train Loss: 0.0836 (Pos: 0.00, Vel: 0.00) | Val Loss: 0.0848 | Val MSE: 0.08\n",
      "Epoch [51/100], Train Loss: 0.083597, Val Loss: 0.084786\n",
      "New best model saved! Epoch [56/100], Train Loss: 0.083505, Val Loss: 0.084777\n",
      "Epoch [60/100] | Train Loss: 0.0835 (Pos: 0.00, Vel: 0.00) | Val Loss: 0.0848 | Val MSE: 0.08\n",
      "Epoch [56/100], Train Loss: 0.083505, Val Loss: 0.084777\n",
      "Epoch [65/100] | Train Loss: 0.0836 (Pos: 0.00, Vel: 0.00) | Val Loss: 0.0848 | Val MSE: 0.08\n",
      "Epoch [56/100], Train Loss: 0.083505, Val Loss: 0.084777\n",
      "Epoch [70/100] | Train Loss: 0.0835 (Pos: 0.00, Vel: 0.00) | Val Loss: 0.0848 | Val MSE: 0.08\n",
      "Epoch [56/100], Train Loss: 0.083505, Val Loss: 0.084777\n",
      "New best model saved! Epoch [70/100], Train Loss: 0.083485, Val Loss: 0.084775\n",
      "Epoch [75/100] | Train Loss: 0.0836 (Pos: 0.00, Vel: 0.00) | Val Loss: 0.0848 | Val MSE: 0.08\n",
      "Epoch [70/100], Train Loss: 0.083485, Val Loss: 0.084775\n",
      "New best model saved! Epoch [79/100], Train Loss: 0.083433, Val Loss: 0.084766\n",
      "Epoch [80/100] | Train Loss: 0.0834 (Pos: 0.00, Vel: 0.00) | Val Loss: 0.0848 | Val MSE: 0.08\n",
      "Epoch [79/100], Train Loss: 0.083433, Val Loss: 0.084766\n",
      "Epoch [85/100] | Train Loss: 0.0837 (Pos: 0.00, Vel: 0.00) | Val Loss: 0.0848 | Val MSE: 0.08\n",
      "Epoch [79/100], Train Loss: 0.083433, Val Loss: 0.084766\n",
      "Epoch [90/100] | Train Loss: 0.0835 (Pos: 0.00, Vel: 0.00) | Val Loss: 0.0849 | Val MSE: 0.08\n",
      "Epoch [79/100], Train Loss: 0.083433, Val Loss: 0.084766\n",
      "Epoch [95/100] | Train Loss: 0.0830 (Pos: 0.00, Vel: 0.00) | Val Loss: 0.0849 | Val MSE: 0.08\n",
      "Epoch [79/100], Train Loss: 0.083433, Val Loss: 0.084766\n",
      "Epoch [100/100] | Train Loss: 0.0832 (Pos: 0.00, Vel: 0.00) | Val Loss: 0.0849 | Val MSE: 0.08\n",
      "Epoch [79/100], Train Loss: 0.083433, Val Loss: 0.084766\n",
      "Training completed.\n",
      "Loading best model with validation loss: 0.084766\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StateKalmanNet(\n",
       "  (dnn): DNN_KalmanNet(\n",
       "    (input_layer): Sequential(\n",
       "      (0): Linear(in_features=8, out_features=384, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (gru): GRU(384, 8)\n",
       "    (output_hidden_layer): Sequential(\n",
       "      (0): Linear(in_features=8, out_features=16, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (output_final_linear): Sequential(\n",
       "      (0): Linear(in_features=16, out_features=4, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "# Nastaven√≠ seedu pro reprodukovatelnost tohoto bƒõhu\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "state_knet = StateKalmanNet(sys_model, device=device, hidden_size_multiplier=12).to(device)\n",
    "trainer.train_state_KalmanNet(\n",
    "    model=state_knet, \n",
    "    train_loader=train_loader, \n",
    "    val_loader=val_loader, \n",
    "    device=device, \n",
    "    epochs=100, \n",
    "    lr=1e-4,\n",
    "    early_stopping_patience=30\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f78c01",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "DNN_KalmanNet.forward() missing 3 required positional arguments: 'diff_state', 'diff_obs', and 'h_prev'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m random\u001b[38;5;241m.\u001b[39mseed(\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m     16\u001b[0m state_knetR \u001b[38;5;241m=\u001b[39m StateKalmanNetWithKnownR(sys_model, device\u001b[38;5;241m=\u001b[39mdevice, hidden_size_multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m12\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 17\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_state_KalmanNet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate_knetR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_patience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\n\u001b[1;32m     25\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/skola/KalmanNet-main/utils/trainer.py:629\u001b[0m, in \u001b[0;36mtrain_state_KalmanNet\u001b[0;34m(model, train_loader, val_loader, device, epochs, lr, clip_grad, early_stopping_patience, optimizer_type, weight_decay, print_gradient)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, seq_len):\n\u001b[1;32m    628\u001b[0m     y_t \u001b[38;5;241m=\u001b[39m y_meas_batch[:, t, :]\n\u001b[0;32m--> 629\u001b[0m     step_output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_t\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m returns_covariance:\n\u001b[1;32m    632\u001b[0m         x_filtered_t, P_filtered_t \u001b[38;5;241m=\u001b[39m step_output\n",
      "File \u001b[0;32m~/skola/KalmanNet-main/state_NN_models/StateKalmanNetWithKnownR.py:59\u001b[0m, in \u001b[0;36mStateKalmanNetWithKnownR.step\u001b[0;34m(self, y_t)\u001b[0m\n\u001b[1;32m     56\u001b[0m norm_delta_x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mnormalize(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelta_x_prev, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, eps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-12\u001b[39m)\n\u001b[1;32m     57\u001b[0m nn_input \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([norm_delta_x, norm_innovation], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 59\u001b[0m K_vec, h_new \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnn_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mh_prev\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m K \u001b[38;5;241m=\u001b[39m K_vec\u001b[38;5;241m.\u001b[39mreshape(batch_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate_dim, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobs_dim)\n\u001b[1;32m     62\u001b[0m mean_K_for_step \u001b[38;5;241m=\u001b[39m K\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: DNN_KalmanNet.forward() missing 3 required positional arguments: 'diff_state', 'diff_obs', and 'h_prev'"
     ]
    }
   ],
   "source": [
    "\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# from torch.utils.data import TensorDataset, DataLoader\n",
    "# import numpy as np\n",
    "# import os\n",
    "# import random\n",
    "# import csv\n",
    "# from datetime import datetime\n",
    "# import pandas as pd\n",
    "# from copy import deepcopy\n",
    "# from state_NN_models.StateKalmanNetWithKnownR import StateKalmanNetWithKnownR\n",
    "# # Nastaven√≠ seedu pro reprodukovatelnost tohoto bƒõhu\n",
    "# torch.manual_seed(42)\n",
    "# np.random.seed(42)\n",
    "# random.seed(42)\n",
    "# state_knetR = StateKalmanNetWithKnownR(sys_model, device=device, hidden_size_multiplier=12).to(device)\n",
    "# trainer.train_state_KalmanNet(\n",
    "#     model=state_knetR, \n",
    "#     train_loader=train_loader, \n",
    "#     val_loader=val_loader, \n",
    "#     device=device, \n",
    "#     epochs=50, \n",
    "#     lr=1e-4,\n",
    "#     early_stopping_patience=30\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "453b1b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: V≈°echny natr√©novan√© modely nalezeny a p≈ôi≈ôazeny.\n",
      "\n",
      "Generuji 10 testovac√≠ch trajektori√≠ o d√©lce 1000...\n",
      "Generov√°n√≠ dat dokonƒçeno.\n",
      "V≈°echny model-based filtry (EKF, UKF, AKF) inicializov√°ny.\n",
      "\n",
      "Vyhodnocuji modely na 10 testovac√≠ch trajektori√≠ch...\n",
      "Spou≈°t√≠m MDM odhad Q a R...\n",
      "MDM odhad dokonƒçen.\n",
      "Odhadnut√© Q:\n",
      " [[0.53521981 0.00161313]\n",
      " [0.00161313 0.55229666]]\n",
      "Odhadnut√© R:\n",
      " [[0.07874503 0.00212589]\n",
      " [0.00212589 0.03761439]]\n",
      "Matice Q a R v Kalmanovƒõ filtru byly aktualizov√°ny.\n",
      "Dokonƒçena trajektorie 1/10...\n",
      "Spou≈°t√≠m MDM odhad Q a R...\n",
      "MDM odhad dokonƒçen.\n",
      "Odhadnut√© Q:\n",
      " [[0.51748314 0.00151425]\n",
      " [0.00151425 0.50499735]]\n",
      "Odhadnut√© R:\n",
      " [[ 0.07691707 -0.00475298]\n",
      " [-0.00475298  0.12057272]]\n",
      "Matice Q a R v Kalmanovƒõ filtru byly aktualizov√°ny.\n",
      "Dokonƒçena trajektorie 2/10...\n",
      "Spou≈°t√≠m MDM odhad Q a R...\n",
      "MDM odhad dokonƒçen.\n",
      "Odhadnut√© Q:\n",
      " [[ 0.54914774 -0.04203468]\n",
      " [-0.04203468  0.55944857]]\n",
      "Odhadnut√© R:\n",
      " [[0.06492597 0.02485289]\n",
      " [0.02485289 0.09486328]]\n",
      "Matice Q a R v Kalmanovƒõ filtru byly aktualizov√°ny.\n",
      "Dokonƒçena trajektorie 3/10...\n",
      "Spou≈°t√≠m MDM odhad Q a R...\n",
      "MDM odhad dokonƒçen.\n",
      "Odhadnut√© Q:\n",
      " [[0.43211876 0.06135003]\n",
      " [0.06135003 0.4502503 ]]\n",
      "Odhadnut√© R:\n",
      " [[ 0.13576756 -0.05224275]\n",
      " [-0.05224275  0.11729857]]\n",
      "Matice Q a R v Kalmanovƒõ filtru byly aktualizov√°ny.\n",
      "Dokonƒçena trajektorie 4/10...\n",
      "Spou≈°t√≠m MDM odhad Q a R...\n",
      "MDM odhad dokonƒçen.\n",
      "Odhadnut√© Q:\n",
      " [[ 0.45127091 -0.05330535]\n",
      " [-0.05330535  0.48407449]]\n",
      "Odhadnut√© R:\n",
      " [[0.1332765  0.00776848]\n",
      " [0.00776848 0.12902066]]\n",
      "Matice Q a R v Kalmanovƒõ filtru byly aktualizov√°ny.\n",
      "Dokonƒçena trajektorie 5/10...\n",
      "Spou≈°t√≠m MDM odhad Q a R...\n",
      "MDM odhad dokonƒçen.\n",
      "Odhadnut√© Q:\n",
      " [[0.40096727 0.04823214]\n",
      " [0.04823214 0.45928053]]\n",
      "Odhadnut√© R:\n",
      " [[ 0.15269657 -0.02821938]\n",
      " [-0.02821938  0.09348884]]\n",
      "Matice Q a R v Kalmanovƒõ filtru byly aktualizov√°ny.\n",
      "Dokonƒçena trajektorie 6/10...\n",
      "Spou≈°t√≠m MDM odhad Q a R...\n",
      "MDM odhad dokonƒçen.\n",
      "Odhadnut√© Q:\n",
      " [[ 0.57458738 -0.06336661]\n",
      " [-0.06336661  0.48769912]]\n",
      "Odhadnut√© R:\n",
      " [[0.01831292 0.02104393]\n",
      " [0.02104393 0.13169989]]\n",
      "Matice Q a R v Kalmanovƒõ filtru byly aktualizov√°ny.\n",
      "Dokonƒçena trajektorie 7/10...\n",
      "Spou≈°t√≠m MDM odhad Q a R...\n",
      "MDM odhad dokonƒçen.\n",
      "Odhadnut√© Q:\n",
      " [[ 0.5399144  -0.00894131]\n",
      " [-0.00894131  0.51190462]]\n",
      "Odhadnut√© R:\n",
      " [[0.08257259 0.00214788]\n",
      " [0.00214788 0.10866791]]\n",
      "Matice Q a R v Kalmanovƒõ filtru byly aktualizov√°ny.\n",
      "Dokonƒçena trajektorie 8/10...\n",
      "Spou≈°t√≠m MDM odhad Q a R...\n",
      "MDM odhad dokonƒçen.\n",
      "Odhadnut√© Q:\n",
      " [[ 0.54318462 -0.00846377]\n",
      " [-0.00846377  0.5669835 ]]\n",
      "Odhadnut√© R:\n",
      " [[0.08396587 0.02589684]\n",
      " [0.02589684 0.05059833]]\n",
      "Matice Q a R v Kalmanovƒõ filtru byly aktualizov√°ny.\n",
      "Dokonƒçena trajektorie 9/10...\n",
      "Spou≈°t√≠m MDM odhad Q a R...\n",
      "MDM odhad dokonƒçen.\n",
      "Odhadnut√© Q:\n",
      " [[0.44054619 0.07188686]\n",
      " [0.07188686 0.48709669]]\n",
      "Odhadnut√© R:\n",
      " [[ 0.11799167 -0.03789257]\n",
      " [-0.03789257  0.13367418]]\n",
      "Matice Q a R v Kalmanovƒõ filtru byly aktualizov√°ny.\n",
      "Dokonƒçena trajektorie 10/10...\n",
      "\n",
      "Poƒç√≠t√°m fin√°ln√≠ metriky pro jednotliv√© trajektorie...\n",
      "\n",
      "================================================================================\n",
      "FIN√ÅLN√ç V√ùSLEDKY (pr≈Ømƒõr p≈ôes 10 bƒõh≈Ø)\n",
      "================================================================================\n",
      "Model                               | Pr≈Ømƒõrn√© MSE         | Pr≈Ømƒõrn√Ω ANEES      \n",
      "--------------------------------------------------------------------------------\n",
      "--- Data-Driven Models ---          | (ni≈æ≈°√≠ je lep≈°√≠)     | (bli≈æ≈°√≠ 2.0 je lep≈°√≠)\n",
      "Recursive KNet (RKN)                | 0.0842               | 1.8099              \n",
      "KNet (pouze MSE)                    | 0.0841               | N/A                 \n",
      "--------------------------------------------------------------------------------\n",
      "--- Model-Based Filters ---         |                      |                     \n",
      "EKF (Nep≈ôesn√Ω model)                | 0.1398               | 4.9880              \n",
      "UKF (Nep≈ôesn√Ω model)                | 0.1398               | 4.9880              \n",
      "AKF (Nep≈ôesn√Ω model)                | 0.0866               | 2.9005              \n",
      "--------------------------------------------------------------------------------\n",
      "--- Benchmarks ---                  |                      |                     \n",
      "EKF (Ide√°ln√≠ model)                 | 0.0839               | 1.9831              \n",
      "UKF (Ide√°ln√≠ model)                 | 0.0839               | 1.9831              \n",
      "KF (Ide√°ln√≠ model)                  | 0.0839               | 1.9831              \n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# ==============================================================================\n",
    "# 0. P≈òEDPOKLADY - ZDE P≈òI≈òAƒéTE VA≈†E NATR√âNOVAN√â MODELY\n",
    "# ==============================================================================\n",
    "# Ujistƒõte se, ≈æe v promƒõnn√Ωch n√≠≈æe m√°te ji≈æ natr√©novan√© a p≈ôipraven√© modely.\n",
    "try:\n",
    "    trained_model_rkn = trained_model  # Zmƒõnƒõno z BKN na RKN\n",
    "    trained_model_classic = state_knet\n",
    "    # trained_model_knetR = state_knetR\n",
    "    print(\"INFO: V≈°echny natr√©novan√© modely nalezeny a p≈ôi≈ôazeny.\")\n",
    "except NameError:\n",
    "    print(\"VAROV√ÅN√ç: Nƒõkter√© z promƒõnn√Ωch `trained_model`, `state_knet`, nebo `state_knetR` nebyly nalezeny.\")\n",
    "    print(\"         Ujistƒõte se, ≈æe jste nejprve √∫spƒõ≈°nƒõ dokonƒçili tr√©nink v≈°ech model≈Ø.\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. KONFIGURACE TESTU\n",
    "# ==============================================================================\n",
    "TEST_SEQ_LEN = 1000\n",
    "NUM_TEST_TRAJ = 10\n",
    "# J_SAMPLES_TEST = 25  <-- Odstranƒõno, RKN je deterministick√Ω a nevy≈æaduje vzorkov√°n√≠\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. P≈ò√çPRAVA DAT\n",
    "# ==============================================================================\n",
    "print(f\"\\nGeneruji {NUM_TEST_TRAJ} testovac√≠ch trajektori√≠ o d√©lce {TEST_SEQ_LEN}...\")\n",
    "x_test, y_test = utils.generate_data(sys_true, num_trajectories=NUM_TEST_TRAJ, seq_len=TEST_SEQ_LEN)\n",
    "test_dataset = TensorDataset(x_test, y_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "print(\"Generov√°n√≠ dat dokonƒçeno.\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. INICIALIZACE V≈†ECH FILTR≈Æ PRO POROVN√ÅN√ç\n",
    "# ==============================================================================\n",
    "ekf_mismatched = Filters.ExtendedKalmanFilter(sys_model)\n",
    "ekf_ideal = Filters.ExtendedKalmanFilter(sys_true)\n",
    "ukf_mismatched = Filters.UnscentedKalmanFilter(sys_model)\n",
    "ukf_ideal = Filters.UnscentedKalmanFilter(sys_true)\n",
    "akf_mismatched = Filters.AdaptiveKalmanFilter(sys_model,mdm_L=3,mdm_version=2)\n",
    "kf_ideal = Filters.KalmanFilter(sys_true)\n",
    "print(\"V≈°echny model-based filtry (EKF, UKF, AKF) inicializov√°ny.\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 4. VYHODNOCOVAC√ç SMYƒåKA\n",
    "# ==============================================================================\n",
    "# Seznamy pro ukl√°d√°n√≠ v√Ωsledk≈Ø z ka≈æd√© trajektorie\n",
    "all_x_true_cpu = []\n",
    "all_x_hat_rkn_cpu, all_P_hat_rkn_cpu = [], []  # P≈ôejmenov√°no na RKN\n",
    "all_x_hat_classic_knet_cpu = []\n",
    "# all_x_hat_knetR_cpu, all_P_hat_knetR_cpu = [], []\n",
    "all_x_hat_ekf_mismatched_cpu, all_P_hat_ekf_mismatched_cpu = [], []\n",
    "all_x_hat_ekf_ideal_cpu, all_P_hat_ekf_ideal_cpu = [], []\n",
    "all_x_hat_ukf_mismatched_cpu, all_P_hat_ukf_mismatched_cpu = [], []\n",
    "all_x_hat_ukf_ideal_cpu, all_P_hat_ukf_ideal_cpu = [], []\n",
    "all_x_hat_akf_mismatched_cpu, all_P_hat_akf_mismatched_cpu = [], []\n",
    "all_x_hat_kf_ideal_cpu, all_P_hat_kf_ideal_cpu = [], []\n",
    "\n",
    "print(f\"\\nVyhodnocuji modely na {NUM_TEST_TRAJ} testovac√≠ch trajektori√≠ch...\")\n",
    "\n",
    "trained_model_rkn.eval() \n",
    "trained_model_classic.eval()\n",
    "# trained_model_knetR.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (x_true_seq_batch, y_test_seq_batch) in enumerate(test_loader):\n",
    "        y_test_seq_gpu = y_test_seq_batch.squeeze(0).to(device)\n",
    "        x_true_seq_gpu = x_true_seq_batch.squeeze(0).to(device)\n",
    "        initial_state = x_true_seq_gpu[0, :].unsqueeze(0)\n",
    "        \n",
    "        # --- A. Recursive KalmanNet (RKN) ---\n",
    "        trained_model_rkn.reset(batch_size=1, initial_state=initial_state)\n",
    "        rkn_preds_x, rkn_preds_P = [], []\n",
    "        \n",
    "        for t in range(1, TEST_SEQ_LEN):\n",
    "            # Model RKN vrac√≠ (x_filtered, P_filtered, reg_loss)\n",
    "            step_output = trained_model_rkn.step(y_test_seq_gpu[t, :].unsqueeze(0))\n",
    "            x_filtered_t = step_output[0]\n",
    "            P_filtered_t = step_output[1]\n",
    "            \n",
    "            rkn_preds_x.append(x_filtered_t)\n",
    "            rkn_preds_P.append(P_filtered_t)\n",
    "            \n",
    "        full_x_hat_rkn = torch.cat([initial_state, torch.cat(rkn_preds_x, dim=0)], dim=0)\n",
    "        \n",
    "        # O≈°et≈ôen√≠ dimenz√≠ pro matici P z RKN\n",
    "        processed_P_rkn_list = []\n",
    "        for p_tensor in rkn_preds_P:\n",
    "            while p_tensor.dim() < 2:\n",
    "                p_tensor = p_tensor.unsqueeze(-1)\n",
    "            if p_tensor.dim() > 2 and p_tensor.shape[0] == 1:\n",
    "                p_tensor = p_tensor.squeeze(0)\n",
    "            processed_P_rkn_list.append(p_tensor)\n",
    "\n",
    "        P_sequence_rkn = torch.stack(processed_P_rkn_list, dim=0)\n",
    "        \n",
    "        P0_for_cat_rkn = sys_model.P0.clone()\n",
    "        while P0_for_cat_rkn.dim() < P_sequence_rkn.dim():\n",
    "            P0_for_cat_rkn = P0_for_cat_rkn.unsqueeze(0)\n",
    "            \n",
    "        full_P_hat_rkn = torch.cat([P0_for_cat_rkn, P_sequence_rkn], dim=0)\n",
    "\n",
    "        # --- B. Klasick√Ω StateKalmanNet (pouze MSE) ---\n",
    "        trained_model_classic.reset(batch_size=1, initial_state=initial_state)\n",
    "        classic_knet_preds = []\n",
    "        for t in range(1, TEST_SEQ_LEN):\n",
    "            x_filtered_t = trained_model_classic.step(y_test_seq_gpu[t, :].unsqueeze(0))\n",
    "            classic_knet_preds.append(x_filtered_t)\n",
    "        full_x_hat_classic_knet = torch.cat([initial_state, torch.cat(classic_knet_preds, dim=0)], dim=0)\n",
    "        \n",
    "        # # --- C. StateKalmanNetWithKnownR ---\n",
    "        # trained_model_knetR.reset(batch_size=1, initial_state=initial_state)\n",
    "        # knetR_preds_x, knetR_preds_P = [], []\n",
    "        # for t in range(1, TEST_SEQ_LEN):\n",
    "        #     x_filtered_t, P_filtered_t = trained_model_knetR.step(y_test_seq_gpu[t, :].unsqueeze(0))\n",
    "        #     knetR_preds_x.append(x_filtered_t)\n",
    "        #     knetR_preds_P.append(P_filtered_t)\n",
    "        # full_x_hat_knetR = torch.cat([initial_state, torch.cat(knetR_preds_x, dim=0)], dim=0)\n",
    "        # processed_P_list = []\n",
    "        # for p_tensor in knetR_preds_P:\n",
    "\n",
    "        #     while p_tensor.dim() < 2:\n",
    "        #         p_tensor = p_tensor.unsqueeze(-1)\n",
    "\n",
    "        #     if p_tensor.dim() > 2 and p_tensor.shape[0] == 1:\n",
    "        #         p_tensor = p_tensor.squeeze(0)\n",
    "        #     processed_P_list.append(p_tensor)\n",
    "\n",
    "        # P_sequence_knetR = torch.stack(processed_P_list, dim=0)\n",
    "        \n",
    "        # P0_for_cat = sys_model.P0.clone()\n",
    "        # while P0_for_cat.dim() < P_sequence_knetR.dim():\n",
    "        #     P0_for_cat = P0_for_cat.unsqueeze(0)\n",
    "            \n",
    "        # full_P_hat_knetR = torch.cat([P0_for_cat, P_sequence_knetR], dim=0)\n",
    "\n",
    "        # --- D. EKF (nep≈ôesn√Ω a ide√°ln√≠) ---\n",
    "        ekf_m_res = ekf_mismatched.process_sequence(y_test_seq_gpu, Ex0=sys_model.Ex0, P0=sys_model.P0)\n",
    "        full_x_hat_ekf_m = ekf_m_res['x_filtered']\n",
    "        full_P_hat_ekf_m = ekf_m_res['P_filtered'] \n",
    "\n",
    "        ekf_i_res = ekf_ideal.process_sequence(y_test_seq_gpu, Ex0=sys_true.Ex0, P0=sys_true.P0)\n",
    "        full_x_hat_ekf_i = ekf_i_res['x_filtered']\n",
    "        full_P_hat_ekf_i = ekf_i_res['P_filtered']\n",
    "\n",
    "        # --- E. UKF (nep≈ôesn√Ω a ide√°ln√≠) ---\n",
    "        ukf_m_res = ukf_mismatched.process_sequence(y_test_seq_gpu, Ex0=sys_model.Ex0, P0=sys_model.P0)\n",
    "        full_x_hat_ukf_m = ukf_m_res['x_filtered']\n",
    "        full_P_hat_ukf_m = ukf_m_res['P_filtered']\n",
    "\n",
    "        ukf_i_res = ukf_ideal.process_sequence(y_test_seq_gpu, Ex0=sys_true.Ex0, P0=sys_true.P0)\n",
    "        full_x_hat_ukf_i = ukf_i_res['x_filtered']\n",
    "        full_P_hat_ukf_i = ukf_i_res['P_filtered']\n",
    "\n",
    "        # --- F. Adaptivn√≠ EKF (nep≈ôesn√Ω) ---\n",
    "        akf_m_res,_,_ = akf_mismatched.process_sequence_adaptively(y_test_seq_gpu)\n",
    "        full_x_hat_akf_m = akf_m_res['x_filtered']\n",
    "        full_P_hat_akf_m = akf_m_res['P_filtered']\n",
    "\n",
    "        kf_i_res = kf_ideal.process_sequence(y_test_seq_gpu, Ex0=sys_true.Ex0, P0=sys_true.P0)\n",
    "        full_x_hat_kf_i = kf_i_res['x_filtered']\n",
    "        full_P_hat_kf_i = kf_i_res['P_filtered']\n",
    "\n",
    "        all_x_true_cpu.append(x_true_seq_gpu.cpu())\n",
    "        all_x_hat_rkn_cpu.append(full_x_hat_rkn.cpu()); all_P_hat_rkn_cpu.append(full_P_hat_rkn.cpu())\n",
    "        all_x_hat_classic_knet_cpu.append(full_x_hat_classic_knet.cpu())\n",
    "        # all_x_hat_knetR_cpu.append(full_x_hat_knetR.cpu()); all_P_hat_knetR_cpu.append(full_P_hat_knetR.cpu())\n",
    "        all_x_hat_ekf_mismatched_cpu.append(full_x_hat_ekf_m.cpu()); all_P_hat_ekf_mismatched_cpu.append(full_P_hat_ekf_m.cpu())\n",
    "        all_x_hat_ekf_ideal_cpu.append(full_x_hat_ekf_i.cpu()); all_P_hat_ekf_ideal_cpu.append(full_P_hat_ekf_i.cpu())\n",
    "        all_x_hat_ukf_mismatched_cpu.append(full_x_hat_ukf_m.cpu()); all_P_hat_ukf_mismatched_cpu.append(full_P_hat_ukf_m.cpu())\n",
    "        all_x_hat_ukf_ideal_cpu.append(full_x_hat_ukf_i.cpu()); all_P_hat_ukf_ideal_cpu.append(full_P_hat_ukf_i.cpu())\n",
    "        all_x_hat_akf_mismatched_cpu.append(full_x_hat_akf_m.cpu()); all_P_hat_akf_mismatched_cpu.append(full_P_hat_akf_m.cpu())\n",
    "        all_x_hat_kf_ideal_cpu.append(full_x_hat_kf_i.cpu()); all_P_hat_kf_ideal_cpu.append(full_P_hat_kf_i.cpu())\n",
    "\n",
    "        print(f\"Dokonƒçena trajektorie {i + 1}/{NUM_TEST_TRAJ}...\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 5. FIN√ÅLN√ç V√ùPOƒåET A V√ùPIS METRIK\n",
    "# ==============================================================================\n",
    "# Seznamy pro sbƒõr metrik\n",
    "mse_rkn, anees_rkn = [], []; mse_classic_knet = []; mse_knetR, anees_knetR = [], []\n",
    "mse_ekf_mis, anees_ekf_mis = [], []; mse_ekf_ideal, anees_ekf_ideal = [], []\n",
    "mse_ukf_mis, anees_ukf_mis = [], []; mse_ukf_ideal, anees_ukf_ideal = [], []\n",
    "mse_akf_mis, anees_akf_mis = [], []; mse_kf_ideal, anees_kf_ideal = [], []\n",
    "\n",
    "print(\"\\nPoƒç√≠t√°m fin√°ln√≠ metriky pro jednotliv√© trajektorie...\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(NUM_TEST_TRAJ):\n",
    "        x_true = all_x_true_cpu[i]\n",
    "        def get_metrics(x_hat, P_hat):\n",
    "            mse = F.mse_loss(x_hat[1:], x_true[1:]).item()\n",
    "            anees = utils.calculate_anees_vectorized(x_true.unsqueeze(0), x_hat.unsqueeze(0), P_hat.unsqueeze(0))\n",
    "            return mse, anees\n",
    "\n",
    "        # V√Ωpoƒçty pro v≈°echny modely\n",
    "        mse, anees = get_metrics(all_x_hat_rkn_cpu[i], all_P_hat_rkn_cpu[i]); mse_rkn.append(mse); anees_rkn.append(anees)\n",
    "        mse = F.mse_loss(all_x_hat_classic_knet_cpu[i][1:], x_true[1:]).item(); mse_classic_knet.append(mse)\n",
    "        # mse, anees = get_metrics(all_x_hat_knetR_cpu[i], all_P_hat_knetR_cpu[i]); mse_knetR.append(mse); anees_knetR.append(anees)\n",
    "        mse, anees = get_metrics(all_x_hat_ekf_mismatched_cpu[i], all_P_hat_ekf_mismatched_cpu[i]); mse_ekf_mis.append(mse); anees_ekf_mis.append(anees)\n",
    "        mse, anees = get_metrics(all_x_hat_ekf_ideal_cpu[i], all_P_hat_ekf_ideal_cpu[i]); mse_ekf_ideal.append(mse); anees_ekf_ideal.append(anees)\n",
    "        mse, anees = get_metrics(all_x_hat_ukf_mismatched_cpu[i], all_P_hat_ukf_mismatched_cpu[i]); mse_ukf_mis.append(mse); anees_ukf_mis.append(anees)\n",
    "        mse, anees = get_metrics(all_x_hat_ukf_ideal_cpu[i], all_P_hat_ukf_ideal_cpu[i]); mse_ukf_ideal.append(mse); anees_ukf_ideal.append(anees)\n",
    "        mse, anees = get_metrics(all_x_hat_akf_mismatched_cpu[i], all_P_hat_akf_mismatched_cpu[i]); mse_akf_mis.append(mse); anees_akf_mis.append(anees)\n",
    "        mse, anees = get_metrics(all_x_hat_kf_ideal_cpu[i], all_P_hat_kf_ideal_cpu[i]); mse_kf_ideal.append(mse); anees_kf_ideal.append(anees)\n",
    "\n",
    "# Funkce pro bezpeƒçn√© pr≈Ømƒõrov√°n√≠\n",
    "def avg(metric_list): return np.mean([m for m in metric_list if not np.isnan(m)])\n",
    "state_dim_for_nees = all_x_true_cpu[0].shape[1]\n",
    "\n",
    "# --- Fin√°ln√≠ v√Ωpis tabulky ---\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"FIN√ÅLN√ç V√ùSLEDKY (pr≈Ømƒõr p≈ôes {NUM_TEST_TRAJ} bƒõh≈Ø)\")\n",
    "print(\"=\"*80)\n",
    "print(f\"{'Model':<35} | {'Pr≈Ømƒõrn√© MSE':<20} | {'Pr≈Ømƒõrn√Ω ANEES':<20}\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"{'--- Data-Driven Models ---':<35} | {'(ni≈æ≈°√≠ je lep≈°√≠)':<20} | {'(bli≈æ≈°√≠ ' + str(float(state_dim_for_nees)) + ' je lep≈°√≠)':<20}\")\n",
    "print(f\"{'Recursive KNet (RKN)':<35} | {avg(mse_rkn):<20.4f} | {avg(anees_rkn):<20.4f}\")\n",
    "print(f\"{'KNet (pouze MSE)':<35} | {avg(mse_classic_knet):<20.4f} | {'N/A':<20}\")\n",
    "# print(f\"{'KNet with Known R (KNetR)':<35} | {avg(mse_knetR):<20.4f} | {avg(anees_knetR):<20.4f}\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"{'--- Model-Based Filters ---':<35} | {'':<20} | {'':<20}\")\n",
    "print(f\"{'EKF (Nep≈ôesn√Ω model)':<35} | {avg(mse_ekf_mis):<20.4f} | {avg(anees_ekf_mis):<20.4f}\")\n",
    "print(f\"{'UKF (Nep≈ôesn√Ω model)':<35} | {avg(mse_ukf_mis):<20.4f} | {avg(anees_ukf_mis):<20.4f}\")\n",
    "print(f\"{'AKF (Nep≈ôesn√Ω model)':<35} | {avg(mse_akf_mis):<20.4f} | {avg(anees_akf_mis):<20.4f}\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"{'--- Benchmarks ---':<35} | {'':<20} | {'':<20}\")\n",
    "print(f\"{'EKF (Ide√°ln√≠ model)':<35} | {avg(mse_ekf_ideal):<20.4f} | {avg(anees_ekf_ideal):<20.4f}\")\n",
    "print(f\"{'UKF (Ide√°ln√≠ model)':<35} | {avg(mse_ukf_ideal):<20.4f} | {avg(anees_ukf_ideal):<20.4f}\")\n",
    "print(f\"{'KF (Ide√°ln√≠ model)':<35} | {avg(mse_kf_ideal):<20.4f} | {avg(anees_kf_ideal):<20.4f}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b74eec",
   "metadata": {},
   "source": [
    "# Kalman Gain comparison"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
