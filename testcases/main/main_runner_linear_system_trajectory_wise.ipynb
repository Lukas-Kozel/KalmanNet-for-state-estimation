{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434435b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "notebook_path = os.getcwd() \n",
    "parent_dir = os.path.dirname(notebook_path)\n",
    "project_root = os.path.dirname(parent_dir)\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63665f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d034973",
   "metadata": {},
   "outputs": [],
   "source": [
    "import state_NN_models\n",
    "import Filters\n",
    "import utils\n",
    "import Systems\n",
    "from utils import losses, trainer, utils\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "from state_NN_models.StateBayesianKalmanNet import StateBayesianKalmanNet\n",
    "from state_NN_models.StateKalmanNet import StateKalmanNet\n",
    "from state_NN_models.StateKalmanNetWithKnownR import StateKalmanNetWithKnownR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61754ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Používané zařízení: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f446aa0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dim_2d = 2\n",
    "obs_dim_2d = 2\n",
    "\n",
    "F_base_2d = torch.tensor([[1.0, 1.0], \n",
    "                          [0.0, 1.0]])\n",
    "\n",
    "svd_F = torch.linalg.svd(F_base_2d)\n",
    "F_true_2d = F_base_2d / svd_F.S[0]\n",
    "\n",
    "H_true_2d = torch.eye(obs_dim_2d)\n",
    "\n",
    "Q_true_2d = torch.eye(state_dim_2d) * 0.5 # Šum procesu\n",
    "R_true_2d = torch.eye(obs_dim_2d) * 0.1 # Šum měření\n",
    "\n",
    "# Počáteční podmínky\n",
    "Ex0_true_2d = torch.tensor([[1.0], [0.0]])\n",
    "P0_true_2d = torch.eye(state_dim_2d) * 1.5\n",
    "F_model_2d = F_true_2d\n",
    "H_model_2d = H_true_2d\n",
    "Q_model_2d = torch.eye(state_dim_2d) * 0.1\n",
    "R_model_2d = R_true_2d\n",
    "Ex0_model_2d = torch.tensor([[0.5], [0.5]])\n",
    "P0_model_2d = torch.eye(state_dim_2d) * 1.0\n",
    "\n",
    "print(\"\\nInicializuji 2D Linear_Canonical systém (replikace autorů)...\")\n",
    "sys_true = Systems.DynamicSystem(\n",
    "    state_dim=state_dim_2d, obs_dim=obs_dim_2d,\n",
    "    Ex0=Ex0_true_2d, P0=P0_true_2d,\n",
    "    Q=Q_true_2d, R=R_true_2d,\n",
    "    F=F_true_2d, H=H_true_2d,\n",
    "    device=device\n",
    ")\n",
    "sys_model = Systems.DynamicSystem(\n",
    "    state_dim=state_dim_2d, obs_dim=obs_dim_2d,\n",
    "    Ex0=Ex0_model_2d, P0=P0_model_2d,\n",
    "    Q=Q_model_2d, R=R_model_2d,\n",
    "    F=F_model_2d, H=H_model_2d,\n",
    "    device=device\n",
    ")\n",
    "print(\"... 2D systém inicializován.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c41ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SEQ_LEN = 10      # Krátké sekvence pro stabilní trénink (TBPTT)\n",
    "VALID_SEQ_LEN = 20      # Stejná délka pro konzistentní validaci\n",
    "TEST_SEQ_LEN = 100      # Dlouhé sekvence pro testování generalizace\n",
    "\n",
    "NUM_TRAIN_TRAJ = 500   # Hodně trénovacích příkladů\n",
    "NUM_VALID_TRAJ = 200    # Dostatek pro spolehlivou validaci\n",
    "NUM_TEST_TRAJ = 100     # Pro robustní vyhodnocení\n",
    "\n",
    "BATCH_SIZE = 8         # Dobrý kompromis\n",
    "\n",
    "x_train, y_train = utils.generate_data(sys_true, num_trajectories=NUM_TRAIN_TRAJ, seq_len=TRAIN_SEQ_LEN)\n",
    "x_val, y_val = utils.generate_data(sys_true, num_trajectories=NUM_VALID_TRAJ, seq_len=VALID_SEQ_LEN)\n",
    "x_test, y_test = utils.generate_data(sys_true, num_trajectories=1, seq_len=TEST_SEQ_LEN)\n",
    "\n",
    "train_dataset = TensorDataset(x_train, y_train)\n",
    "val_dataset = TensorDataset(x_val, y_val)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad00e88f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Průměrný MSE: 0.2631, Průměrný ANEES: 18.0960\n",
      "  >>> Nové nejlepší VALIDAČNÍ ANEES! Ukládám model. <<<\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 54\u001b[0m\n\u001b[1;32m     46\u001b[0m state_bkn_knet \u001b[38;5;241m=\u001b[39m StateBayesianKalmanNet(\n\u001b[1;32m     47\u001b[0m     sys_model,\n\u001b[1;32m     48\u001b[0m     device\u001b[38;5;241m=\u001b[39mdevice,\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_config\n\u001b[1;32m     50\u001b[0m )\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# Spuštění tréninku\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# Používáme `run_training_session`, která vrací slovník s výsledky\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_session_trajectory_with_gaussian_nll_training_fcn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate_bkn_knet\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtrain_config\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# `run_training_session` automaticky načte nejlepší model zpět,\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# takže `state_bkn_knet` nyní obsahuje váhy nejlepšího modelu.\u001b[39;00m\n\u001b[1;32m     63\u001b[0m trained_model \u001b[38;5;241m=\u001b[39m results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinal_model\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/skola/KalmanNet-for-state-estimation/utils/trainer.py:495\u001b[0m, in \u001b[0;36mtraining_session_trajectory_with_gaussian_nll_training_fcn\u001b[0;34m(model, train_loader, val_loader, device, total_train_iter, learning_rate, clip_grad, J_samples, validation_period, logging_period, warmup_iterations)\u001b[0m\n\u001b[1;32m    491\u001b[0m     loss \u001b[38;5;241m=\u001b[39m nll_loss \u001b[38;5;241m+\u001b[39m regularization_loss\n\u001b[1;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misnan(loss): \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m!!! Kolaps !!!\u001b[39m\u001b[38;5;124m\"\u001b[39m); done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m; \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 495\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m clip_grad \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m: torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), clip_grad)\n\u001b[1;32m    497\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "\n",
    "model_config = {\n",
    "    \"hidden_size_multiplier\": 10,\n",
    "    \"output_layer_multiplier\": 4,\n",
    "    \"num_gru_layers\": 1,\n",
    "    \"init_min_dropout\": 0.5,\n",
    "    \"init_max_dropout\": 0.8\n",
    "}\n",
    "\n",
    "train_config = {\n",
    "    \"total_train_iter\": 1200,\n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"clip_grad\": 10.0,\n",
    "    \"J_samples\": 20,\n",
    "    \"validation_period\": 20,\n",
    "    \"logging_period\": 20,\n",
    "    \"warmup_iterations\":100 # Trénuj prvních 400 iterací jen na MSE\n",
    "}\n",
    "\n",
    "# =================================================================================\n",
    "# KROK 3: SPUŠTĚNÍ JEDNOHO TRÉNINKOVÉHO BĚHU\n",
    "# =================================================================================\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"Spouštím jeden plnohodnotný tréninkový běh...\")\n",
    "print(f\"Parametry modelu: {model_config}\")\n",
    "print(f\"Parametry tréninku: {train_config}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Nastavení seedu pro reprodukovatelnost tohoto běhu\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Vytvoření modelu\n",
    "state_bkn_knet = StateBayesianKalmanNet(\n",
    "    sys_model,\n",
    "    device=device,\n",
    "    **model_config\n",
    ").to(device)\n",
    "\n",
    "# Spuštění tréninku\n",
    "# Používáme `run_training_session`, která vrací slovník s výsledky\n",
    "results = trainer.training_session_trajectory_with_gaussian_nll_training_fcn(model=state_bkn_knet,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    device=device,\n",
    "    **train_config\n",
    ")\n",
    "\n",
    "# `run_training_session` automaticky načte nejlepší model zpět,\n",
    "# takže `state_bkn_knet` nyní obsahuje váhy nejlepšího modelu.\n",
    "trained_model = results['final_model']\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRÉNINK DOKONČEN - FINÁLNÍ VÝSLEDKY Z NEJLEPŠÍHO MODELU\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Nejlepší model byl nalezen v iteraci: {results['best_iter']}\")\n",
    "# --- Změněné klíče, aby odpovídaly return statementu ---\n",
    "print(f\"Nejlepší dosažený validační ANEES: {results['best_val_anees']:.4f}\")\n",
    "print(\"--- Metriky odpovídající tomuto nejlepšímu modelu ---\")\n",
    "print(f\"  MSE na validační sadě:       {results['best_val_mse']:.4f}\")\n",
    "print(f\"  NLL na validační sadě:       {results['best_val_nll']:.4f}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Nyní můžeš s `trained_model` pokračovat, například ho vyhodnotit na testovací sadě."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b62217b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "# Nastavení seedu pro reprodukovatelnost tohoto běhu\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "state_knet = StateKalmanNet(sys_model, device=device, hidden_size_multiplier=12).to(device)\n",
    "trainer.train_state_KalmanNet(\n",
    "    model=state_knet, \n",
    "    train_loader=train_loader, \n",
    "    val_loader=val_loader, \n",
    "    device=device, \n",
    "    epochs=100, \n",
    "    lr=1e-4,\n",
    "    early_stopping_patience=30\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f78c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "# Nastavení seedu pro reprodukovatelnost tohoto běhu\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "state_knetR = StateKalmanNetWithKnownR(sys_model, device=device, hidden_size_multiplier=12).to(device)\n",
    "trainer.train_state_KalmanNet(\n",
    "    model=state_knetR, \n",
    "    train_loader=train_loader, \n",
    "    val_loader=val_loader, \n",
    "    device=device, \n",
    "    epochs=100, \n",
    "    lr=1e-4,\n",
    "    early_stopping_patience=30\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453b1b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# ==============================================================================\n",
    "# 0. PŘEDPOKLADY - ZDE PŘIŘAĎTE VAŠE NATRÉNOVANÉ MODELY\n",
    "# ==============================================================================\n",
    "# Ujistěte se, že v proměnných níže máte již natrénované a připravené modely.\n",
    "# Názvy proměnných si upravte podle vašeho kódu, pokud se liší.\n",
    "try:\n",
    "    trained_model_bkn = trained_model\n",
    "    trained_model_classic = state_knet\n",
    "    trained_model_knetR = state_knetR\n",
    "    print(\"INFO: Všechny natrénované modely nalezeny a přiřazeny.\")\n",
    "except NameError:\n",
    "    print(\"VAROVÁNÍ: Některé z proměnných `trained_model`, `state_knet`, nebo `state_knetR` nebyly nalezeny.\")\n",
    "    print(\"         Ujistěte se, že jste nejprve úspěšně dokončili trénink všech modelů.\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. KONFIGURACE TESTU\n",
    "# ==============================================================================\n",
    "TEST_SEQ_LEN = 500\n",
    "NUM_TEST_TRAJ = 20\n",
    "J_SAMPLES_TEST = 25\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. PŘÍPRAVA DAT\n",
    "# ==============================================================================\n",
    "print(f\"\\nGeneruji {NUM_TEST_TRAJ} testovacích trajektorií o délce {TEST_SEQ_LEN}...\")\n",
    "x_test, y_test = utils.generate_data(sys_true, num_trajectories=NUM_TEST_TRAJ, seq_len=TEST_SEQ_LEN)\n",
    "test_dataset = TensorDataset(x_test, y_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "print(\"Generování dat dokončeno.\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. INICIALIZACE VŠECH FILTRŮ PRO POROVNÁNÍ\n",
    "# ==============================================================================\n",
    "ekf_mismatched = Filters.ExtendedKalmanFilter(sys_model)\n",
    "ekf_ideal = Filters.ExtendedKalmanFilter(sys_true)\n",
    "ukf_mismatched = Filters.UnscentedKalmanFilter(sys_model)\n",
    "ukf_ideal = Filters.UnscentedKalmanFilter(sys_true)\n",
    "akf_mismatched = Filters.AdaptiveKalmanFilter(sys_model,mdm_L=4,mdm_version=2)\n",
    "kf_ideal = Filters.KalmanFilter(sys_true)\n",
    "print(\"Všechny model-based filtry (EKF, UKF, AKF) inicializovány.\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 4. VYHODNOCOVACÍ SMYČKA\n",
    "# ==============================================================================\n",
    "# Seznamy pro ukládání výsledků z každé trajektorie\n",
    "all_x_true_cpu = []\n",
    "all_x_hat_bkn_cpu, all_P_hat_bkn_cpu = [], []\n",
    "all_x_hat_classic_knet_cpu = []\n",
    "all_x_hat_knetR_cpu, all_P_hat_knetR_cpu = [], []\n",
    "all_x_hat_ekf_mismatched_cpu, all_P_hat_ekf_mismatched_cpu = [], []\n",
    "all_x_hat_ekf_ideal_cpu, all_P_hat_ekf_ideal_cpu = [], []\n",
    "all_x_hat_ukf_mismatched_cpu, all_P_hat_ukf_mismatched_cpu = [], []\n",
    "all_x_hat_ukf_ideal_cpu, all_P_hat_ukf_ideal_cpu = [], []\n",
    "all_x_hat_akf_mismatched_cpu, all_P_hat_akf_mismatched_cpu = [], []\n",
    "all_x_hat_kf_ideal_cpu, all_P_hat_kf_ideal_cpu = [], []\n",
    "\n",
    "print(f\"\\nVyhodnocuji modely na {NUM_TEST_TRAJ} testovacích trajektoriích...\")\n",
    "\n",
    "trained_model_bkn.eval() \n",
    "trained_model_classic.eval()\n",
    "trained_model_knetR.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (x_true_seq_batch, y_test_seq_batch) in enumerate(test_loader):\n",
    "        y_test_seq_gpu = y_test_seq_batch.squeeze(0).to(device)\n",
    "        x_true_seq_gpu = x_true_seq_batch.squeeze(0).to(device)\n",
    "        initial_state = x_true_seq_gpu[0, :].unsqueeze(0)\n",
    "        \n",
    "        # --- A. Bayesian KalmanNet (Trajectory-wise) ---\n",
    "        ensemble_trajectories = []\n",
    "        for j in range(J_SAMPLES_TEST):\n",
    "            trained_model_bkn.reset(batch_size=1, initial_state=initial_state)\n",
    "            current_x_hats = []\n",
    "            for t in range(1, TEST_SEQ_LEN):\n",
    "                x_filtered_t, _ = trained_model_bkn.step(y_test_seq_gpu[t, :].unsqueeze(0))\n",
    "                current_x_hats.append(x_filtered_t)\n",
    "            ensemble_trajectories.append(torch.cat(current_x_hats, dim=0))\n",
    "        ensemble = torch.stack(ensemble_trajectories, dim=0)\n",
    "        predictions_bkn = ensemble.mean(dim=0)\n",
    "        diff = ensemble - predictions_bkn.unsqueeze(0)\n",
    "        covariances_bkn = (diff.unsqueeze(-1) @ diff.unsqueeze(-2)).mean(dim=0)\n",
    "        full_x_hat_bkn = torch.cat([initial_state, predictions_bkn], dim=0)\n",
    "        full_P_hat_bkn = torch.cat([sys_model.P0.unsqueeze(0), covariances_bkn], dim=0)\n",
    "\n",
    "        # --- B. Klasický StateKalmanNet (pouze MSE) ---\n",
    "        trained_model_classic.reset(batch_size=1, initial_state=initial_state)\n",
    "        classic_knet_preds = []\n",
    "        for t in range(1, TEST_SEQ_LEN):\n",
    "            x_filtered_t = trained_model_classic.step(y_test_seq_gpu[t, :].unsqueeze(0))\n",
    "            classic_knet_preds.append(x_filtered_t)\n",
    "        full_x_hat_classic_knet = torch.cat([initial_state, torch.cat(classic_knet_preds, dim=0)], dim=0)\n",
    "        \n",
    "        # --- C. StateKalmanNetWithKnownR ---\n",
    "        trained_model_knetR.reset(batch_size=1, initial_state=initial_state)\n",
    "        knetR_preds_x, knetR_preds_P = [], []\n",
    "        for t in range(1, TEST_SEQ_LEN):\n",
    "            x_filtered_t, P_filtered_t = trained_model_knetR.step(y_test_seq_gpu[t, :].unsqueeze(0))\n",
    "            knetR_preds_x.append(x_filtered_t)\n",
    "            knetR_preds_P.append(P_filtered_t)\n",
    "        full_x_hat_knetR = torch.cat([initial_state, torch.cat(knetR_preds_x, dim=0)], dim=0)\n",
    "        processed_P_list = []\n",
    "        for p_tensor in knetR_preds_P:\n",
    "\n",
    "            while p_tensor.dim() < 2:\n",
    "                p_tensor = p_tensor.unsqueeze(-1)\n",
    "\n",
    "            if p_tensor.dim() > 2 and p_tensor.shape[0] == 1:\n",
    "                p_tensor = p_tensor.squeeze(0)\n",
    "            processed_P_list.append(p_tensor)\n",
    "\n",
    "\n",
    "        P_sequence_knetR = torch.stack(processed_P_list, dim=0)\n",
    "        \n",
    "\n",
    "        P0_for_cat = sys_model.P0.clone()\n",
    "        while P0_for_cat.dim() < P_sequence_knetR.dim():\n",
    "            P0_for_cat = P0_for_cat.unsqueeze(0)\n",
    "            \n",
    "        full_P_hat_knetR = torch.cat([P0_for_cat, P_sequence_knetR], dim=0)\n",
    "\n",
    "        # --- D. EKF (nepřesný a ideální) ---\n",
    "        ekf_m_res = ekf_mismatched.process_sequence(y_test_seq_gpu, Ex0=sys_model.Ex0, P0=sys_model.P0)\n",
    "\n",
    "        full_x_hat_ekf_m = ekf_m_res['x_filtered'] # Výsledek je již kompletní trajektorie\n",
    "        full_P_hat_ekf_m = ekf_m_res['P_filtered'] # To samé pro kovarianci\n",
    "\n",
    "        ekf_i_res = ekf_ideal.process_sequence(y_test_seq_gpu, Ex0=sys_true.Ex0, P0=sys_true.P0)\n",
    "\n",
    "        full_x_hat_ekf_i = ekf_i_res['x_filtered']\n",
    "        full_P_hat_ekf_i = ekf_i_res['P_filtered']\n",
    "\n",
    "        # --- E. UKF (nepřesný a ideální) ---\n",
    "        ukf_m_res = ukf_mismatched.process_sequence(y_test_seq_gpu, Ex0=sys_model.Ex0, P0=sys_model.P0)\n",
    "\n",
    "        full_x_hat_ukf_m = ukf_m_res['x_filtered']\n",
    "        full_P_hat_ukf_m = ukf_m_res['P_filtered']\n",
    "\n",
    "        ukf_i_res = ukf_ideal.process_sequence(y_test_seq_gpu, Ex0=sys_true.Ex0, P0=sys_true.P0)\n",
    "\n",
    "        full_x_hat_ukf_i = ukf_i_res['x_filtered']\n",
    "        full_P_hat_ukf_i = ukf_i_res['P_filtered']\n",
    "\n",
    "        # --- F. Adaptivní EKF (nepřesný) ---\n",
    "        akf_m_res,_,_ = akf_mismatched.process_sequence_adaptively(y_test_seq_gpu)\n",
    "        full_x_hat_akf_m = akf_m_res['x_filtered']\n",
    "        full_P_hat_akf_m = akf_m_res['P_filtered']\n",
    "\n",
    "        kf_i_res = kf_ideal.process_sequence(y_test_seq_gpu, Ex0=sys_true.Ex0, P0=sys_true.P0)\n",
    "\n",
    "        full_x_hat_kf_i = kf_i_res['x_filtered']\n",
    "        full_P_hat_kf_i = kf_i_res['P_filtered']\n",
    "\n",
    "        all_x_true_cpu.append(x_true_seq_gpu.cpu())\n",
    "        all_x_hat_bkn_cpu.append(full_x_hat_bkn.cpu()); all_P_hat_bkn_cpu.append(full_P_hat_bkn.cpu())\n",
    "        all_x_hat_classic_knet_cpu.append(full_x_hat_classic_knet.cpu())\n",
    "        all_x_hat_knetR_cpu.append(full_x_hat_knetR.cpu()); all_P_hat_knetR_cpu.append(full_P_hat_knetR.cpu())\n",
    "        all_x_hat_ekf_mismatched_cpu.append(full_x_hat_ekf_m.cpu()); all_P_hat_ekf_mismatched_cpu.append(full_P_hat_ekf_m.cpu())\n",
    "        all_x_hat_ekf_ideal_cpu.append(full_x_hat_ekf_i.cpu()); all_P_hat_ekf_ideal_cpu.append(full_P_hat_ekf_i.cpu())\n",
    "        all_x_hat_ukf_mismatched_cpu.append(full_x_hat_ukf_m.cpu()); all_P_hat_ukf_mismatched_cpu.append(full_P_hat_ukf_m.cpu())\n",
    "        all_x_hat_ukf_ideal_cpu.append(full_x_hat_ukf_i.cpu()); all_P_hat_ukf_ideal_cpu.append(full_P_hat_ukf_i.cpu())\n",
    "        all_x_hat_akf_mismatched_cpu.append(full_x_hat_akf_m.cpu()); all_P_hat_akf_mismatched_cpu.append(full_P_hat_akf_m.cpu())\n",
    "        all_x_hat_kf_ideal_cpu.append(full_x_hat_kf_i.cpu()); all_P_hat_kf_ideal_cpu.append(full_P_hat_kf_i.cpu())\n",
    "\n",
    "        print(f\"Dokončena trajektorie {i + 1}/{NUM_TEST_TRAJ}...\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 5. FINÁLNÍ VÝPOČET A VÝPIS METRIK\n",
    "# ==============================================================================\n",
    "# Seznamy pro sběr metrik\n",
    "mse_bkn, anees_bkn = [], []; mse_classic_knet = []; mse_knetR, anees_knetR = [], []\n",
    "mse_ekf_mis, anees_ekf_mis = [], []; mse_ekf_ideal, anees_ekf_ideal = [], []\n",
    "mse_ukf_mis, anees_ukf_mis = [], []; mse_ukf_ideal, anees_ukf_ideal = [], []\n",
    "mse_akf_mis, anees_akf_mis = [], []; mse_kf_ideal, anees_kf_ideal = [], []\n",
    "\n",
    "print(\"\\nPočítám finální metriky pro jednotlivé trajektorie...\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(NUM_TEST_TRAJ):\n",
    "        x_true = all_x_true_cpu[i]\n",
    "        def get_metrics(x_hat, P_hat):\n",
    "            mse = F.mse_loss(x_hat[1:], x_true[1:]).item()\n",
    "            anees = utils.calculate_anees_vectorized(x_true.unsqueeze(0), x_hat.unsqueeze(0), P_hat.unsqueeze(0))\n",
    "            return mse, anees\n",
    "\n",
    "        # Výpočty pro všechny modely\n",
    "        mse, anees = get_metrics(all_x_hat_bkn_cpu[i], all_P_hat_bkn_cpu[i]); mse_bkn.append(mse); anees_bkn.append(anees)\n",
    "        mse = F.mse_loss(all_x_hat_classic_knet_cpu[i][1:], x_true[1:]).item(); mse_classic_knet.append(mse)\n",
    "        mse, anees = get_metrics(all_x_hat_knetR_cpu[i], all_P_hat_knetR_cpu[i]); mse_knetR.append(mse); anees_knetR.append(anees)\n",
    "        mse, anees = get_metrics(all_x_hat_ekf_mismatched_cpu[i], all_P_hat_ekf_mismatched_cpu[i]); mse_ekf_mis.append(mse); anees_ekf_mis.append(anees)\n",
    "        mse, anees = get_metrics(all_x_hat_ekf_ideal_cpu[i], all_P_hat_ekf_ideal_cpu[i]); mse_ekf_ideal.append(mse); anees_ekf_ideal.append(anees)\n",
    "        mse, anees = get_metrics(all_x_hat_ukf_mismatched_cpu[i], all_P_hat_ukf_mismatched_cpu[i]); mse_ukf_mis.append(mse); anees_ukf_mis.append(anees)\n",
    "        mse, anees = get_metrics(all_x_hat_ukf_ideal_cpu[i], all_P_hat_ukf_ideal_cpu[i]); mse_ukf_ideal.append(mse); anees_ukf_ideal.append(anees)\n",
    "        mse, anees = get_metrics(all_x_hat_akf_mismatched_cpu[i], all_P_hat_akf_mismatched_cpu[i]); mse_akf_mis.append(mse); anees_akf_mis.append(anees)\n",
    "        mse, anees = get_metrics(all_x_hat_kf_ideal_cpu[i], all_P_hat_kf_ideal_cpu[i]); mse_kf_ideal.append(mse); anees_kf_ideal.append(anees)\n",
    "# Funkce pro bezpečné průměrování\n",
    "def avg(metric_list): return np.mean([m for m in metric_list if not np.isnan(m)])\n",
    "state_dim_for_nees = all_x_true_cpu[0].shape[1]\n",
    "\n",
    "# --- Finální výpis tabulky ---\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"FINÁLNÍ VÝSLEDKY (průměr přes {NUM_TEST_TRAJ} běhů)\")\n",
    "print(\"=\"*80)\n",
    "print(f\"{'Model':<35} | {'Průměrné MSE':<20} | {'Průměrný ANEES':<20}\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"{'--- Data-Driven Models ---':<35} | {'(nižší je lepší)':<20} | {'(bližší ' + str(float(state_dim_for_nees)) + ' je lepší)':<20}\")\n",
    "print(f\"{'Bayesian KNet (BKN)':<35} | {avg(mse_bkn):<20.4f} | {avg(anees_bkn):<20.4f}\")\n",
    "print(f\"{'KNet (pouze MSE)':<35} | {avg(mse_classic_knet):<20.4f} | {'N/A':<20}\")\n",
    "print(f\"{'KNet with Known R (KNetR)':<35} | {avg(mse_knetR):<20.4f} | {avg(anees_knetR):<20.4f}\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"{'--- Model-Based Filters ---':<35} | {'':<20} | {'':<20}\")\n",
    "print(f\"{'EKF (Nepřesný model)':<35} | {avg(mse_ekf_mis):<20.4f} | {avg(anees_ekf_mis):<20.4f}\")\n",
    "print(f\"{'UKF (Nepřesný model)':<35} | {avg(mse_ukf_mis):<20.4f} | {avg(anees_ukf_mis):<20.4f}\")\n",
    "print(f\"{'AKF (Nepřesný model)':<35} | {avg(mse_akf_mis):<20.4f} | {avg(anees_akf_mis):<20.4f}\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"{'--- Benchmarks ---':<35} | {'':<20} | {'':<20}\")\n",
    "print(f\"{'EKF (Ideální model)':<35} | {avg(mse_ekf_ideal):<20.4f} | {avg(anees_ekf_ideal):<20.4f}\")\n",
    "print(f\"{'UKF (Ideální model)':<35} | {avg(mse_ukf_ideal):<20.4f} | {avg(anees_ukf_ideal):<20.4f}\")\n",
    "print(f\"{'KF (Ideální model)':<35} | {avg(mse_kf_ideal):<20.4f} | {avg(anees_kf_ideal):<20.4f}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b74eec",
   "metadata": {},
   "source": [
    "# Kalman Gain comparison"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
