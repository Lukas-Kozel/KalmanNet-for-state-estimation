{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "434435b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "notebook_path = os.getcwd() \n",
    "parent_dir = os.path.dirname(notebook_path)\n",
    "project_root = os.path.dirname(parent_dir)\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63665f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d034973",
   "metadata": {},
   "outputs": [],
   "source": [
    "import state_NN_models\n",
    "import Filters\n",
    "import utils\n",
    "import Systems\n",
    "from utils import losses, trainer, utils\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "from state_NN_models.StateBayesianKalmanNet import StateBayesianKalmanNet\n",
    "from state_NN_models.StateKalmanNet import StateKalmanNet\n",
    "from state_NN_models.StateKalmanNetWithKnownR import StateKalmanNetWithKnownR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e61754ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Používané zařízení: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Používané zařízení: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f446aa0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6180, 0.6180],\n",
      "        [0.0000, 0.6180]])\n",
      "\n",
      "Inicializuji 2D Linear_Canonical systém (replikace autorů)...\n",
      "... 2D systém inicializován.\n"
     ]
    }
   ],
   "source": [
    "state_dim_2d = 2\n",
    "obs_dim_2d = 2\n",
    "\n",
    "F_base_2d = torch.tensor([[1.0, 1.0], \n",
    "                          [0.0, 1.0]])\n",
    "\n",
    "svd_F = torch.linalg.svd(F_base_2d)\n",
    "F_true_2d = F_base_2d / svd_F.S[0]\n",
    "print(F_true_2d)\n",
    "\n",
    "H_true_2d = torch.eye(obs_dim_2d)\n",
    "\n",
    "Q_true_2d = torch.eye(state_dim_2d) * 0.5 # Šum procesu\n",
    "R_true_2d = torch.eye(obs_dim_2d) * 0.1 # Šum měření\n",
    "\n",
    "# Počáteční podmínky\n",
    "Ex0_true_2d = torch.tensor([[1.0], [0.0]])\n",
    "P0_true_2d = torch.eye(state_dim_2d) * 1.5\n",
    "F_model_2d = F_true_2d\n",
    "H_model_2d = H_true_2d\n",
    "Q_model_2d = torch.eye(state_dim_2d) * 0.1\n",
    "R_model_2d = R_true_2d\n",
    "Ex0_model_2d = torch.tensor([[0.5], [0.5]])\n",
    "P0_model_2d = torch.eye(state_dim_2d) * 1.0\n",
    "\n",
    "print(\"\\nInicializuji 2D Linear_Canonical systém (replikace autorů)...\")\n",
    "sys_true = Systems.DynamicSystem(\n",
    "    state_dim=state_dim_2d, obs_dim=obs_dim_2d,\n",
    "    Ex0=Ex0_true_2d, P0=P0_true_2d,\n",
    "    Q=Q_true_2d, R=R_true_2d,\n",
    "    F=F_true_2d, H=H_true_2d,\n",
    "    device=device\n",
    ")\n",
    "sys_model = Systems.DynamicSystem(\n",
    "    state_dim=state_dim_2d, obs_dim=obs_dim_2d,\n",
    "    Ex0=Ex0_model_2d, P0=P0_model_2d,\n",
    "    Q=Q_model_2d, R=R_model_2d,\n",
    "    F=F_model_2d, H=H_model_2d,\n",
    "    device=device\n",
    ")\n",
    "print(\"... 2D systém inicializován.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9c41ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SEQ_LEN = 10      # Krátké sekvence pro stabilní trénink (TBPTT)\n",
    "VALID_SEQ_LEN = 20      # Stejná délka pro konzistentní validaci\n",
    "TEST_SEQ_LEN = 100      # Dlouhé sekvence pro testování generalizace\n",
    "\n",
    "NUM_TRAIN_TRAJ = 500   # Hodně trénovacích příkladů\n",
    "NUM_VALID_TRAJ = 200    # Dostatek pro spolehlivou validaci\n",
    "NUM_TEST_TRAJ = 100     # Pro robustní vyhodnocení\n",
    "\n",
    "BATCH_SIZE = 8         # Dobrý kompromis\n",
    "\n",
    "x_train, y_train = utils.generate_data(sys_true, num_trajectories=NUM_TRAIN_TRAJ, seq_len=TRAIN_SEQ_LEN)\n",
    "x_val, y_val = utils.generate_data(sys_true, num_trajectories=NUM_VALID_TRAJ, seq_len=VALID_SEQ_LEN)\n",
    "x_test, y_test = utils.generate_data(sys_true, num_trajectories=1, seq_len=TEST_SEQ_LEN)\n",
    "\n",
    "train_dataset = TensorDataset(x_train, y_train)\n",
    "val_dataset = TensorDataset(x_val, y_val)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad00e88f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Spouštím jeden plnohodnotný tréninkový běh...\n",
      "Parametry modelu: {'hidden_size_multiplier': 10, 'output_layer_multiplier': 4, 'num_gru_layers': 1, 'init_min_dropout': 0.5, 'init_max_dropout': 0.8}\n",
      "Parametry tréninku: {'total_train_iter': 2000, 'learning_rate': 0.0001, 'clip_grad': 10.0, 'J_samples': 10, 'validation_period': 10, 'logging_period': 20, 'warmup_iterations': 100}\n",
      "================================================================================\n",
      "loaded with input normalization\n",
      "\n",
      "--- Validation at iteration 10 ---\n",
      "  Average MSE: 0.4554, Average ANEES: 31.3557\n",
      "  >>> New best VALIDATION ANEES! Saving model. <<<\n",
      "--------------------------------------------------\n",
      "--- Iteration [20/2000] ---\n",
      "    - Total Loss: 0.3093\n",
      "    - NLL: 0.0000\n",
      "    - Reg: 0.0026\n",
      "    - p1=0.602, p2=0.654\n",
      "\n",
      "--- Validation at iteration 20 ---\n",
      "  Average MSE: 0.3812, Average ANEES: 27.6187\n",
      "  >>> New best VALIDATION ANEES! Saving model. <<<\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 30 ---\n",
      "  Average MSE: 0.3180, Average ANEES: 26.4406\n",
      "  >>> New best VALIDATION ANEES! Saving model. <<<\n",
      "--------------------------------------------------\n",
      "--- Iteration [40/2000] ---\n",
      "    - Total Loss: 0.2960\n",
      "    - NLL: 0.0000\n",
      "    - Reg: 0.0026\n",
      "    - p1=0.602, p2=0.654\n",
      "\n",
      "--- Validation at iteration 40 ---\n",
      "  Average MSE: 0.2713, Average ANEES: 24.3746\n",
      "  >>> New best VALIDATION ANEES! Saving model. <<<\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 50 ---\n",
      "  Average MSE: 0.2349, Average ANEES: 21.2609\n",
      "  >>> New best VALIDATION ANEES! Saving model. <<<\n",
      "--------------------------------------------------\n",
      "--- Iteration [60/2000] ---\n",
      "    - Total Loss: 0.1927\n",
      "    - NLL: 0.0000\n",
      "    - Reg: 0.0026\n",
      "    - p1=0.602, p2=0.654\n",
      "\n",
      "--- Validation at iteration 60 ---\n",
      "  Average MSE: 0.2029, Average ANEES: 19.4995\n",
      "  >>> New best VALIDATION ANEES! Saving model. <<<\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 70 ---\n",
      "  Average MSE: 0.1814, Average ANEES: 18.1253\n",
      "  >>> New best VALIDATION ANEES! Saving model. <<<\n",
      "--------------------------------------------------\n",
      "--- Iteration [80/2000] ---\n",
      "    - Total Loss: 0.1461\n",
      "    - NLL: 0.0000\n",
      "    - Reg: 0.0026\n",
      "    - p1=0.602, p2=0.653\n",
      "\n",
      "--- Validation at iteration 80 ---\n",
      "  Average MSE: 0.1622, Average ANEES: 17.2451\n",
      "  >>> New best VALIDATION ANEES! Saving model. <<<\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 90 ---\n",
      "  Average MSE: 0.1489, Average ANEES: 15.9278\n",
      "  >>> New best VALIDATION ANEES! Saving model. <<<\n",
      "--------------------------------------------------\n",
      "--- Iteration [100/2000] ---\n",
      "    - Total Loss: 0.1275\n",
      "    - NLL: 0.0000\n",
      "    - Reg: 0.0026\n",
      "    - p1=0.602, p2=0.653\n",
      "\n",
      "--- Validation at iteration 100 ---\n",
      "  Average MSE: 0.1389, Average ANEES: 15.3794\n",
      "  >>> New best VALIDATION ANEES! Saving model. <<<\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 110 ---\n",
      "  Average MSE: 0.1254, Average ANEES: 13.1991\n",
      "  >>> New best VALIDATION ANEES! Saving model. <<<\n",
      "--------------------------------------------------\n",
      "--- Iteration [120/2000] ---\n",
      "    - Total Loss: 3.2924\n",
      "    - NLL: 3.2898\n",
      "    - Reg: 0.0026\n",
      "    - p1=0.602, p2=0.654\n",
      "\n",
      "--- Validation at iteration 120 ---\n",
      "  Average MSE: 0.1168, Average ANEES: 11.6658\n",
      "  >>> New best VALIDATION ANEES! Saving model. <<<\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 130 ---\n",
      "  Average MSE: 0.1116, Average ANEES: 11.4134\n",
      "  >>> New best VALIDATION ANEES! Saving model. <<<\n",
      "--------------------------------------------------\n",
      "--- Iteration [140/2000] ---\n",
      "    - Total Loss: 1.9377\n",
      "    - NLL: 1.9351\n",
      "    - Reg: 0.0026\n",
      "    - p1=0.602, p2=0.654\n",
      "\n",
      "--- Validation at iteration 140 ---\n",
      "  Average MSE: 0.1091, Average ANEES: 9.6451\n",
      "  >>> New best VALIDATION ANEES! Saving model. <<<\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 150 ---\n",
      "  Average MSE: 0.1049, Average ANEES: 8.7528\n",
      "  >>> New best VALIDATION ANEES! Saving model. <<<\n",
      "--------------------------------------------------\n",
      "--- Iteration [160/2000] ---\n",
      "    - Total Loss: 1.0548\n",
      "    - NLL: 1.0521\n",
      "    - Reg: 0.0026\n",
      "    - p1=0.601, p2=0.655\n",
      "\n",
      "--- Validation at iteration 160 ---\n",
      "  Average MSE: 0.1043, Average ANEES: 7.8576\n",
      "  >>> New best VALIDATION ANEES! Saving model. <<<\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 170 ---\n",
      "  Average MSE: 0.1026, Average ANEES: 8.2370\n",
      "--------------------------------------------------\n",
      "--- Iteration [180/2000] ---\n",
      "    - Total Loss: 2.4785\n",
      "    - NLL: 2.4758\n",
      "    - Reg: 0.0026\n",
      "    - p1=0.601, p2=0.655\n",
      "\n",
      "--- Validation at iteration 180 ---\n",
      "  Average MSE: 0.1004, Average ANEES: 7.8602\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 190 ---\n",
      "  Average MSE: 0.1039, Average ANEES: 7.3024\n",
      "  >>> New best VALIDATION ANEES! Saving model. <<<\n",
      "--------------------------------------------------\n",
      "--- Iteration [200/2000] ---\n",
      "    - Total Loss: 2.5363\n",
      "    - NLL: 2.5337\n",
      "    - Reg: 0.0026\n",
      "    - p1=0.602, p2=0.656\n",
      "\n",
      "--- Validation at iteration 200 ---\n",
      "  Average MSE: 0.1044, Average ANEES: 6.6018\n",
      "  >>> New best VALIDATION ANEES! Saving model. <<<\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 210 ---\n",
      "  Average MSE: 0.1027, Average ANEES: 6.4228\n",
      "  >>> New best VALIDATION ANEES! Saving model. <<<\n",
      "--------------------------------------------------\n",
      "--- Iteration [220/2000] ---\n",
      "    - Total Loss: 4.8959\n",
      "    - NLL: 4.8932\n",
      "    - Reg: 0.0026\n",
      "    - p1=0.602, p2=0.656\n",
      "\n",
      "--- Validation at iteration 220 ---\n",
      "  Average MSE: 0.1033, Average ANEES: 6.2930\n",
      "  >>> New best VALIDATION ANEES! Saving model. <<<\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 230 ---\n",
      "  Average MSE: 0.1018, Average ANEES: 6.2350\n",
      "  >>> New best VALIDATION ANEES! Saving model. <<<\n",
      "--------------------------------------------------\n",
      "--- Iteration [240/2000] ---\n",
      "    - Total Loss: 2.6366\n",
      "    - NLL: 2.6340\n",
      "    - Reg: 0.0027\n",
      "    - p1=0.602, p2=0.657\n",
      "\n",
      "--- Validation at iteration 240 ---\n",
      "  Average MSE: 0.1026, Average ANEES: 5.9373\n",
      "  >>> New best VALIDATION ANEES! Saving model. <<<\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 250 ---\n",
      "  Average MSE: 0.1037, Average ANEES: 5.6485\n",
      "  >>> New best VALIDATION ANEES! Saving model. <<<\n",
      "--------------------------------------------------\n",
      "--- Iteration [260/2000] ---\n",
      "    - Total Loss: 1.6818\n",
      "    - NLL: 1.6791\n",
      "    - Reg: 0.0027\n",
      "    - p1=0.602, p2=0.657\n",
      "\n",
      "--- Validation at iteration 260 ---\n",
      "  Average MSE: 0.1029, Average ANEES: 5.4283\n",
      "  >>> New best VALIDATION ANEES! Saving model. <<<\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 270 ---\n",
      "  Average MSE: 0.1048, Average ANEES: 5.4694\n",
      "--------------------------------------------------\n",
      "--- Iteration [280/2000] ---\n",
      "    - Total Loss: 1.8820\n",
      "    - NLL: 1.8793\n",
      "    - Reg: 0.0027\n",
      "    - p1=0.602, p2=0.657\n",
      "\n",
      "--- Validation at iteration 280 ---\n",
      "  Average MSE: 0.1050, Average ANEES: 5.3323\n",
      "  >>> New best VALIDATION ANEES! Saving model. <<<\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 290 ---\n",
      "  Average MSE: 0.1059, Average ANEES: 5.2586\n",
      "  >>> New best VALIDATION ANEES! Saving model. <<<\n",
      "--------------------------------------------------\n",
      "--- Iteration [300/2000] ---\n",
      "    - Total Loss: 1.0096\n",
      "    - NLL: 1.0069\n",
      "    - Reg: 0.0027\n",
      "    - p1=0.602, p2=0.658\n",
      "\n",
      "--- Validation at iteration 300 ---\n",
      "  Average MSE: 0.1066, Average ANEES: 4.7931\n",
      "  >>> New best VALIDATION ANEES! Saving model. <<<\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 310 ---\n",
      "  Average MSE: 0.1078, Average ANEES: 4.9180\n",
      "--------------------------------------------------\n",
      "--- Iteration [320/2000] ---\n",
      "    - Total Loss: 1.4860\n",
      "    - NLL: 1.4833\n",
      "    - Reg: 0.0027\n",
      "    - p1=0.602, p2=0.658\n",
      "\n",
      "--- Validation at iteration 320 ---\n",
      "  Average MSE: 0.1072, Average ANEES: 4.9611\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 330 ---\n",
      "  Average MSE: 0.1082, Average ANEES: 4.7158\n",
      "  >>> New best VALIDATION ANEES! Saving model. <<<\n",
      "--------------------------------------------------\n",
      "--- Iteration [340/2000] ---\n",
      "    - Total Loss: 1.1262\n",
      "    - NLL: 1.1236\n",
      "    - Reg: 0.0027\n",
      "    - p1=0.602, p2=0.658\n",
      "\n",
      "--- Validation at iteration 340 ---\n",
      "  Average MSE: 0.1072, Average ANEES: 4.3982\n",
      "  >>> New best VALIDATION ANEES! Saving model. <<<\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 350 ---\n",
      "  Average MSE: 0.1071, Average ANEES: 4.6608\n",
      "--------------------------------------------------\n",
      "--- Iteration [360/2000] ---\n",
      "    - Total Loss: 0.8719\n",
      "    - NLL: 0.8692\n",
      "    - Reg: 0.0027\n",
      "    - p1=0.603, p2=0.658\n",
      "\n",
      "--- Validation at iteration 360 ---\n",
      "  Average MSE: 0.1077, Average ANEES: 4.5417\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 370 ---\n",
      "  Average MSE: 0.1070, Average ANEES: 4.8937\n",
      "--------------------------------------------------\n",
      "--- Iteration [380/2000] ---\n",
      "    - Total Loss: 0.8786\n",
      "    - NLL: 0.8759\n",
      "    - Reg: 0.0027\n",
      "    - p1=0.603, p2=0.658\n",
      "\n",
      "--- Validation at iteration 380 ---\n",
      "  Average MSE: 0.1084, Average ANEES: 4.4216\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 390 ---\n",
      "  Average MSE: 0.1087, Average ANEES: 4.5024\n",
      "--------------------------------------------------\n",
      "--- Iteration [400/2000] ---\n",
      "    - Total Loss: 1.4694\n",
      "    - NLL: 1.4667\n",
      "    - Reg: 0.0027\n",
      "    - p1=0.603, p2=0.659\n",
      "\n",
      "--- Validation at iteration 400 ---\n",
      "  Average MSE: 0.1087, Average ANEES: 4.3540\n",
      "  >>> New best VALIDATION ANEES! Saving model. <<<\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 410 ---\n",
      "  Average MSE: 0.1086, Average ANEES: 4.2473\n",
      "  >>> New best VALIDATION ANEES! Saving model. <<<\n",
      "--------------------------------------------------\n",
      "--- Iteration [420/2000] ---\n",
      "    - Total Loss: 0.7889\n",
      "    - NLL: 0.7863\n",
      "    - Reg: 0.0027\n",
      "    - p1=0.603, p2=0.659\n",
      "\n",
      "--- Validation at iteration 420 ---\n",
      "  Average MSE: 0.1085, Average ANEES: 3.9286\n",
      "  >>> New best VALIDATION ANEES! Saving model. <<<\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 430 ---\n",
      "  Average MSE: 0.1116, Average ANEES: 3.9470\n",
      "--------------------------------------------------\n",
      "--- Iteration [440/2000] ---\n",
      "    - Total Loss: 0.9430\n",
      "    - NLL: 0.9404\n",
      "    - Reg: 0.0027\n",
      "    - p1=0.603, p2=0.659\n",
      "\n",
      "--- Validation at iteration 440 ---\n",
      "  Average MSE: 0.1132, Average ANEES: 4.5652\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 450 ---\n",
      "  Average MSE: 0.1107, Average ANEES: 4.0936\n",
      "--------------------------------------------------\n",
      "--- Iteration [460/2000] ---\n",
      "    - Total Loss: 1.4907\n",
      "    - NLL: 1.4881\n",
      "    - Reg: 0.0027\n",
      "    - p1=0.603, p2=0.659\n",
      "\n",
      "--- Validation at iteration 460 ---\n",
      "  Average MSE: 0.1114, Average ANEES: 4.0768\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 470 ---\n",
      "  Average MSE: 0.1103, Average ANEES: 4.0168\n",
      "--------------------------------------------------\n",
      "--- Iteration [480/2000] ---\n",
      "    - Total Loss: 1.6842\n",
      "    - NLL: 1.6815\n",
      "    - Reg: 0.0027\n",
      "    - p1=0.603, p2=0.659\n",
      "\n",
      "--- Validation at iteration 480 ---\n",
      "  Average MSE: 0.1099, Average ANEES: 3.9053\n",
      "  >>> New best VALIDATION ANEES! Saving model. <<<\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 490 ---\n",
      "  Average MSE: 0.1134, Average ANEES: 4.0138\n",
      "--------------------------------------------------\n",
      "--- Iteration [500/2000] ---\n",
      "    - Total Loss: 1.2297\n",
      "    - NLL: 1.2270\n",
      "    - Reg: 0.0027\n",
      "    - p1=0.603, p2=0.659\n",
      "\n",
      "--- Validation at iteration 500 ---\n",
      "  Average MSE: 0.1095, Average ANEES: 3.9879\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 510 ---\n",
      "  Average MSE: 0.1107, Average ANEES: 4.2649\n",
      "--------------------------------------------------\n",
      "--- Iteration [520/2000] ---\n",
      "    - Total Loss: 0.8081\n",
      "    - NLL: 0.8055\n",
      "    - Reg: 0.0027\n",
      "    - p1=0.603, p2=0.659\n",
      "\n",
      "--- Validation at iteration 520 ---\n",
      "  Average MSE: 0.1109, Average ANEES: 3.8038\n",
      "  >>> New best VALIDATION ANEES! Saving model. <<<\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 530 ---\n",
      "  Average MSE: 0.1111, Average ANEES: 4.0498\n",
      "--------------------------------------------------\n",
      "--- Iteration [540/2000] ---\n",
      "    - Total Loss: 1.0499\n",
      "    - NLL: 1.0472\n",
      "    - Reg: 0.0027\n",
      "    - p1=0.603, p2=0.659\n",
      "\n",
      "--- Validation at iteration 540 ---\n",
      "  Average MSE: 0.1113, Average ANEES: 3.8523\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 550 ---\n",
      "  Average MSE: 0.1102, Average ANEES: 4.2129\n",
      "--------------------------------------------------\n",
      "--- Iteration [560/2000] ---\n",
      "    - Total Loss: 1.9859\n",
      "    - NLL: 1.9832\n",
      "    - Reg: 0.0027\n",
      "    - p1=0.603, p2=0.659\n",
      "\n",
      "--- Validation at iteration 560 ---\n",
      "  Average MSE: 0.1114, Average ANEES: 3.5887\n",
      "  >>> New best VALIDATION ANEES! Saving model. <<<\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 570 ---\n",
      "  Average MSE: 0.1099, Average ANEES: 3.5449\n",
      "  >>> New best VALIDATION ANEES! Saving model. <<<\n",
      "--------------------------------------------------\n",
      "--- Iteration [580/2000] ---\n",
      "    - Total Loss: 1.2205\n",
      "    - NLL: 1.2179\n",
      "    - Reg: 0.0027\n",
      "    - p1=0.603, p2=0.659\n",
      "\n",
      "--- Validation at iteration 580 ---\n",
      "  Average MSE: 0.1128, Average ANEES: 3.8064\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 590 ---\n",
      "  Average MSE: 0.1148, Average ANEES: 3.7444\n",
      "--------------------------------------------------\n",
      "--- Iteration [600/2000] ---\n",
      "    - Total Loss: 0.9826\n",
      "    - NLL: 0.9799\n",
      "    - Reg: 0.0027\n",
      "    - p1=0.603, p2=0.659\n",
      "\n",
      "--- Validation at iteration 600 ---\n",
      "  Average MSE: 0.1135, Average ANEES: 3.7795\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 610 ---\n",
      "  Average MSE: 0.1138, Average ANEES: 3.8449\n",
      "--------------------------------------------------\n",
      "--- Iteration [620/2000] ---\n",
      "    - Total Loss: 1.9263\n",
      "    - NLL: 1.9236\n",
      "    - Reg: 0.0027\n",
      "    - p1=0.603, p2=0.659\n",
      "\n",
      "--- Validation at iteration 620 ---\n",
      "  Average MSE: 0.1099, Average ANEES: 3.8378\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 630 ---\n",
      "  Average MSE: 0.1119, Average ANEES: 3.6597\n",
      "--------------------------------------------------\n",
      "--- Iteration [640/2000] ---\n",
      "    - Total Loss: 2.5500\n",
      "    - NLL: 2.5473\n",
      "    - Reg: 0.0027\n",
      "    - p1=0.603, p2=0.659\n",
      "\n",
      "--- Validation at iteration 640 ---\n",
      "  Average MSE: 0.1142, Average ANEES: 3.8686\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 650 ---\n",
      "  Average MSE: 0.1144, Average ANEES: 3.6674\n",
      "--------------------------------------------------\n",
      "--- Iteration [660/2000] ---\n",
      "    - Total Loss: 0.9741\n",
      "    - NLL: 0.9714\n",
      "    - Reg: 0.0027\n",
      "    - p1=0.603, p2=0.660\n",
      "\n",
      "--- Validation at iteration 660 ---\n",
      "  Average MSE: 0.1134, Average ANEES: 3.5308\n",
      "  >>> New best VALIDATION ANEES! Saving model. <<<\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 670 ---\n",
      "  Average MSE: 0.1130, Average ANEES: 3.4189\n",
      "  >>> New best VALIDATION ANEES! Saving model. <<<\n",
      "--------------------------------------------------\n",
      "--- Iteration [680/2000] ---\n",
      "    - Total Loss: 1.0332\n",
      "    - NLL: 1.0306\n",
      "    - Reg: 0.0027\n",
      "    - p1=0.603, p2=0.660\n",
      "\n",
      "--- Validation at iteration 680 ---\n",
      "  Average MSE: 0.1116, Average ANEES: 3.7317\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 690 ---\n",
      "  Average MSE: 0.1113, Average ANEES: 3.4223\n",
      "--------------------------------------------------\n",
      "--- Iteration [700/2000] ---\n",
      "    - Total Loss: 1.1742\n",
      "    - NLL: 1.1715\n",
      "    - Reg: 0.0027\n",
      "    - p1=0.603, p2=0.660\n",
      "\n",
      "--- Validation at iteration 700 ---\n",
      "  Average MSE: 0.1120, Average ANEES: 3.4186\n",
      "  >>> New best VALIDATION ANEES! Saving model. <<<\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 710 ---\n",
      "  Average MSE: 0.1128, Average ANEES: 3.5319\n",
      "--------------------------------------------------\n",
      "--- Iteration [720/2000] ---\n",
      "    - Total Loss: 1.2926\n",
      "    - NLL: 1.2900\n",
      "    - Reg: 0.0027\n",
      "    - p1=0.603, p2=0.660\n",
      "\n",
      "--- Validation at iteration 720 ---\n",
      "  Average MSE: 0.1145, Average ANEES: 3.5844\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 730 ---\n",
      "  Average MSE: 0.1124, Average ANEES: 3.3704\n",
      "  >>> New best VALIDATION ANEES! Saving model. <<<\n",
      "--------------------------------------------------\n",
      "--- Iteration [740/2000] ---\n",
      "    - Total Loss: 1.6229\n",
      "    - NLL: 1.6203\n",
      "    - Reg: 0.0027\n",
      "    - p1=0.603, p2=0.660\n",
      "\n",
      "--- Validation at iteration 740 ---\n",
      "  Average MSE: 0.1140, Average ANEES: 3.7281\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 750 ---\n",
      "  Average MSE: 0.1162, Average ANEES: 3.1762\n",
      "  >>> New best VALIDATION ANEES! Saving model. <<<\n",
      "--------------------------------------------------\n",
      "--- Iteration [760/2000] ---\n",
      "    - Total Loss: 1.3446\n",
      "    - NLL: 1.3419\n",
      "    - Reg: 0.0027\n",
      "    - p1=0.603, p2=0.660\n",
      "\n",
      "--- Validation at iteration 760 ---\n",
      "  Average MSE: 0.1135, Average ANEES: 3.5467\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 770 ---\n",
      "  Average MSE: 0.1159, Average ANEES: 3.4957\n",
      "--------------------------------------------------\n",
      "--- Iteration [780/2000] ---\n",
      "    - Total Loss: 1.1331\n",
      "    - NLL: 1.1304\n",
      "    - Reg: 0.0027\n",
      "    - p1=0.603, p2=0.660\n",
      "\n",
      "--- Validation at iteration 780 ---\n",
      "  Average MSE: 0.1157, Average ANEES: 3.6498\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 790 ---\n",
      "  Average MSE: 0.1151, Average ANEES: 3.6379\n",
      "--------------------------------------------------\n",
      "--- Iteration [800/2000] ---\n",
      "    - Total Loss: 1.4211\n",
      "    - NLL: 1.4184\n",
      "    - Reg: 0.0027\n",
      "    - p1=0.603, p2=0.660\n",
      "\n",
      "--- Validation at iteration 800 ---\n",
      "  Average MSE: 0.1139, Average ANEES: 3.5866\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 810 ---\n",
      "  Average MSE: 0.1135, Average ANEES: 3.3799\n",
      "--------------------------------------------------\n",
      "--- Iteration [820/2000] ---\n",
      "    - Total Loss: 1.3599\n",
      "    - NLL: 1.3573\n",
      "    - Reg: 0.0027\n",
      "    - p1=0.603, p2=0.660\n",
      "\n",
      "--- Validation at iteration 820 ---\n",
      "  Average MSE: 0.1131, Average ANEES: 3.2956\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 830 ---\n",
      "  Average MSE: 0.1144, Average ANEES: 3.8881\n",
      "--------------------------------------------------\n",
      "--- Iteration [840/2000] ---\n",
      "    - Total Loss: 1.8104\n",
      "    - NLL: 1.8077\n",
      "    - Reg: 0.0027\n",
      "    - p1=0.603, p2=0.660\n",
      "\n",
      "--- Validation at iteration 840 ---\n",
      "  Average MSE: 0.1135, Average ANEES: 3.2701\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 850 ---\n",
      "  Average MSE: 0.1145, Average ANEES: 3.2757\n",
      "--------------------------------------------------\n",
      "--- Iteration [860/2000] ---\n",
      "    - Total Loss: 1.1179\n",
      "    - NLL: 1.1152\n",
      "    - Reg: 0.0027\n",
      "    - p1=0.603, p2=0.660\n",
      "\n",
      "--- Validation at iteration 860 ---\n",
      "  Average MSE: 0.1138, Average ANEES: 3.3161\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 870 ---\n",
      "  Average MSE: 0.1126, Average ANEES: 3.2045\n",
      "--------------------------------------------------\n",
      "--- Iteration [880/2000] ---\n",
      "    - Total Loss: 0.9269\n",
      "    - NLL: 0.9243\n",
      "    - Reg: 0.0027\n",
      "    - p1=0.603, p2=0.660\n",
      "\n",
      "--- Validation at iteration 880 ---\n",
      "  Average MSE: 0.1124, Average ANEES: 3.2795\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 890 ---\n",
      "  Average MSE: 0.1132, Average ANEES: 3.3757\n",
      "--------------------------------------------------\n",
      "--- Iteration [900/2000] ---\n",
      "    - Total Loss: 1.0256\n",
      "    - NLL: 1.0229\n",
      "    - Reg: 0.0027\n",
      "    - p1=0.603, p2=0.660\n",
      "\n",
      "--- Validation at iteration 900 ---\n",
      "  Average MSE: 0.1157, Average ANEES: 3.7573\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 910 ---\n",
      "  Average MSE: 0.1138, Average ANEES: 3.3736\n",
      "--------------------------------------------------\n",
      "--- Iteration [920/2000] ---\n",
      "    - Total Loss: 1.2591\n",
      "    - NLL: 1.2565\n",
      "    - Reg: 0.0027\n",
      "    - p1=0.603, p2=0.660\n",
      "\n",
      "--- Validation at iteration 920 ---\n",
      "  Average MSE: 0.1133, Average ANEES: 3.2725\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 930 ---\n",
      "  Average MSE: 0.1180, Average ANEES: 3.3908\n",
      "--------------------------------------------------\n",
      "--- Iteration [940/2000] ---\n",
      "    - Total Loss: 1.3759\n",
      "    - NLL: 1.3733\n",
      "    - Reg: 0.0027\n",
      "    - p1=0.603, p2=0.660\n",
      "\n",
      "--- Validation at iteration 940 ---\n",
      "  Average MSE: 0.1140, Average ANEES: 3.4340\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 950 ---\n",
      "  Average MSE: 0.1168, Average ANEES: 3.6442\n",
      "--------------------------------------------------\n",
      "--- Iteration [960/2000] ---\n",
      "    - Total Loss: 3.9337\n",
      "    - NLL: 3.9310\n",
      "    - Reg: 0.0027\n",
      "    - p1=0.603, p2=0.660\n",
      "\n",
      "--- Validation at iteration 960 ---\n",
      "  Average MSE: 0.1093, Average ANEES: 3.1806\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 970 ---\n",
      "  Average MSE: 0.1128, Average ANEES: 3.2662\n",
      "--------------------------------------------------\n",
      "--- Iteration [980/2000] ---\n",
      "    - Total Loss: 0.9856\n",
      "    - NLL: 0.9829\n",
      "    - Reg: 0.0027\n",
      "    - p1=0.603, p2=0.660\n",
      "\n",
      "--- Validation at iteration 980 ---\n",
      "  Average MSE: 0.1137, Average ANEES: 3.1725\n",
      "  >>> New best VALIDATION ANEES! Saving model. <<<\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 990 ---\n",
      "  Average MSE: 0.1139, Average ANEES: 3.7624\n",
      "--------------------------------------------------\n",
      "--- Iteration [1000/2000] ---\n",
      "    - Total Loss: 1.5063\n",
      "    - NLL: 1.5036\n",
      "    - Reg: 0.0027\n",
      "    - p1=0.603, p2=0.660\n",
      "\n",
      "--- Validation at iteration 1000 ---\n",
      "  Average MSE: 0.1118, Average ANEES: 3.9195\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 1010 ---\n",
      "  Average MSE: 0.1119, Average ANEES: 3.3694\n",
      "--------------------------------------------------\n",
      "--- Iteration [1020/2000] ---\n",
      "    - Total Loss: 1.2859\n",
      "    - NLL: 1.2833\n",
      "    - Reg: 0.0027\n",
      "    - p1=0.603, p2=0.660\n",
      "\n",
      "--- Validation at iteration 1020 ---\n",
      "  Average MSE: 0.1123, Average ANEES: 3.4069\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 1030 ---\n",
      "  Average MSE: 0.1163, Average ANEES: 3.4060\n",
      "--------------------------------------------------\n",
      "--- Iteration [1040/2000] ---\n",
      "    - Total Loss: 1.0589\n",
      "    - NLL: 1.0562\n",
      "    - Reg: 0.0027\n",
      "    - p1=0.603, p2=0.660\n",
      "\n",
      "--- Validation at iteration 1040 ---\n",
      "  Average MSE: 0.1125, Average ANEES: 3.2045\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 1050 ---\n",
      "  Average MSE: 0.1128, Average ANEES: 3.4024\n",
      "--------------------------------------------------\n",
      "--- Iteration [1060/2000] ---\n",
      "    - Total Loss: 0.9940\n",
      "    - NLL: 0.9914\n",
      "    - Reg: 0.0027\n",
      "    - p1=0.603, p2=0.660\n",
      "\n",
      "--- Validation at iteration 1060 ---\n",
      "  Average MSE: 0.1151, Average ANEES: 3.0912\n",
      "  >>> New best VALIDATION ANEES! Saving model. <<<\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 1070 ---\n",
      "  Average MSE: 0.1114, Average ANEES: 3.1627\n",
      "--------------------------------------------------\n",
      "--- Iteration [1080/2000] ---\n",
      "    - Total Loss: 1.1895\n",
      "    - NLL: 1.1868\n",
      "    - Reg: 0.0027\n",
      "    - p1=0.603, p2=0.660\n",
      "\n",
      "--- Validation at iteration 1080 ---\n",
      "  Average MSE: 0.1153, Average ANEES: 3.1906\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 1090 ---\n",
      "  Average MSE: 0.1147, Average ANEES: 3.3199\n",
      "--------------------------------------------------\n",
      "--- Iteration [1100/2000] ---\n",
      "    - Total Loss: 1.1673\n",
      "    - NLL: 1.1646\n",
      "    - Reg: 0.0027\n",
      "    - p1=0.603, p2=0.660\n",
      "\n",
      "--- Validation at iteration 1100 ---\n",
      "  Average MSE: 0.1173, Average ANEES: 3.7214\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 1110 ---\n",
      "  Average MSE: 0.1145, Average ANEES: 3.3570\n",
      "--------------------------------------------------\n",
      "--- Iteration [1120/2000] ---\n",
      "    - Total Loss: 0.9016\n",
      "    - NLL: 0.8990\n",
      "    - Reg: 0.0027\n",
      "    - p1=0.603, p2=0.660\n",
      "\n",
      "--- Validation at iteration 1120 ---\n",
      "  Average MSE: 0.1136, Average ANEES: 3.1999\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 1130 ---\n",
      "  Average MSE: 0.1130, Average ANEES: 3.1358\n",
      "--------------------------------------------------\n",
      "--- Iteration [1140/2000] ---\n",
      "    - Total Loss: 1.0284\n",
      "    - NLL: 1.0257\n",
      "    - Reg: 0.0027\n",
      "    - p1=0.602, p2=0.660\n",
      "\n",
      "--- Validation at iteration 1140 ---\n",
      "  Average MSE: 0.1137, Average ANEES: 3.5506\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 1150 ---\n",
      "  Average MSE: 0.1134, Average ANEES: 3.2554\n",
      "--------------------------------------------------\n",
      "--- Iteration [1160/2000] ---\n",
      "    - Total Loss: 1.1370\n",
      "    - NLL: 1.1343\n",
      "    - Reg: 0.0027\n",
      "    - p1=0.602, p2=0.660\n",
      "\n",
      "--- Validation at iteration 1160 ---\n",
      "  Average MSE: 0.1175, Average ANEES: 3.2817\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 1170 ---\n",
      "  Average MSE: 0.1147, Average ANEES: 3.2070\n",
      "--------------------------------------------------\n",
      "--- Iteration [1180/2000] ---\n",
      "    - Total Loss: 1.0036\n",
      "    - NLL: 1.0009\n",
      "    - Reg: 0.0027\n",
      "    - p1=0.602, p2=0.660\n",
      "\n",
      "--- Validation at iteration 1180 ---\n",
      "  Average MSE: 0.1171, Average ANEES: 3.3169\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 1190 ---\n",
      "  Average MSE: 0.1137, Average ANEES: 3.0834\n",
      "  >>> New best VALIDATION ANEES! Saving model. <<<\n",
      "--------------------------------------------------\n",
      "--- Iteration [1200/2000] ---\n",
      "    - Total Loss: 1.8099\n",
      "    - NLL: 1.8073\n",
      "    - Reg: 0.0027\n",
      "    - p1=0.602, p2=0.660\n",
      "\n",
      "--- Validation at iteration 1200 ---\n",
      "  Average MSE: 0.1170, Average ANEES: 3.1680\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 1210 ---\n",
      "  Average MSE: 0.1129, Average ANEES: 3.1681\n",
      "--------------------------------------------------\n",
      "--- Iteration [1220/2000] ---\n",
      "    - Total Loss: 0.9607\n",
      "    - NLL: 0.9581\n",
      "    - Reg: 0.0027\n",
      "    - p1=0.602, p2=0.660\n",
      "\n",
      "--- Validation at iteration 1220 ---\n",
      "  Average MSE: 0.1147, Average ANEES: 3.5486\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 1230 ---\n",
      "  Average MSE: 0.1150, Average ANEES: 3.0992\n",
      "--------------------------------------------------\n",
      "--- Iteration [1240/2000] ---\n",
      "    - Total Loss: 1.0678\n",
      "    - NLL: 1.0651\n",
      "    - Reg: 0.0027\n",
      "    - p1=0.602, p2=0.660\n",
      "\n",
      "--- Validation at iteration 1240 ---\n",
      "  Average MSE: 0.1143, Average ANEES: 3.2970\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 1250 ---\n",
      "  Average MSE: 0.1148, Average ANEES: 3.1499\n",
      "--------------------------------------------------\n",
      "--- Iteration [1260/2000] ---\n",
      "    - Total Loss: 1.3750\n",
      "    - NLL: 1.3723\n",
      "    - Reg: 0.0027\n",
      "    - p1=0.602, p2=0.660\n",
      "\n",
      "--- Validation at iteration 1260 ---\n",
      "  Average MSE: 0.1150, Average ANEES: 3.3583\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 1270 ---\n",
      "  Average MSE: 0.1150, Average ANEES: 3.3660\n",
      "--------------------------------------------------\n",
      "--- Iteration [1280/2000] ---\n",
      "    - Total Loss: 2.9028\n",
      "    - NLL: 2.9001\n",
      "    - Reg: 0.0027\n",
      "    - p1=0.602, p2=0.660\n",
      "\n",
      "--- Validation at iteration 1280 ---\n",
      "  Average MSE: 0.1131, Average ANEES: 3.1971\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 1290 ---\n",
      "  Average MSE: 0.1161, Average ANEES: 3.1379\n",
      "--------------------------------------------------\n",
      "--- Iteration [1300/2000] ---\n",
      "    - Total Loss: 1.3512\n",
      "    - NLL: 1.3485\n",
      "    - Reg: 0.0027\n",
      "    - p1=0.602, p2=0.660\n",
      "\n",
      "--- Validation at iteration 1300 ---\n",
      "  Average MSE: 0.1144, Average ANEES: 3.2172\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 1310 ---\n",
      "  Average MSE: 0.1123, Average ANEES: 3.1321\n",
      "--------------------------------------------------\n",
      "--- Iteration [1320/2000] ---\n",
      "    - Total Loss: 1.5305\n",
      "    - NLL: 1.5278\n",
      "    - Reg: 0.0027\n",
      "    - p1=0.602, p2=0.660\n",
      "\n",
      "--- Validation at iteration 1320 ---\n",
      "  Average MSE: 0.1137, Average ANEES: 2.9845\n",
      "  >>> New best VALIDATION ANEES! Saving model. <<<\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 1330 ---\n",
      "  Average MSE: 0.1125, Average ANEES: 3.4147\n",
      "--------------------------------------------------\n",
      "--- Iteration [1340/2000] ---\n",
      "    - Total Loss: 1.1465\n",
      "    - NLL: 1.1438\n",
      "    - Reg: 0.0027\n",
      "    - p1=0.602, p2=0.660\n",
      "\n",
      "--- Validation at iteration 1340 ---\n",
      "  Average MSE: 0.1158, Average ANEES: 3.3721\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 1350 ---\n",
      "  Average MSE: 0.1160, Average ANEES: 3.1358\n",
      "--------------------------------------------------\n",
      "--- Iteration [1360/2000] ---\n",
      "    - Total Loss: 0.8255\n",
      "    - NLL: 0.8229\n",
      "    - Reg: 0.0027\n",
      "    - p1=0.602, p2=0.661\n",
      "\n",
      "--- Validation at iteration 1360 ---\n",
      "  Average MSE: 0.1157, Average ANEES: 3.3382\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 1370 ---\n",
      "  Average MSE: 0.1146, Average ANEES: 3.5474\n",
      "--------------------------------------------------\n",
      "--- Iteration [1380/2000] ---\n",
      "    - Total Loss: 1.1704\n",
      "    - NLL: 1.1677\n",
      "    - Reg: 0.0027\n",
      "    - p1=0.602, p2=0.660\n",
      "\n",
      "--- Validation at iteration 1380 ---\n",
      "  Average MSE: 0.1131, Average ANEES: 3.4262\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 1390 ---\n",
      "  Average MSE: 0.1148, Average ANEES: 3.4102\n",
      "--------------------------------------------------\n",
      "--- Iteration [1400/2000] ---\n",
      "    - Total Loss: 1.1987\n",
      "    - NLL: 1.1960\n",
      "    - Reg: 0.0027\n",
      "    - p1=0.602, p2=0.660\n",
      "\n",
      "--- Validation at iteration 1400 ---\n",
      "  Average MSE: 0.1134, Average ANEES: 3.4173\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 1410 ---\n",
      "  Average MSE: 0.1141, Average ANEES: 3.9368\n",
      "--------------------------------------------------\n",
      "--- Iteration [1420/2000] ---\n",
      "    - Total Loss: 1.6112\n",
      "    - NLL: 1.6085\n",
      "    - Reg: 0.0027\n",
      "    - p1=0.602, p2=0.661\n",
      "\n",
      "--- Validation at iteration 1420 ---\n",
      "  Average MSE: 0.1133, Average ANEES: 3.4294\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 1430 ---\n",
      "  Average MSE: 0.1135, Average ANEES: 3.4527\n",
      "--------------------------------------------------\n",
      "--- Iteration [1440/2000] ---\n",
      "    - Total Loss: 1.2233\n",
      "    - NLL: 1.2206\n",
      "    - Reg: 0.0027\n",
      "    - p1=0.602, p2=0.661\n",
      "\n",
      "--- Validation at iteration 1440 ---\n",
      "  Average MSE: 0.1151, Average ANEES: 3.3142\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 1450 ---\n",
      "  Average MSE: 0.1143, Average ANEES: 3.3498\n",
      "--------------------------------------------------\n",
      "--- Iteration [1460/2000] ---\n",
      "    - Total Loss: 0.9928\n",
      "    - NLL: 0.9901\n",
      "    - Reg: 0.0027\n",
      "    - p1=0.602, p2=0.661\n",
      "\n",
      "--- Validation at iteration 1460 ---\n",
      "  Average MSE: 0.1152, Average ANEES: 3.2410\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 1470 ---\n",
      "  Average MSE: 0.1122, Average ANEES: 3.3488\n",
      "--------------------------------------------------\n",
      "--- Iteration [1480/2000] ---\n",
      "    - Total Loss: 1.0783\n",
      "    - NLL: 1.0757\n",
      "    - Reg: 0.0027\n",
      "    - p1=0.602, p2=0.661\n",
      "\n",
      "--- Validation at iteration 1480 ---\n",
      "  Average MSE: 0.1144, Average ANEES: 3.4539\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 1490 ---\n",
      "  Average MSE: 0.1153, Average ANEES: 3.3219\n",
      "--------------------------------------------------\n",
      "--- Iteration [1500/2000] ---\n",
      "    - Total Loss: 1.1727\n",
      "    - NLL: 1.1700\n",
      "    - Reg: 0.0027\n",
      "    - p1=0.602, p2=0.660\n",
      "\n",
      "--- Validation at iteration 1500 ---\n",
      "  Average MSE: 0.1140, Average ANEES: 3.1371\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 1510 ---\n",
      "  Average MSE: 0.1152, Average ANEES: 3.5111\n",
      "--------------------------------------------------\n",
      "--- Iteration [1520/2000] ---\n",
      "    - Total Loss: 0.8787\n",
      "    - NLL: 0.8760\n",
      "    - Reg: 0.0027\n",
      "    - p1=0.602, p2=0.660\n",
      "\n",
      "--- Validation at iteration 1520 ---\n",
      "  Average MSE: 0.1152, Average ANEES: 3.1756\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 1530 ---\n",
      "  Average MSE: 0.1173, Average ANEES: 3.2216\n",
      "--------------------------------------------------\n",
      "--- Iteration [1540/2000] ---\n",
      "    - Total Loss: 1.4208\n",
      "    - NLL: 1.4181\n",
      "    - Reg: 0.0027\n",
      "    - p1=0.602, p2=0.660\n",
      "\n",
      "--- Validation at iteration 1540 ---\n",
      "  Average MSE: 0.1151, Average ANEES: 3.4140\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 1550 ---\n",
      "  Average MSE: 0.1124, Average ANEES: 3.3611\n",
      "--------------------------------------------------\n",
      "--- Iteration [1560/2000] ---\n",
      "    - Total Loss: 1.0106\n",
      "    - NLL: 1.0079\n",
      "    - Reg: 0.0027\n",
      "    - p1=0.602, p2=0.661\n",
      "\n",
      "--- Validation at iteration 1560 ---\n",
      "  Average MSE: 0.1119, Average ANEES: 3.3716\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 1570 ---\n",
      "  Average MSE: 0.1141, Average ANEES: 3.3038\n",
      "--------------------------------------------------\n",
      "--- Iteration [1580/2000] ---\n",
      "    - Total Loss: 0.7536\n",
      "    - NLL: 0.7509\n",
      "    - Reg: 0.0027\n",
      "    - p1=0.602, p2=0.660\n",
      "\n",
      "--- Validation at iteration 1580 ---\n",
      "  Average MSE: 0.1143, Average ANEES: 2.9442\n",
      "  >>> New best VALIDATION ANEES! Saving model. <<<\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 1590 ---\n",
      "  Average MSE: 0.1138, Average ANEES: 3.2630\n",
      "--------------------------------------------------\n",
      "--- Iteration [1600/2000] ---\n",
      "    - Total Loss: 1.2963\n",
      "    - NLL: 1.2936\n",
      "    - Reg: 0.0027\n",
      "    - p1=0.602, p2=0.660\n",
      "\n",
      "--- Validation at iteration 1600 ---\n",
      "  Average MSE: 0.1172, Average ANEES: 3.6522\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 1610 ---\n",
      "  Average MSE: 0.1157, Average ANEES: 3.2277\n",
      "--------------------------------------------------\n",
      "--- Iteration [1620/2000] ---\n",
      "    - Total Loss: 1.0173\n",
      "    - NLL: 1.0146\n",
      "    - Reg: 0.0027\n",
      "    - p1=0.602, p2=0.660\n",
      "\n",
      "--- Validation at iteration 1620 ---\n",
      "  Average MSE: 0.1146, Average ANEES: 3.2357\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 1630 ---\n",
      "  Average MSE: 0.1145, Average ANEES: 3.3524\n",
      "--------------------------------------------------\n",
      "--- Iteration [1640/2000] ---\n",
      "    - Total Loss: 1.2171\n",
      "    - NLL: 1.2144\n",
      "    - Reg: 0.0027\n",
      "    - p1=0.602, p2=0.660\n",
      "\n",
      "--- Validation at iteration 1640 ---\n",
      "  Average MSE: 0.1169, Average ANEES: 3.3072\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 1650 ---\n",
      "  Average MSE: 0.1142, Average ANEES: 3.3545\n",
      "--------------------------------------------------\n",
      "--- Iteration [1660/2000] ---\n",
      "    - Total Loss: 0.8337\n",
      "    - NLL: 0.8310\n",
      "    - Reg: 0.0027\n",
      "    - p1=0.602, p2=0.660\n",
      "\n",
      "--- Validation at iteration 1660 ---\n",
      "  Average MSE: 0.1131, Average ANEES: 3.2291\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 1670 ---\n",
      "  Average MSE: 0.1139, Average ANEES: 3.6143\n",
      "--------------------------------------------------\n",
      "--- Iteration [1680/2000] ---\n",
      "    - Total Loss: 1.6792\n",
      "    - NLL: 1.6766\n",
      "    - Reg: 0.0027\n",
      "    - p1=0.602, p2=0.660\n",
      "\n",
      "--- Validation at iteration 1680 ---\n",
      "  Average MSE: 0.1139, Average ANEES: 3.3673\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 1690 ---\n",
      "  Average MSE: 0.1121, Average ANEES: 3.3842\n",
      "--------------------------------------------------\n",
      "--- Iteration [1700/2000] ---\n",
      "    - Total Loss: 1.2116\n",
      "    - NLL: 1.2090\n",
      "    - Reg: 0.0027\n",
      "    - p1=0.602, p2=0.660\n",
      "\n",
      "--- Validation at iteration 1700 ---\n",
      "  Average MSE: 0.1133, Average ANEES: 3.3492\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 1710 ---\n",
      "  Average MSE: 0.1132, Average ANEES: 3.2204\n",
      "--------------------------------------------------\n",
      "--- Iteration [1720/2000] ---\n",
      "    - Total Loss: 3.1005\n",
      "    - NLL: 3.0978\n",
      "    - Reg: 0.0027\n",
      "    - p1=0.602, p2=0.660\n",
      "\n",
      "--- Validation at iteration 1720 ---\n",
      "  Average MSE: 0.1123, Average ANEES: 3.5429\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 1730 ---\n",
      "  Average MSE: 0.1129, Average ANEES: 3.7870\n",
      "--------------------------------------------------\n",
      "--- Iteration [1740/2000] ---\n",
      "    - Total Loss: 0.9880\n",
      "    - NLL: 0.9853\n",
      "    - Reg: 0.0027\n",
      "    - p1=0.602, p2=0.660\n",
      "\n",
      "--- Validation at iteration 1740 ---\n",
      "  Average MSE: 0.1144, Average ANEES: 3.2057\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 1750 ---\n",
      "  Average MSE: 0.1136, Average ANEES: 3.2786\n",
      "--------------------------------------------------\n",
      "--- Iteration [1760/2000] ---\n",
      "    - Total Loss: 1.0896\n",
      "    - NLL: 1.0870\n",
      "    - Reg: 0.0027\n",
      "    - p1=0.602, p2=0.660\n",
      "\n",
      "--- Validation at iteration 1760 ---\n",
      "  Average MSE: 0.1135, Average ANEES: 3.3983\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 1770 ---\n",
      "  Average MSE: 0.1155, Average ANEES: 3.4879\n",
      "--------------------------------------------------\n",
      "--- Iteration [1780/2000] ---\n",
      "    - Total Loss: 1.0752\n",
      "    - NLL: 1.0725\n",
      "    - Reg: 0.0027\n",
      "    - p1=0.602, p2=0.660\n",
      "\n",
      "--- Validation at iteration 1780 ---\n",
      "  Average MSE: 0.1131, Average ANEES: 3.4095\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 1790 ---\n",
      "  Average MSE: 0.1128, Average ANEES: 3.4666\n",
      "--------------------------------------------------\n",
      "--- Iteration [1800/2000] ---\n",
      "    - Total Loss: 0.7501\n",
      "    - NLL: 0.7474\n",
      "    - Reg: 0.0027\n",
      "    - p1=0.602, p2=0.660\n",
      "\n",
      "--- Validation at iteration 1800 ---\n",
      "  Average MSE: 0.1139, Average ANEES: 3.3172\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 1810 ---\n",
      "  Average MSE: 0.1148, Average ANEES: 3.1230\n",
      "--------------------------------------------------\n",
      "--- Iteration [1820/2000] ---\n",
      "    - Total Loss: 1.1151\n",
      "    - NLL: 1.1124\n",
      "    - Reg: 0.0027\n",
      "    - p1=0.602, p2=0.660\n",
      "\n",
      "--- Validation at iteration 1820 ---\n",
      "  Average MSE: 0.1146, Average ANEES: 3.2576\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 1830 ---\n",
      "  Average MSE: 0.1142, Average ANEES: 3.2955\n",
      "--------------------------------------------------\n",
      "--- Iteration [1840/2000] ---\n",
      "    - Total Loss: 0.9924\n",
      "    - NLL: 0.9897\n",
      "    - Reg: 0.0027\n",
      "    - p1=0.601, p2=0.660\n",
      "\n",
      "--- Validation at iteration 1840 ---\n",
      "  Average MSE: 0.1179, Average ANEES: 3.4079\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 1850 ---\n",
      "  Average MSE: 0.1139, Average ANEES: 3.2876\n",
      "--------------------------------------------------\n",
      "--- Iteration [1860/2000] ---\n",
      "    - Total Loss: 0.7459\n",
      "    - NLL: 0.7433\n",
      "    - Reg: 0.0027\n",
      "    - p1=0.601, p2=0.660\n",
      "\n",
      "--- Validation at iteration 1860 ---\n",
      "  Average MSE: 0.1131, Average ANEES: 3.3412\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 1870 ---\n",
      "  Average MSE: 0.1151, Average ANEES: 3.1934\n",
      "--------------------------------------------------\n",
      "--- Iteration [1880/2000] ---\n",
      "    - Total Loss: 0.9120\n",
      "    - NLL: 0.9094\n",
      "    - Reg: 0.0027\n",
      "    - p1=0.602, p2=0.660\n",
      "\n",
      "--- Validation at iteration 1880 ---\n",
      "  Average MSE: 0.1179, Average ANEES: 3.3870\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 1890 ---\n",
      "  Average MSE: 0.1128, Average ANEES: 3.3773\n",
      "--------------------------------------------------\n",
      "--- Iteration [1900/2000] ---\n",
      "    - Total Loss: 1.2987\n",
      "    - NLL: 1.2960\n",
      "    - Reg: 0.0027\n",
      "    - p1=0.601, p2=0.660\n",
      "\n",
      "--- Validation at iteration 1900 ---\n",
      "  Average MSE: 0.1191, Average ANEES: 3.5845\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 1910 ---\n",
      "  Average MSE: 0.1143, Average ANEES: 3.0944\n",
      "--------------------------------------------------\n",
      "--- Iteration [1920/2000] ---\n",
      "    - Total Loss: 0.9307\n",
      "    - NLL: 0.9280\n",
      "    - Reg: 0.0027\n",
      "    - p1=0.602, p2=0.660\n",
      "\n",
      "--- Validation at iteration 1920 ---\n",
      "  Average MSE: 0.1136, Average ANEES: 3.2233\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 1930 ---\n",
      "  Average MSE: 0.1117, Average ANEES: 3.1795\n",
      "--------------------------------------------------\n",
      "--- Iteration [1940/2000] ---\n",
      "    - Total Loss: 1.4143\n",
      "    - NLL: 1.4117\n",
      "    - Reg: 0.0027\n",
      "    - p1=0.601, p2=0.660\n",
      "\n",
      "--- Validation at iteration 1940 ---\n",
      "  Average MSE: 0.1136, Average ANEES: 3.3722\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 1950 ---\n",
      "  Average MSE: 0.1137, Average ANEES: 3.2259\n",
      "--------------------------------------------------\n",
      "--- Iteration [1960/2000] ---\n",
      "    - Total Loss: 0.9944\n",
      "    - NLL: 0.9918\n",
      "    - Reg: 0.0027\n",
      "    - p1=0.601, p2=0.660\n",
      "\n",
      "--- Validation at iteration 1960 ---\n",
      "  Average MSE: 0.1156, Average ANEES: 3.2481\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 1970 ---\n",
      "  Average MSE: 0.1160, Average ANEES: 3.4421\n",
      "--------------------------------------------------\n",
      "--- Iteration [1980/2000] ---\n",
      "    - Total Loss: 0.9691\n",
      "    - NLL: 0.9664\n",
      "    - Reg: 0.0027\n",
      "    - p1=0.601, p2=0.660\n",
      "\n",
      "--- Validation at iteration 1980 ---\n",
      "  Average MSE: 0.1143, Average ANEES: 3.4808\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Validation at iteration 1990 ---\n",
      "  Average MSE: 0.1171, Average ANEES: 3.3039\n",
      "--------------------------------------------------\n",
      "--- Iteration [2000/2000] ---\n",
      "    - Total Loss: 1.0136\n",
      "    - NLL: 1.0110\n",
      "    - Reg: 0.0027\n",
      "    - p1=0.601, p2=0.660\n",
      "\n",
      "--- Validation at iteration 2000 ---\n",
      "  Average MSE: 0.1155, Average ANEES: 3.2743\n",
      "--------------------------------------------------\n",
      "\n",
      "Training completed.\n",
      "Loading best model from iteration 1580 with ANEES 2.9442\n",
      "\n",
      "================================================================================\n",
      "TRÉNINK DOKONČEN - FINÁLNÍ VÝSLEDKY Z NEJLEPŠÍHO MODELU\n",
      "================================================================================\n",
      "Nejlepší model byl nalezen v iteraci: 1580\n",
      "Nejlepší dosažený validační ANEES: 2.9442\n",
      "--- Metriky odpovídající tomuto nejlepšímu modelu ---\n",
      "  MSE na validační sadě:       0.1143\n",
      "  NLL na validační sadě:       0.0000\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "\n",
    "model_config = {\n",
    "    \"hidden_size_multiplier\": 10,\n",
    "    \"output_layer_multiplier\": 4,\n",
    "    \"num_gru_layers\": 1,\n",
    "    \"init_min_dropout\": 0.5,\n",
    "    \"init_max_dropout\": 0.8\n",
    "}\n",
    "\n",
    "train_config = {\n",
    "    \"total_train_iter\": 2000,\n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"clip_grad\": 10.0,\n",
    "    \"J_samples\": 10,\n",
    "    \"validation_period\": 10,\n",
    "    \"logging_period\": 20,\n",
    "    \"warmup_iterations\":100 # Trénuj prvních 400 iterací jen na MSE\n",
    "}\n",
    "\n",
    "# =================================================================================\n",
    "# KROK 3: SPUŠTĚNÍ JEDNOHO TRÉNINKOVÉHO BĚHU\n",
    "# =================================================================================\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"Spouštím jeden plnohodnotný tréninkový běh...\")\n",
    "print(f\"Parametry modelu: {model_config}\")\n",
    "print(f\"Parametry tréninku: {train_config}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Nastavení seedu pro reprodukovatelnost tohoto běhu\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Vytvoření modelu\n",
    "state_bkn_knet = StateBayesianKalmanNet(\n",
    "    sys_model,\n",
    "    device=device,\n",
    "    **model_config\n",
    ").to(device)\n",
    "\n",
    "# Spuštění tréninku\n",
    "# Používáme `run_training_session`, která vrací slovník s výsledky\n",
    "results = trainer.training_session_trajectory_with_gaussian_nll_training_fcn(model=state_bkn_knet,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    device=device,\n",
    "    **train_config\n",
    ")\n",
    "\n",
    "# `run_training_session` automaticky načte nejlepší model zpět,\n",
    "# takže `state_bkn_knet` nyní obsahuje váhy nejlepšího modelu.\n",
    "trained_model = results['final_model']\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRÉNINK DOKONČEN - FINÁLNÍ VÝSLEDKY Z NEJLEPŠÍHO MODELU\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Nejlepší model byl nalezen v iteraci: {results['best_iter']}\")\n",
    "# --- Změněné klíče, aby odpovídaly return statementu ---\n",
    "print(f\"Nejlepší dosažený validační ANEES: {results['best_val_anees']:.4f}\")\n",
    "print(\"--- Metriky odpovídající tomuto nejlepšímu modelu ---\")\n",
    "print(f\"  MSE na validační sadě:       {results['best_val_mse']:.4f}\")\n",
    "print(f\"  NLL na validační sadě:       {results['best_val_nll']:.4f}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Nyní můžeš s `trained_model` pokračovat, například ho vyhodnotit na testovací sadě."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "096fdf12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Váhy modelu byly úspěšně uloženy do: LinearSystemWeights/best_bkn_model_weights_real_aaaaaaaaaaaabbbba.pth\n",
      "Načítám váhy zpět do nové instance modelu...\n",
      "loaded with input normalization\n",
      "Model byl úspěšně načten a je připraven v proměnné 'trained_model' k vyhodnocení.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "# =================================================================================\n",
    "# KROK 4: ULOŽENÍ A OPĚTOVNÉ NAČTENÍ VAH MODELU\n",
    "# =================================================================================\n",
    "\n",
    "# 1. Vytvoření cílové složky (pokud ještě neexistuje)\n",
    "save_dir = \"LinearSystemWeights\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Cesta k souboru s váhami\n",
    "weights_path = os.path.join(save_dir, \"best_bkn_model_weights_real_aaaaaaaaaaaabbbba.pth\")\n",
    "\n",
    "# 2. Uložení vah aktuálně nejlepšího modelu z předchozí buňky\n",
    "torch.save(trained_model.state_dict(), weights_path)\n",
    "print(f\"Váhy modelu byly úspěšně uloženy do: {weights_path}\")\n",
    "\n",
    "# 3. Následné načtení modelu z uložených vah\n",
    "print(\"Načítám váhy zpět do nové instance modelu...\")\n",
    "\n",
    "# Nejprve musíme vytvořit novou, prázdnou instanci modelu se naprosto stejnou konfigurací\n",
    "loaded_bkn_model = StateBayesianKalmanNet(\n",
    "    sys_model,\n",
    "    device=device,\n",
    "    **model_config\n",
    ").to(device)\n",
    "\n",
    "# Načteme uložený slovník vah do této nové instance\n",
    "loaded_bkn_model.load_state_dict(torch.load(weights_path))\n",
    "\n",
    "# Přepneme model do evaluačního módu (velmi důležité pro dropout a batchnorm vrstvy před testováním!)\n",
    "loaded_bkn_model.eval()\n",
    "\n",
    "# Přiřadíme do proměnné trained_model, jak jsi požadoval\n",
    "trained_model = loaded_bkn_model\n",
    "\n",
    "print(\"Model byl úspěšně načten a je připraven v proměnné 'trained_model' k vyhodnocení.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b62217b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Layer 'output_final_linear.0' initialized near zero (Start K=0).\n",
      "New best model saved! Epoch [1/100], Train Loss: 0.685550, Val Loss: 0.561850\n",
      "New best model saved! Epoch [2/100], Train Loss: 0.460528, Val Loss: 0.378792\n",
      "New best model saved! Epoch [3/100], Train Loss: 0.325862, Val Loss: 0.279672\n",
      "New best model saved! Epoch [4/100], Train Loss: 0.248223, Val Loss: 0.215482\n",
      "Epoch [5/100] | Train Loss: 0.1926 (Pos: 0.00, Vel: 0.00) | Val Loss: 0.1695 | Val MSE: 0.17\n",
      "Epoch [4/100], Train Loss: 0.248223, Val Loss: 0.215482\n",
      "New best model saved! Epoch [5/100], Train Loss: 0.192613, Val Loss: 0.169501\n",
      "New best model saved! Epoch [6/100], Train Loss: 0.153118, Val Loss: 0.135673\n",
      "New best model saved! Epoch [7/100], Train Loss: 0.124484, Val Loss: 0.109896\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m random\u001b[38;5;241m.\u001b[39mseed(\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m     15\u001b[0m state_knet \u001b[38;5;241m=\u001b[39m StateKalmanNet(sys_model, device\u001b[38;5;241m=\u001b[39mdevice, hidden_size_multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m12\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 16\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_state_KalmanNet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate_knet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_patience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\n\u001b[1;32m     24\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/skola/KalmanNet-main/utils/trainer.py:653\u001b[0m, in \u001b[0;36mtrain_state_KalmanNet\u001b[0;34m(model, train_loader, val_loader, device, epochs, lr, clip_grad, early_stopping_patience, optimizer_type, weight_decay, print_gradient)\u001b[0m\n\u001b[1;32m    647\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(predicted_trajectory, x_true_batch[:, \u001b[38;5;241m1\u001b[39m:, :])\n\u001b[1;32m    648\u001b[0m \u001b[38;5;66;03m# diff = predicted_trajectory - x_true_batch[:, 1:, :]\u001b[39;00m\n\u001b[1;32m    649\u001b[0m \u001b[38;5;66;03m# pos_loss = torch.mean(diff[:, :, :2]**2) # Pozice X, Y\u001b[39;00m\n\u001b[1;32m    650\u001b[0m \u001b[38;5;66;03m# vel_loss = torch.mean(diff[:, :, 2:]**2) # Rychlost\u001b[39;00m\n\u001b[1;32m    651\u001b[0m \u001b[38;5;66;03m# loss = 100.0 * pos_loss + 1.0 * vel_loss\u001b[39;00m\n\u001b[0;32m--> 653\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    655\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m print_gradient:\n\u001b[1;32m    656\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgradient: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;241m.\u001b[39mdnn\u001b[38;5;241m.\u001b[39minput_layer[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mgrad\u001b[38;5;241m.\u001b[39mabs()\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "# Nastavení seedu pro reprodukovatelnost tohoto běhu\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "state_knet = StateKalmanNet(sys_model, device=device, hidden_size_multiplier=12).to(device)\n",
    "trainer.train_state_KalmanNet(\n",
    "    model=state_knet, \n",
    "    train_loader=train_loader, \n",
    "    val_loader=val_loader, \n",
    "    device=device, \n",
    "    epochs=100, \n",
    "    lr=1e-4,\n",
    "    early_stopping_patience=30\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f78c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "# Nastavení seedu pro reprodukovatelnost tohoto běhu\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "state_knetR = StateKalmanNetWithKnownR(sys_model, device=device, hidden_size_multiplier=12).to(device)\n",
    "trainer.train_state_KalmanNet(\n",
    "    model=state_knetR, \n",
    "    train_loader=train_loader, \n",
    "    val_loader=val_loader, \n",
    "    device=device, \n",
    "    epochs=100, \n",
    "    lr=1e-4,\n",
    "    early_stopping_patience=30\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453b1b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# ==============================================================================\n",
    "# 0. PŘEDPOKLADY - ZDE PŘIŘAĎTE VAŠE NATRÉNOVANÉ MODELY\n",
    "# ==============================================================================\n",
    "# Ujistěte se, že v proměnných níže máte již natrénované a připravené modely.\n",
    "# Názvy proměnných si upravte podle vašeho kódu, pokud se liší.\n",
    "try:\n",
    "    trained_model_bkn = trained_model\n",
    "    trained_model_classic = state_knet\n",
    "    trained_model_knetR = state_knetR\n",
    "    print(\"INFO: Všechny natrénované modely nalezeny a přiřazeny.\")\n",
    "except NameError:\n",
    "    print(\"VAROVÁNÍ: Některé z proměnných `trained_model`, `state_knet`, nebo `state_knetR` nebyly nalezeny.\")\n",
    "    print(\"         Ujistěte se, že jste nejprve úspěšně dokončili trénink všech modelů.\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. KONFIGURACE TESTU\n",
    "# ==============================================================================\n",
    "TEST_SEQ_LEN = 1000\n",
    "NUM_TEST_TRAJ = 10\n",
    "J_SAMPLES_TEST = 25\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. PŘÍPRAVA DAT\n",
    "# ==============================================================================\n",
    "print(f\"\\nGeneruji {NUM_TEST_TRAJ} testovacích trajektorií o délce {TEST_SEQ_LEN}...\")\n",
    "x_test, y_test = utils.generate_data(sys_true, num_trajectories=NUM_TEST_TRAJ, seq_len=TEST_SEQ_LEN)\n",
    "test_dataset = TensorDataset(x_test, y_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "print(\"Generování dat dokončeno.\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. INICIALIZACE VŠECH FILTRŮ PRO POROVNÁNÍ\n",
    "# ==============================================================================\n",
    "ekf_mismatched = Filters.ExtendedKalmanFilter(sys_model)\n",
    "ekf_ideal = Filters.ExtendedKalmanFilter(sys_true)\n",
    "ukf_mismatched = Filters.UnscentedKalmanFilter(sys_model)\n",
    "ukf_ideal = Filters.UnscentedKalmanFilter(sys_true)\n",
    "akf_mismatched = Filters.AdaptiveKalmanFilter(sys_model,mdm_L=3,mdm_version=2)\n",
    "kf_ideal = Filters.KalmanFilter(sys_true)\n",
    "print(\"Všechny model-based filtry (EKF, UKF, AKF) inicializovány.\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 4. VYHODNOCOVACÍ SMYČKA\n",
    "# ==============================================================================\n",
    "# Seznamy pro ukládání výsledků z každé trajektorie\n",
    "all_x_true_cpu = []\n",
    "all_x_hat_bkn_cpu, all_P_hat_bkn_cpu = [], []\n",
    "all_x_hat_classic_knet_cpu = []\n",
    "all_x_hat_knetR_cpu, all_P_hat_knetR_cpu = [], []\n",
    "all_x_hat_ekf_mismatched_cpu, all_P_hat_ekf_mismatched_cpu = [], []\n",
    "all_x_hat_ekf_ideal_cpu, all_P_hat_ekf_ideal_cpu = [], []\n",
    "all_x_hat_ukf_mismatched_cpu, all_P_hat_ukf_mismatched_cpu = [], []\n",
    "all_x_hat_ukf_ideal_cpu, all_P_hat_ukf_ideal_cpu = [], []\n",
    "all_x_hat_akf_mismatched_cpu, all_P_hat_akf_mismatched_cpu = [], []\n",
    "all_x_hat_kf_ideal_cpu, all_P_hat_kf_ideal_cpu = [], []\n",
    "\n",
    "print(f\"\\nVyhodnocuji modely na {NUM_TEST_TRAJ} testovacích trajektoriích...\")\n",
    "\n",
    "trained_model_bkn.eval() \n",
    "trained_model_classic.eval()\n",
    "trained_model_knetR.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (x_true_seq_batch, y_test_seq_batch) in enumerate(test_loader):\n",
    "        y_test_seq_gpu = y_test_seq_batch.squeeze(0).to(device)\n",
    "        x_true_seq_gpu = x_true_seq_batch.squeeze(0).to(device)\n",
    "        initial_state = x_true_seq_gpu[0, :].unsqueeze(0)\n",
    "        \n",
    "        # --- A. Bayesian KalmanNet (Trajectory-wise) ---\n",
    "        ensemble_trajectories = []\n",
    "        for j in range(J_SAMPLES_TEST):\n",
    "            trained_model_bkn.reset(batch_size=1, initial_state=initial_state)\n",
    "            current_x_hats = []\n",
    "            for t in range(1, TEST_SEQ_LEN):\n",
    "                x_filtered_t, _ = trained_model_bkn.step(y_test_seq_gpu[t, :].unsqueeze(0))\n",
    "                current_x_hats.append(x_filtered_t)\n",
    "            ensemble_trajectories.append(torch.cat(current_x_hats, dim=0))\n",
    "        ensemble = torch.stack(ensemble_trajectories, dim=0)\n",
    "        predictions_bkn = ensemble.mean(dim=0)\n",
    "        diff = ensemble - predictions_bkn.unsqueeze(0)\n",
    "        covariances_bkn = (diff.unsqueeze(-1) @ diff.unsqueeze(-2)).mean(dim=0)\n",
    "        full_x_hat_bkn = torch.cat([initial_state, predictions_bkn], dim=0)\n",
    "        full_P_hat_bkn = torch.cat([sys_model.P0.unsqueeze(0), covariances_bkn], dim=0)\n",
    "\n",
    "        # --- B. Klasický StateKalmanNet (pouze MSE) ---\n",
    "        trained_model_classic.reset(batch_size=1, initial_state=initial_state)\n",
    "        classic_knet_preds = []\n",
    "        for t in range(1, TEST_SEQ_LEN):\n",
    "            x_filtered_t = trained_model_classic.step(y_test_seq_gpu[t, :].unsqueeze(0))\n",
    "            classic_knet_preds.append(x_filtered_t)\n",
    "        full_x_hat_classic_knet = torch.cat([initial_state, torch.cat(classic_knet_preds, dim=0)], dim=0)\n",
    "        \n",
    "        # --- C. StateKalmanNetWithKnownR ---\n",
    "        trained_model_knetR.reset(batch_size=1, initial_state=initial_state)\n",
    "        knetR_preds_x, knetR_preds_P = [], []\n",
    "        for t in range(1, TEST_SEQ_LEN):\n",
    "            x_filtered_t, P_filtered_t = trained_model_knetR.step(y_test_seq_gpu[t, :].unsqueeze(0))\n",
    "            knetR_preds_x.append(x_filtered_t)\n",
    "            knetR_preds_P.append(P_filtered_t)\n",
    "        full_x_hat_knetR = torch.cat([initial_state, torch.cat(knetR_preds_x, dim=0)], dim=0)\n",
    "        processed_P_list = []\n",
    "        for p_tensor in knetR_preds_P:\n",
    "\n",
    "            while p_tensor.dim() < 2:\n",
    "                p_tensor = p_tensor.unsqueeze(-1)\n",
    "\n",
    "            if p_tensor.dim() > 2 and p_tensor.shape[0] == 1:\n",
    "                p_tensor = p_tensor.squeeze(0)\n",
    "            processed_P_list.append(p_tensor)\n",
    "\n",
    "\n",
    "        P_sequence_knetR = torch.stack(processed_P_list, dim=0)\n",
    "        \n",
    "\n",
    "        P0_for_cat = sys_model.P0.clone()\n",
    "        while P0_for_cat.dim() < P_sequence_knetR.dim():\n",
    "            P0_for_cat = P0_for_cat.unsqueeze(0)\n",
    "            \n",
    "        full_P_hat_knetR = torch.cat([P0_for_cat, P_sequence_knetR], dim=0)\n",
    "\n",
    "        # --- D. EKF (nepřesný a ideální) ---\n",
    "        ekf_m_res = ekf_mismatched.process_sequence(y_test_seq_gpu, Ex0=sys_model.Ex0, P0=sys_model.P0)\n",
    "\n",
    "        full_x_hat_ekf_m = ekf_m_res['x_filtered'] # Výsledek je již kompletní trajektorie\n",
    "        full_P_hat_ekf_m = ekf_m_res['P_filtered'] # To samé pro kovarianci\n",
    "\n",
    "        ekf_i_res = ekf_ideal.process_sequence(y_test_seq_gpu, Ex0=sys_true.Ex0, P0=sys_true.P0)\n",
    "\n",
    "        full_x_hat_ekf_i = ekf_i_res['x_filtered']\n",
    "        full_P_hat_ekf_i = ekf_i_res['P_filtered']\n",
    "\n",
    "        # --- E. UKF (nepřesný a ideální) ---\n",
    "        ukf_m_res = ukf_mismatched.process_sequence(y_test_seq_gpu, Ex0=sys_model.Ex0, P0=sys_model.P0)\n",
    "\n",
    "        full_x_hat_ukf_m = ukf_m_res['x_filtered']\n",
    "        full_P_hat_ukf_m = ukf_m_res['P_filtered']\n",
    "\n",
    "        ukf_i_res = ukf_ideal.process_sequence(y_test_seq_gpu, Ex0=sys_true.Ex0, P0=sys_true.P0)\n",
    "\n",
    "        full_x_hat_ukf_i = ukf_i_res['x_filtered']\n",
    "        full_P_hat_ukf_i = ukf_i_res['P_filtered']\n",
    "\n",
    "        # --- F. Adaptivní EKF (nepřesný) ---\n",
    "        akf_m_res,_,_ = akf_mismatched.process_sequence_adaptively(y_test_seq_gpu)\n",
    "        full_x_hat_akf_m = akf_m_res['x_filtered']\n",
    "        full_P_hat_akf_m = akf_m_res['P_filtered']\n",
    "\n",
    "        kf_i_res = kf_ideal.process_sequence(y_test_seq_gpu, Ex0=sys_true.Ex0, P0=sys_true.P0)\n",
    "\n",
    "        full_x_hat_kf_i = kf_i_res['x_filtered']\n",
    "        full_P_hat_kf_i = kf_i_res['P_filtered']\n",
    "\n",
    "        all_x_true_cpu.append(x_true_seq_gpu.cpu())\n",
    "        all_x_hat_bkn_cpu.append(full_x_hat_bkn.cpu()); all_P_hat_bkn_cpu.append(full_P_hat_bkn.cpu())\n",
    "        all_x_hat_classic_knet_cpu.append(full_x_hat_classic_knet.cpu())\n",
    "        all_x_hat_knetR_cpu.append(full_x_hat_knetR.cpu()); all_P_hat_knetR_cpu.append(full_P_hat_knetR.cpu())\n",
    "        all_x_hat_ekf_mismatched_cpu.append(full_x_hat_ekf_m.cpu()); all_P_hat_ekf_mismatched_cpu.append(full_P_hat_ekf_m.cpu())\n",
    "        all_x_hat_ekf_ideal_cpu.append(full_x_hat_ekf_i.cpu()); all_P_hat_ekf_ideal_cpu.append(full_P_hat_ekf_i.cpu())\n",
    "        all_x_hat_ukf_mismatched_cpu.append(full_x_hat_ukf_m.cpu()); all_P_hat_ukf_mismatched_cpu.append(full_P_hat_ukf_m.cpu())\n",
    "        all_x_hat_ukf_ideal_cpu.append(full_x_hat_ukf_i.cpu()); all_P_hat_ukf_ideal_cpu.append(full_P_hat_ukf_i.cpu())\n",
    "        all_x_hat_akf_mismatched_cpu.append(full_x_hat_akf_m.cpu()); all_P_hat_akf_mismatched_cpu.append(full_P_hat_akf_m.cpu())\n",
    "        all_x_hat_kf_ideal_cpu.append(full_x_hat_kf_i.cpu()); all_P_hat_kf_ideal_cpu.append(full_P_hat_kf_i.cpu())\n",
    "\n",
    "        print(f\"Dokončena trajektorie {i + 1}/{NUM_TEST_TRAJ}...\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 5. FINÁLNÍ VÝPOČET A VÝPIS METRIK\n",
    "# ==============================================================================\n",
    "# Seznamy pro sběr metrik\n",
    "mse_bkn, anees_bkn = [], []; mse_classic_knet = []; mse_knetR, anees_knetR = [], []\n",
    "mse_ekf_mis, anees_ekf_mis = [], []; mse_ekf_ideal, anees_ekf_ideal = [], []\n",
    "mse_ukf_mis, anees_ukf_mis = [], []; mse_ukf_ideal, anees_ukf_ideal = [], []\n",
    "mse_akf_mis, anees_akf_mis = [], []; mse_kf_ideal, anees_kf_ideal = [], []\n",
    "\n",
    "print(\"\\nPočítám finální metriky pro jednotlivé trajektorie...\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(NUM_TEST_TRAJ):\n",
    "        x_true = all_x_true_cpu[i]\n",
    "        def get_metrics(x_hat, P_hat):\n",
    "            mse = F.mse_loss(x_hat[1:], x_true[1:]).item()\n",
    "            anees = utils.calculate_anees_vectorized(x_true.unsqueeze(0), x_hat.unsqueeze(0), P_hat.unsqueeze(0))\n",
    "            return mse, anees\n",
    "\n",
    "        # Výpočty pro všechny modely\n",
    "        mse, anees = get_metrics(all_x_hat_bkn_cpu[i], all_P_hat_bkn_cpu[i]); mse_bkn.append(mse); anees_bkn.append(anees)\n",
    "        mse = F.mse_loss(all_x_hat_classic_knet_cpu[i][1:], x_true[1:]).item(); mse_classic_knet.append(mse)\n",
    "        mse, anees = get_metrics(all_x_hat_knetR_cpu[i], all_P_hat_knetR_cpu[i]); mse_knetR.append(mse); anees_knetR.append(anees)\n",
    "        mse, anees = get_metrics(all_x_hat_ekf_mismatched_cpu[i], all_P_hat_ekf_mismatched_cpu[i]); mse_ekf_mis.append(mse); anees_ekf_mis.append(anees)\n",
    "        mse, anees = get_metrics(all_x_hat_ekf_ideal_cpu[i], all_P_hat_ekf_ideal_cpu[i]); mse_ekf_ideal.append(mse); anees_ekf_ideal.append(anees)\n",
    "        mse, anees = get_metrics(all_x_hat_ukf_mismatched_cpu[i], all_P_hat_ukf_mismatched_cpu[i]); mse_ukf_mis.append(mse); anees_ukf_mis.append(anees)\n",
    "        mse, anees = get_metrics(all_x_hat_ukf_ideal_cpu[i], all_P_hat_ukf_ideal_cpu[i]); mse_ukf_ideal.append(mse); anees_ukf_ideal.append(anees)\n",
    "        mse, anees = get_metrics(all_x_hat_akf_mismatched_cpu[i], all_P_hat_akf_mismatched_cpu[i]); mse_akf_mis.append(mse); anees_akf_mis.append(anees)\n",
    "        mse, anees = get_metrics(all_x_hat_kf_ideal_cpu[i], all_P_hat_kf_ideal_cpu[i]); mse_kf_ideal.append(mse); anees_kf_ideal.append(anees)\n",
    "# Funkce pro bezpečné průměrování\n",
    "def avg(metric_list): return np.mean([m for m in metric_list if not np.isnan(m)])\n",
    "state_dim_for_nees = all_x_true_cpu[0].shape[1]\n",
    "\n",
    "# --- Finální výpis tabulky ---\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"FINÁLNÍ VÝSLEDKY (průměr přes {NUM_TEST_TRAJ} běhů)\")\n",
    "print(\"=\"*80)\n",
    "print(f\"{'Model':<35} | {'Průměrné MSE':<20} | {'Průměrný ANEES':<20}\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"{'--- Data-Driven Models ---':<35} | {'(nižší je lepší)':<20} | {'(bližší ' + str(float(state_dim_for_nees)) + ' je lepší)':<20}\")\n",
    "print(f\"{'Bayesian KNet (BKN)':<35} | {avg(mse_bkn):<20.4f} | {avg(anees_bkn):<20.4f}\")\n",
    "print(f\"{'KNet (pouze MSE)':<35} | {avg(mse_classic_knet):<20.4f} | {'N/A':<20}\")\n",
    "print(f\"{'KNet with Known R (KNetR)':<35} | {avg(mse_knetR):<20.4f} | {avg(anees_knetR):<20.4f}\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"{'--- Model-Based Filters ---':<35} | {'':<20} | {'':<20}\")\n",
    "print(f\"{'EKF (Nepřesný model)':<35} | {avg(mse_ekf_mis):<20.4f} | {avg(anees_ekf_mis):<20.4f}\")\n",
    "print(f\"{'UKF (Nepřesný model)':<35} | {avg(mse_ukf_mis):<20.4f} | {avg(anees_ukf_mis):<20.4f}\")\n",
    "print(f\"{'AKF (Nepřesný model)':<35} | {avg(mse_akf_mis):<20.4f} | {avg(anees_akf_mis):<20.4f}\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"{'--- Benchmarks ---':<35} | {'':<20} | {'':<20}\")\n",
    "print(f\"{'EKF (Ideální model)':<35} | {avg(mse_ekf_ideal):<20.4f} | {avg(anees_ekf_ideal):<20.4f}\")\n",
    "print(f\"{'UKF (Ideální model)':<35} | {avg(mse_ukf_ideal):<20.4f} | {avg(anees_ukf_ideal):<20.4f}\")\n",
    "print(f\"{'KF (Ideální model)':<35} | {avg(mse_kf_ideal):<20.4f} | {avg(anees_kf_ideal):<20.4f}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b74eec",
   "metadata": {},
   "source": [
    "# Kalman Gain comparison"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
